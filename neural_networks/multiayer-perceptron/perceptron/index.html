
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A complete description of mathematics that go in making a perceptron work.">
      
      
        <meta name="author" content="Murtaza Nazir">
      
      
        <link rel="canonical" href="https://themurtazanazir.github.io/neural_networks/multiayer-perceptron/perceptron/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../perceptron-convergence-theorem/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Maths Behind Perceptron - murtaza</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="brown" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="murtaza" class="md-header__button md-logo" aria-label="murtaza" data-md-component="logo">
      
  <img src="../../../img/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            murtaza
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Maths Behind Perceptron
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="murtaza" class="md-nav__button md-logo" aria-label="murtaza" data-md-component="logo">
      
  <img src="../../../img/logo.svg" alt="logo">

    </a>
    murtaza
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Linear Algebra
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Linear Algebra
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../linear_algebra/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../linear_algebra/vectors-linear-combinations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vectors & Linear Combinations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../linear_algebra/vector-spaces-and-subspaces/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vector Spaces & Subspaces
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Multi-Layer Perceptron
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Multi-Layer Perceptron
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Perceptron
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../perceptron-convergence-theorem/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Perceptron Convergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-layer-perceptron/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multi-Layer Perceptron
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../improvements-to-mlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Improvements to MLP
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Convolutional Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Convolutional Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../convolutional_neural_networks/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../convolutional_neural_networks/convolutions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convolutions
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Transformer
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/transformer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<p><a href="../">‚Üê Multi-Layer Perceptron</a></p>
<h1 id="mathematics-behind-perceptron">Mathematics Behind Perceptron</h1>
<p class="drop-cap">This is actually a notebook made by me during the internet shutdown in Kashmir (since 5th Aug 2019). This notebook, and others, are heavily inspired by <a href="https://www.amazon.in/dp/1466583282/ref=cm_sw_r_cp_apa_i_TAKcEbNSD9Y57" target="_blank"> Machine Learning: An Algorithmic Perspective </a> . This notebook is essentially the notes of chapter 3 of this book. I highly recommend this book for the basic understanding of Machine Learning Algorithms. This post covers mathematics, implementation of the basic perceptron algorithm. I would suggest to practice on the code for perceptron. Although stay away from the visualization code, if that seems too complex.</p>

<h1 id="hebbs-rule">Hebb's Rule</h1>
<p>It states that <em>"the changes in the strength of synaptic connections are proportional to the correlation in the firing of two connecting neurons"</em></p>
<h1 id="mcculloch-and-pitts-neurons">McCulloch and Pitts Neurons</h1>
<h2 id="1-introduction">1. Introduction</h2>
<p>This was a mathematical model of a neuron. It extracts the basic essentials to accurately represent the entity being studied(the neurons that make our nervous system!), removing all the extraneous details.</p>
<p>It is modelled as:
1. <strong>a set of weighted inputs, \(w_i\),</strong> that correspond to synapses.
2. <strong>an adder,</strong> that sums the input signals.
3. <strong>an activation function</strong>(usually a threshold function), that decides whether the neuron fires(spikes!) for the current inputs.</p>
<p>So,</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(h=\sum_{i=1}^m{w_ix_i}\tag{1}\)</span>\)</span></p>
<p>where \(w_i\) is the weight at the synapse for \(i^{th}\) input and \(x_i\) is the input from \(i^{th}\) neuron into synapse. </p>
<p>Now to decide if the neuron fires or not, we need a threshold (\(\theta\)). If the weighted sum of the inputs(\(h\)) is greater than the threshold, the neuron fires(i.e output is 1).</p>
<p>So the activation function is:
$$\sigma=g(h)=\begin{cases} 1&amp;\text{if }h&gt;\theta\ 0&amp;\text{if }h\leq\theta\ \end{cases} \tag{2} $$</p>
<h2 id="2-limitations">2. Limitations</h2>
<ul>
<li>The inputs to a real neuron aren't necessarily summed linearly: there may be non-linear summations.</li>
<li>The real neurons do not output a single response, instead a train of spikes like a sequence of pulses is produced which encodes information.</li>
<li>The neurons do not update themselves sequentially according to a computer clock but do it asynchronously.</li>
<li>The weights in our model can be positive and negative, implying the presence of excitation or inhibitance property, which is also possesed by the real neurons but unlike real neurons our model change change from exciting to inhibitory after weight updates while real neurons stay the way they are(exciting or inhibitory).</li>
</ul>
<h1 id="the-perceptron">The Perceptron</h1>
<h2 id="1-introduction_1">1. Introduction</h2>
<p>The perceptron is nothing more than a collection of <a href="#mcculloch-and-pitts-neurons">McCulloch and Pitts neurons</a> together with a set of inputs and some weights to fasten the inputs to the neurons. The neurons in the Perceptron are completely independent of each other.</p>
<p><img alt="" src="../perceptron_network.png" />
Figure 1: The Perceptron Network(the orange nodes are inputs, not neurons)</p>
<p>Each neuron has its own weights which it multiplies with its input and adds them to decide whether to fire or not depending on its own threshold. The inputs are the number of features(usually columns) our data has. The number of neurons can be varied and is usually the total unique classifying target values.</p>
<p>We represent a particular weight as \(w_{ij}\) where \(i\) is the input it is coming from and \(j\) is the neuron it is going into. So \(w_{32}\) is the weight that connects the input node 3 to neuron 2. In the <a href="#2.-Implementation">implementation</a>, we will save the weights in a two dimensional array.</p>
<p>The input will be stored as a vector and so the output.</p>
<h2 id="2-implementation">2. Implementation</h2>
<h3 id="21-introduction">2.1 Introduction</h3>
<p>In supervised learning, we already have a ground truth target.</p>
<ol>
<li>For an input vector, we apply Equation 1 for each neuron to decide if each neuron will fire or not, generating its the output vector. </li>
<li>For an output vector(a vector of 0s and 1s which determine if the corresponding neurons have fired or not!), we compare it to the target vector(the actual value for that input) to identify which neurons got the answer right and which did not.</li>
<li>Those neurons with correct outputs are fine but those with wrong outputs(i.e they fire when they didn't have to or didn't when they had to), their weights need to be changed so that they fire correctly.</li>
</ol>
<h3 id="22-learning-the-weights">2.2 Learning the Weights</h3>
<h4 id="221-introduction">2.2.1 Introduction</h4>
<p>We'll talk more about it later, but for now let's deploy a simple learning system.</p>
<p>\(m:\) no. of input features.</p>
<p>\(n:\) no. of output neurons.</p>
<p>\(x_i,  i \in [0,m]:\) the input vector of m features.</p>
<p>\(y_i,   i \in [0,n]:\) the output vector of n neurons.</p>
<p>\(t_i,  i \in [0,n]:\) the actual target vector.</p>
<p>Suppose \(k^{th}\) neuron gets the wrong answer, it has \(m\) weights connected to it(one for each input node). The weights we need to change is \(w_{ik}\) where \(i\) runs from \(1\) to \(m\).</p>
<p>Now we know which weights to change, but by how much to change them by?</p>
<p>Before answering that, let's figure out if a weight is too high or low(i.e do we need to increase it or decrease it?).</p>
<p>At the first glance, we can say that bigger weights tend a neuron to fire(as they help it get over the threshold) and smaller weights tend to not fire. So if a neuron fires when it wasn't supposed to, there are some weights which are bigger than they should be, or if doesn't fire when it should(some weights are too small!).</p>
<p>For that neuron we can calculate:
<span class="arithmatex">\(<span class="arithmatex">\(y_k-t_k \tag{3}\)</span>\)</span>
i.e the difference between the output of the nepuron and the actual truth.</p>
<p>If the above equation is Zero, then neuron has the correct output. However if it is positive(specifically \(1\)), then the neuron has fired when it shouldn't have, i.e weights are big and if it is negative(specifically \(-1\)), then the neuron hasn't fired when it should have, i.e weights are small. The above equation can act as a possible <strong>error function</strong>.</p>
<p>So until now we know:</p>
<p>the weights \(w_{ij}\) will be changed by \( \Delta w_{ij}\)</p>
<p>where,</p>
<div class="arithmatex">\[\Delta w_{ij}  = \begin{cases} &gt; 0 &amp; \text{if } y_j - t_j &lt;0\\ &lt; 0 &amp; \text{if } y_j - t_j &gt;0\\ = 0 &amp; \text{if } y_j - t_j =0\\ \end{cases}\\ \implies \Delta w_{ij} = - (y_j-t_j)k \]</div>
<p>where \(k\) is the constant which gives the <em>amount by which each weight needs to be changed</em>.</p>
<p>While this all seems right, we have missed something. What if the inputs are negative? </p>
<p>If the inputs are negative, then switch values, we'll need to reduce the weights to fire and increase to not fire.</p>
<p>To get around that we make a change:</p>
<div class="arithmatex">\[ \Delta w_{ij}=-k(y_j - t_j)x_i\]</div>
<p>if \(x_i\) is negative it will automatically change the direction of weight change and \(k\) decides how much the weight changes by. The parameter \(k\) is called the learning rate and is often represented by \(\eta\) instead of k.</p>
<p>so </p>
<div class="arithmatex">\[\Delta w_{ij}= - \eta(y_j-t_j) x_i\]</div>
<p>Finally we update the weights,</p>
<div class="arithmatex">\[w_{ij} \leftarrow w_{ij}-\eta(y_j-t_j) x_i \tag{4}\]</div>
<p>We can update these for an optimum learning rate for some predefined \(T\) iterations. However we will later see other stopping methods.</p>
<h4 id="222-learning-rate">2.2.2 Learning Rate</h4>
<p>The learning rate is an important parameter which needs to be tuned to get better accuracies. Too high value of it might change the weights more than they were needed to and a too low will take too long to train. It is often used in the range of \( 10^{-4} &lt; \eta &lt; 10 \). But feel free to check out of these bounds. Also for perceptron this parameter is way less important and can be set to anything. However for other models it is the most crucial parameter.</p>
<h4 id="223-bias-node">2.2.3 Bias node</h4>
<p>Now that we have figured out the weights, but we haven't discussed another important parameter, the threshold. What threshold to choose for what problem? That is where a Bias node comes into play.</p>
<p>We can show Equation 1 for a certain neuron as:</p>
<div class="arithmatex">\[ h = w_{1j} x_1 + w_{2j}  x_2 + w_{3j}  x_3 + \cdots +w_{mj}  x_m  \]</div>
<p>where \(x_k\) is \(k^{th}\) input feature and \(w_{kj}\) is the weight from \(k^{th}\) input node to \(j^{th}\) neuron.</p>
<p>Now, if the threshold is \(\theta\), Equation 2 shows that:</p>
<div class="arithmatex">\[ \begin{align} \sigma &amp;= \begin{cases}1 &amp; \text{if }w_{1j} x_1 + w_{2j} x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m &gt; \theta_j \\ 0 &amp; \text{if }w_{1j}  x_1 + w_{2j}  x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m &lt; \theta_j \end{cases}\\ \\ &amp;= \begin{cases} 1 &amp; \text{if }w_{1j} x_1 + w_{2j} x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m - \theta_j &gt;0 \\ 0 &amp; \text{if }w_{1j}  x_1 + w_{2j}  x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m - \theta_j&lt;0 \end{cases}\\ \\ &amp;=\begin{cases} 1 &amp; \text{if }w_{1j} x_1 + w_{2j} x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m + (-1) \theta_j &gt;0 \\ 0 &amp; \text{if }w_{1j}  x_1 + w_{2j}  x_2 + w_{3j} x_3 + \cdots +w_{mj} x_m + (-1) \theta_j&lt;0 \end{cases} \end{align} \]</div>
<p>so \(\theta\) can be learned as another weight, if we consider an extra input feature which is always \(-1\) and our new threshold is \(0\).(However \(\theta_j\) is the actual threshold which instead of defining, we let the neuron to learn like any other weight.)</p>
<p>The Bias Node also helps us overcome the all-zero input problem. If all the inputs in an example are Zero then no matter how the weights change, it won't change the output, but the bias node will change and make changes necessary for correct output. </p>
<p>So to make it work we will also need an extra but constant input node reserved for -1.</p>
<p><strong>Note :</strong> <em>Actually, it is not necessary to use -1 as the bias input. Any constant will do. People mostly use +1 but we will use -1 to make it stand out.</em></p>
<p>The Bias Node is considered the \(x_0\) which is constant(-1) and the weight to it is \(w_{0j}\)(which is actually \(\theta_j\)).</p>
<p>So the new Structure is like:
<img alt="" src="../perceptron_with_bias_node.png" /></p>
<p>Figure 2: Perceptron with Bias Node</p>
<h3 id="23-putting-everything-together">2.3 Putting Everything Together</h3>
<p>Now that we have all the things cleared out, it is time to put everything together.</p>
<p>The algorithm is separated into two parts: a <strong>training</strong> phase and a <strong>recall</strong> phase. The <strong>recall</strong> is essentially used after training is finished to actually use the model.</p>
<p>The Algorithm is as:</p>
<h4 id="1-initialization">1. <strong>Initialization:</strong></h4>
<ul>
<li>set all the weights \(w_{ij}\) to small random numbers(both positive and negative).</li>
</ul>
<h4 id="2-training">2. <strong>Training:</strong></h4>
<ul>
<li>for \(T\) iterations or untill all outputs are correct:<ul>
<li>
<p>for each input vector:</p>
<ol>
<li>compute the activation of each neuron \(j\) using:</li>
</ol>
<p><span class="arithmatex">\(<span class="arithmatex">\(y=g \bigg(\sum_{i=0}^mw_{ij}x_i\bigg)=\begin{cases}1 &amp; \text{if } \sum_{i=0}^mw_{ij}x_i &gt; 0 \\ 0 &amp; \text{if } \sum_{i=0}^mw_{ij}x_i \leq 0 \end{cases}\)</span>\)</span></p>
<p>where \(x_0\) is -1 (the bias node) and \(m\) is the number of features our data has.</p>
<ol>
<li>update each of the weights individually using:
    <span class="arithmatex">\(<span class="arithmatex">\(w_{ij} \leftarrow w_{ij} - \eta(y_j-t_j)\cdot x_i\)</span>\)</span></li>
</ol>
</li>
</ul>
</li>
</ul>
<h4 id="3-recall">3. <strong>Recall:</strong></h4>
<ul>
<li>compute the activation of each neuron \(j\) using:</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(y=g \Bigg(\sum_{i=0}^mw_{ij}x_i\Bigg)=\begin{cases}1 &amp; \text{if } \sum_{i=0}^mw_{ij}x_i &gt; 0 \\ 0 &amp; \text{if } \sum_{i=0}^mw_{ij}x_i \leq 0 \end{cases}\)</span>\)</span></p>
<h3 id="24-speeding-up-the-code">2.4 Speeding Up the code</h3>
<h4 id="241-speeding-up-the-computation-of-activations">2.4.1 Speeding Up the computation of activations</h4>
<p>The code for it has multiple loops for training. Loops for multiplying the weights with inputs and loops while updating weights. The simple loops can take a lot of time, but many languages, like python, have libraries(numpy, tensorflow, pytorch) to perform matrix perations much quicker than simple loops. We will put these to our use to speed up the training as well as the recall process as well.</p>
<p>Let's say we have \(k\) number of training examples and each example has \(m\) features with \(n\) types of outputs.</p>
<p>Now instead of taking one example at a time and updating weights and doing the same for \(T\) iterations, we can store all our training examples in a matrix where each example is a row and each column is a feature.</p>
<p>So the 4th feature of 6th training example will look like \(x_{64}\).</p>
<p>So our input matrix \(X\) should look like:</p>
<div class="arithmatex">\[X= \begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} &amp; \cdots &amp; x_{1m} \\ x_{21} &amp; x_{22} &amp; x_{23} &amp; \cdots &amp; x_{2m} \\ x_{31} &amp; x_{32} &amp; x_{33} &amp; \cdots &amp; x_{3m} \\ \vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\ x_{k1} &amp; x_{k2} &amp; x_{k3} &amp; \cdots &amp; x_{km} \\ \end{bmatrix} \tag{5} \]</div>
<p>This matrix will be \(k \times m\).</p>
<p>In python we would do this using a library called <code>numpy</code></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</code></pre></div>
<p>let's say we want to train to learn the Logical-OR function.
So our input should look like:</p>
<div class="arithmatex">\[X= \begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 1 \\ 1 &amp; 0 \\ 1 &amp; 1 \\ \end{bmatrix} \]</div>
<p>we can make it make it using <code>np.array</code> method:</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">X</span>
</code></pre></div>
<pre><code>array([[0, 0],
       [0, 1],
       [1, 0],
       [1, 1]])
</code></pre>
<p>now our input is ready, let's figure out how to store the target values. Each input has target values for which neuron to fire and which not to(1s and 0s).</p>
<p>So with \(k\) examples and \(n\) output neurons, the target matrix should be \([t_{ij}]\) which is the target for \(i^{th}\) example and \(j^{th}\) neuron.</p>
<p>So,
$$ T=\begin{bmatrix} t_{11} &amp; t_{12} &amp; t_{13} &amp; \cdots &amp; t_{1n}\ t_{21} &amp; t_{22} &amp; t_{23} &amp; \cdots &amp; t_{2n}\ t_{31} &amp; t_{32} &amp; t_{33} &amp; \cdots &amp; t_{3n}\ \vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \ t_{k1} &amp; t_{k2} &amp; t_{k3} &amp; \cdots &amp; t_{kn}\ \end{bmatrix}\ \tag{6}$$
where \(t_{ij} \in {0,1}\) </p>
<p>For binary outputs, like in our example, we can just use one output neuron, which will fire for one output and not fire for other which means \(n=1\).</p>
<p>So, </p>
<div class="arithmatex">\[ T_{binary} = \begin{bmatrix} t_1\\ t_2\\ \vdots \\ t_k \end{bmatrix} \]</div>
<p>and in our example,</p>
<div class="arithmatex">\[ T = \begin{bmatrix} 0\\ 1\\ 1\\ 1 \end{bmatrix} \]</div>
<p>we can do it in numpy in the same way:</p>
<div class="highlight"><pre><span></span><code><span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">]]);</span><span class="n">T</span>
</code></pre></div>
<pre><code>array([[0],
       [1],
       [1],
       [1]])
</code></pre>
<p>Moving on to the outputs generated by our neurons. For \(n\) neurons and \(k\) examples, we can store that in a matrix \([y_{ij}]\) for \(i^{th}\) example and \(j^{th}\) neuron like:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(Y= \begin{bmatrix} y_{11} &amp; y_{12} &amp; y_{13} &amp; \cdots &amp; y_{1n}\\ y_{21} &amp; y_{22} &amp; y_{23} &amp; \cdots &amp; y_{2n}\\ y_{31} &amp; y_{32} &amp; y_{33} &amp; \cdots &amp; y_{3n}\\ \vdots \\ y_{k1} &amp; y_{k2} &amp; y_{k3} &amp; \cdots &amp; y_{kn}\\ \end{bmatrix}\\\tag{7}\)</span>\)</span>
where \(y_{ij} \in {0,1}\)</p>
<p>So,
$$ y_{ij} = g(h_{ij})=\begin{cases} 1 &amp; \text{if } x_{i1}w_{1j}+x_{i2}w_{2j}+\cdots + x_{im}w_{mj} + (-1)w_{0j} &gt; 0 \ 0 &amp; \text{if } x_{i1}w_{1j}+x_{i2}w_{2j}+\cdots + x_{im}w_{mj} + (-1)w_{0j} \leq 0 \ \end{cases} \tag{8} $$</p>
<p>if we replace all of it in the matrix,</p>
<p>$$Y=g\Bigg( \begin{bmatrix} h_{11} &amp; h_{12} &amp; h_{13} &amp; \cdots &amp; h_{1n}\ h_{21} &amp; h_{22} &amp; h_{23} &amp; \cdots &amp; h_{2n}\ h_{31} &amp; h_{32} &amp; h_{33} &amp; \cdots &amp; h_{3n}\ \vdots \ h_{k1} &amp; h_{k2} &amp; h_{k3} &amp; \cdots &amp; h_{kn}\ \end{bmatrix}\Bigg) \tag{9} $$
where \(h_{ij} =(-1)w_{0j}+\sum_{a=1}^{m}x_{ia}w_{aj}\)</p>
<p>or if we keep
<span class="arithmatex">\(<span class="arithmatex">\(x_{j0} = -1  \  \forall j \in [1,k] \tag{10}\\\)</span>\)</span></p>
<div class="arithmatex">\[ \implies Y=g\Bigg( \begin{bmatrix} \sum_{a=0}^{m}x_{1a}w_{a1} &amp; \sum_{a=0}^{m}x_{1a}w_{a2} &amp; \cdots &amp; \sum_{a=0}^{m}x_{1a}w_{an}\\ \\ \sum_{a=0}^{m}x_{2a}w_{a1} &amp; \sum_{a=0}^{m}x_{2a}w_{a2} &amp; \cdots &amp; \sum_{a=0}^{m}x_{2a}w_{an}\\ \\ \sum_{a=0}^{m}x_{3a}w_{a1} &amp; \sum_{a=0}^{m}x_{3a}w_{a2} &amp; \cdots &amp; \sum_{a=0}^{m}x_{3a}w_{an}\\ \vdots &amp; \vdots &amp;   &amp; \vdots\\ \sum_{a=0}^{m}x_{ka}w_{a1} &amp; \sum_{a=0}^{m}x_{ka}w_{a2}  &amp; \cdots &amp; \sum_{a=0}^{m}x_{ka}w_{an}\\ \end{bmatrix}\Bigg) \tag{11} \]</div>
<p>The above matrix looks like a multiplication of two matrices. Let's open it up:</p>
<div class="arithmatex">\[Y=g\Bigg( \begin{bmatrix} x_{10} &amp; x_{11} &amp;  \cdots &amp; x_{1m}\\ x_{20} &amp; x_{21}  &amp; \cdots &amp; x_{2m}\\ x_{30} &amp; x_{31} &amp; \cdots &amp; x_{3m}\\ \vdots &amp; \vdots &amp; &amp; \vdots \\ x_{k0} &amp; x_{k1} &amp; \cdots &amp; x_{km}\\ \end{bmatrix}\times \begin{bmatrix} w_{01} &amp; w_{02}  &amp; \cdots &amp; w_{0n}\\ w_{11} &amp; w_{12} &amp;  \cdots &amp; w_{1n}\\ w_{21} &amp; w_{22}  &amp; \cdots &amp; w_{2n}\\ \vdots &amp; \vdots &amp; &amp; \vdots \\ w_{m1} &amp; w_{m2}  &amp; \cdots &amp; w_{mn}\\ \end{bmatrix} \Bigg) \tag{12} \]</div>
<p>if we look at the Left Matrix it is the input matrix (\(X\)) with extra column on far left and we know the far left column is always -1, so we can actually redefine the input matrix to include this extra column.</p>
<div class="arithmatex">\[\implies X=\begin{bmatrix} x_{10} &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1m}\\ x_{20} &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2m}\\ x_{30} &amp; x_{31} &amp; x_{32} &amp; \cdots &amp; x_{3m}\\ \vdots \\ x_{k0} &amp; x_{k1} &amp; x_{k2} &amp; \cdots &amp; x_{km}\\ \end{bmatrix} \tag{13}\]</div>
<p>This matrix is now \(k \times (m+1)\).</p>
<p>we can generate a column of -1 using the <code>np.ones</code> method and then concatenate it with our input matrix using <code>np.concatenate</code> to form the new input matrix, like:</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span><span class="n">X</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span>
</code></pre></div>
<pre><code>array([[-1.,  0.,  0.],
       [-1.,  0.,  1.],
       [-1.,  1.,  0.],
       [-1.,  1.,  1.]])
</code></pre>
<p>Now that we have fixed the input matrix, let's move to the second matrix in Equation 12, the <strong>weight matrix</strong>.</p>
<p>$$ W = \begin{bmatrix} w_{01} &amp; w_{02} &amp; w_{03} &amp; \cdots &amp; w_{0n}\ w_{11} &amp; w_{12} &amp; x_{13} &amp; \cdots &amp; w_{1n}\ w_{21} &amp; w_{22} &amp; x_{23} &amp; \cdots &amp; w_{2n}\ \vdots \ w_{m1} &amp; w_{m2} &amp; x_{m3} &amp; \cdots &amp; w_{mn}\ \end{bmatrix}\ \tag{14}$$
where \(w_{ij}\) is the weight from \(i^{th}\) input node to \(j^{th}\) output neuron</p>
<p>This matrix is \( (m+1) \times n\).</p>
<p>with Equation 13 can be rewriten as:</p>
<p>$$ Y=g(X \times W)\ \tag{15} $$
where:
1. \(X\) is the input matrix(Equation 13 with bias nodes.
2. \(W\) is the weight matrix (Equation 14).
3. \(\times\) represents matrix multiplication.
4. and the function \(g\)(Equation 8) is applied elementwise to the resultant matrix to generate outputs for every neuron for every training example.</p>
<p>We will use the <code>np.matmul</code> function to perform a matrix multiplication and we will use the <strong>numpy boolean mask broadcasting</strong> to compute activations. Since we have to repeat this step, we will make a function for this named <code>compute_activations</code>. so <code>Y=compute_activations(X,W)</code> whenever needed.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">activation</span>
</code></pre></div>
<p>This completes the first part of the <a href="#2.-Training:">Training Algorithm</a> (i.e compute activation of each neuron for each input example). Now let's move to the Second Part of the Training, Updating Weights.</p>
<h4 id="242-speeding-up-the-the-updation-of-weights">2.4.2 Speeding up the the updation of weights</h4>
<p>The updation of weights is given by Equation 4, which is:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(w_{ij}\leftarrow w_{ij} - \eta(y_j-t_j)\cdot x_i\tag{4}\)</span>\)</span>
where \(w_{ij}\) is the weight from \(i^{th}\) input node to \(j^{th}\) output neuron. </p>
<p>We can vectorize this operation, instead of updating every weight using a loop, we update the whole weight matrix at once. </p>
<p>$$ W \leftarrow W -\eta \Delta W \tag{16} $$
where \(W\) is the weight matrix and \( \Delta W \) is the matrix having the corresponding \((y_j - t_j) \cdot x_i\) for each weight.</p>
<p>Now before we move on figure out how \(\Delta W\) should be computed, let's put a detour to see how the weight changes for different examples.</p>
<p>Let's say we had three examples. Each weight will be updated three times with their corresponding \(x_i\).</p>
<p>Let's denote \(x_{ij}\) as the \(j^{th}\) input feature of \(i^{th}\) example and \(t_{ia}\) as the target for \(i^{th}\) example and \(a^{th}\) output neuron. So, \(1\leq i \leq 3\).</p>
<p>Now after each example, weights will change, like:</p>
<div class="arithmatex">\[ w_{ja} \leftarrow w_{ja} - \eta(y_{1a} - t_{1a})  x_{1j} \tag{for ex. 1}\\ \]</div>
<div class="arithmatex">\[ w_{ja} \leftarrow w_{ja} - \eta(y_{2a} - t_{2a})  x_{2j} \tag{for ex. 2}\\ \]</div>
<div class="arithmatex">\[ w_{ja} \leftarrow w_{ja} - \eta(y_{3a} - t_{3a})  x_{3j} \tag{for ex. 3} \]</div>
<p>each of the above change will occur to each weight one after the another. so these can be summed as:</p>
<div class="arithmatex">\[ w_{ja} \leftarrow w_{ja} - \eta \{(y_{1a} - t_{1a})  x_{1j} + (y_{2a} - t_{2a})  x_{2j} + (y_{3a} - t_{3a})  x_{3j}\} \tag{17} \]</div>
<p>It can be generalized as, for \(k\) examples:</p>
<div class="arithmatex">\[ w_{ja} \leftarrow w_{ja}- \eta \Big(\sum_{i=1}^k(y_{ia} - t_{ia}) x_{ij}\Big) \tag{18} \]</div>
<p>So \(\Delta W\) is just a matrix of the \(\sum_{i=1}^k(y_{ia} - t_{ia}) x_{ij}\) for every neuron and for every example.</p>
<p>So, for \(k\) examples with \(m+1\) input features (the first being \(x_{i0} = -1\)) and \(n\) output neurons</p>
<div class="arithmatex">\[ \Delta W = \begin{bmatrix} \sum_{i=1}^k  x_{i0}  (y_{i1} - t_{i1})  &amp; \sum_{i=1}^k  x_{i0}  (y_{i2} - t_{i2})  &amp; \cdots &amp; \sum_{i=1}^k  x_{i0}  (y_{in} - t_{in}) \\ \sum_{i=1}^k  x_{i1}  (y_{i1} - t_{i1})  &amp; \sum_{i=1}^k  x_{i1}  (y_{i2} - t_{i2})  &amp; \cdots &amp; \sum_{i=1}^k  x_{i1}  (y_{in} - t_{in}) \\ \vdots\\ \sum_{i=1}^k  x_{im}  (y_{i1} - t_{i1})  &amp; \sum_{i=1}^k  x_{im}  (y_{i2} - t_{i2})  &amp; \cdots &amp; \sum_{i=1}^k  x_{im} (y_{in} - t_{in}) \\ \end{bmatrix} \tag{19} \]</div>
<p>This matrix is \((m+1) \times n\) same as the weights matrix.</p>
<p>Take some time to write it down and look at every entry to make it clear for yourself.</p>
<p>Let's unpack this bad boy! So it also looks like a matrix multiplication of two matrices.</p>
<div class="arithmatex">\[ \Delta W = \begin{bmatrix} x_{10} &amp; x_{20} &amp; \cdots &amp; x_{k0}\\ x_{11} &amp; x_{21} &amp; \cdots &amp; x_{k1}\\ \vdots \\ x_{1m} &amp; x_{2m} &amp; \cdots &amp; x_{km}\\ \end{bmatrix} \times  \begin{bmatrix} y_{11} - t_{11} &amp; y_{12} - t_{12} &amp; \cdots &amp; y_{1n} - t_{1n} \\ y_{21} - t_{21} &amp; y_{22} - t_{22} &amp; \cdots &amp; y_{2n} - t_{2n} \\ \vdots \\ y_{k1} - t_{k1} &amp; y_{k2} - t_{k2} &amp; \cdots &amp; y_{kn} - t_{kn} \\ \end{bmatrix} \]</div>
<p>The right matrix is basically the subtraction of target matrix \(T\) ([Equation 6]) subtracted from the output matrix \(Y\) ([Equation 7]).</p>
<div class="arithmatex">\[ \implies \Delta W =  \begin{bmatrix} x_{10} &amp; x_{20} &amp; \cdots &amp; x_{k0}\\ x_{11} &amp; x_{21} &amp; \cdots &amp; x_{k1}\\ \vdots \\ x_{1m} &amp; x_{2m} &amp; \cdots &amp; x_{km}\\ \end{bmatrix} \times \Bigg( \begin{bmatrix} y_{11} &amp; y_{12} &amp; \cdots &amp; y_{1n} \\ y_{21} &amp; y_{22} &amp; \cdots &amp; y_{2n} \\ \vdots \\ y_{k1} &amp; y_{k2} &amp; \cdots &amp; y_{kn} \\ \end{bmatrix} -  \begin{bmatrix} t_{11} &amp; t_{12} &amp; \cdots &amp; t_{1n} \\ t_{21} &amp; t_{22} &amp; \cdots &amp; t_{2n} \\ \vdots \\ t_{k1} &amp; y_{k2} &amp; \cdots &amp; t_{kn} \\ \end{bmatrix} \Bigg) \]</div>
<p>The left matrix is the transpose of the input matrix with bias values \(X\) (Equation 13).</p>
<div class="arithmatex">\[ \implies \Delta W =  \begin{bmatrix} x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1m}\\ x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2m}\\ \vdots \\ x_{k0} &amp; x_{k1} &amp; \cdots &amp; x_{km}\\ \end{bmatrix}^T \times \Bigg( \begin{bmatrix} y_{11} &amp; y_{12} &amp; \cdots &amp; y_{1n} \\ y_{21} &amp; y_{22} &amp; \cdots &amp; y_{2n} \\ \vdots \\ y_{k1} &amp; y_{k2} &amp; \cdots &amp; y_{kn} \\ \end{bmatrix} -  \begin{bmatrix} t_{11} &amp; t_{12} &amp; \cdots &amp; t_{1n} \\ t_{21} &amp; t_{22} &amp; \cdots &amp; t_{2n} \\ \vdots \\ t_{k1} &amp; y_{k2} &amp; \cdots &amp; t_{kn} \\ \end{bmatrix} \Bigg) \tag{20} \]</div>
<p>Finally,</p>
<div class="arithmatex">\[ \Delta W = X^T \times (Y-T) \tag{21} \]</div>
<p>Using the above equation, Equation 16 becomes:</p>
<div class="arithmatex">\[ W \leftarrow W - \eta \{X^T \times (Y-T)\}\\ \tag{22} \]</div>
<p>where:
- \(X^T\): is the transpose of input matrix.
- \(Y\): is the output matrix.
- \(T\):  is the target matrix.
- \( \eta \):  is the <a href="#2.2.2-Learning-Rate">learning rate</a>.
- \(\times\):  represents matrix multiplication.</p>
<p>now to compute the transpose of a matrix, we use <code>np.transpose</code> function. we can use the simple minus operator to perform subtraction in matrices. Also to multiply each element by \(\eta\), we use the broadcasting property. Since this step is also going to be used multiple times, we will turn it into a function, like:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">input_matrix</span><span class="p">,</span> <span class="n">output_matrix</span><span class="p">,</span> <span class="n">target_matrix</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="n">delta_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">),(</span><span class="n">output_matrix</span><span class="o">-</span><span class="n">target_matrix</span><span class="p">))</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span><span class="o">*</span><span class="n">delta_w</span><span class="p">)</span> <span class="c1"># elementwise multiplication using broadcasting</span>
    <span class="k">return</span> <span class="n">weights</span>
</code></pre></div>
<p>but before updating the weight matrix, we need to initialize a weight matrix with small random numbers. we can use the <code>np.random.rand</code> to generate random numbers between 0 and 1, then multiply by 0.1 (to make them small) and subtract 0.05 to get some negative weights.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_out</span><span class="p">):</span>
    <span class="c1"># the input shape should be including the bias inputs</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_out</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span> <span class="o">-</span> <span class="mf">0.05</span>
    <span class="k">return</span> <span class="n">weights</span>
</code></pre></div>
<h3 id="25-final-code">2.5 Final Code</h3>
<p>now that we have finished all the functions for training as well as initialization, for recall, we can again use the <code>compute_activations</code> function.</p>
<p>Let's put the code together and run for an example. while training, we can print weights and output after each iteration.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">activation</span>

<span class="k">def</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="c1"># the input shape should be including the bias inputs</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_out</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span> <span class="o">-</span> <span class="mf">0.05</span>
    <span class="k">return</span> <span class="n">weights</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">input_matrix</span><span class="p">,</span> <span class="n">output_matrix</span><span class="p">,</span> <span class="n">target_matrix</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="n">delta_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">),(</span><span class="n">output_matrix</span><span class="o">-</span><span class="n">target_matrix</span><span class="p">))</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span><span class="o">*</span><span class="n">delta_w</span><span class="p">)</span> <span class="c1"># elementwise multiplication using broadcasting</span>
    <span class="k">return</span> <span class="n">weights</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">init_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># add the bias values to input_matrix</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">input_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span><span class="n">input_data</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1">#set the shapes</span>
    <span class="n">n_input</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n_out</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1">#initialize the weights</span>
    <span class="k">if</span> <span class="n">init_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">initialize_weights</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">init_weights</span>

    <span class="k">if</span> <span class="n">save_weights</span><span class="p">:</span>
        <span class="n">weight_array</span><span class="o">=</span><span class="p">[</span><span class="n">W</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># compute outputs</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">compute_activations</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="c1">#print the output</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration: </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">W</span><span class="si">}</span><span class="se">\n</span><span class="s2">Output:</span><span class="se">\n</span><span class="si">{</span><span class="n">Y</span><span class="p">[:</span><span class="mi">10</span><span class="p">,:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="p">(</span><span class="n">Y</span><span class="o">==</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># update weights</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">update_weights</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">save_weights</span><span class="p">:</span>
            <span class="n">weight_array</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">save_weights</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">weight_array</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">W</span>

<span class="k">def</span><span class="w"> </span><span class="nf">recall</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="c1"># add the bias values to input_matrix</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">input_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span><span class="n">input_data</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute activations</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">compute_activations</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Y</span>
</code></pre></div>
<p>This is all we need for a perceptron code. After a good time, you can feel the simplicity and elegancy of it.</p>
<p>Let's try it for an OR data. Let's see if it can learn the parameters.</p>
<div class="highlight"><pre><span></span><code> <span class="n">prepare</span> <span class="n">the</span> <span class="n">data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">train</span> <span class="n">the</span> <span class="n">data</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="n">T</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<pre><code>Iteration: 0
[[-0.01254599]
 [ 0.04507143]
 [ 0.02319939]]
Output:
[[ True]
 [ True]
 [ True]
 [ True]]
Accuracy: 0.75
Iteration: 1
[[0.23745401]
 [0.04507143]
 [0.02319939]]
Output:
[[False]
 [False]
 [False]
 [False]]
Accuracy: 0.25
Iteration: 2
[[-0.51254599]
 [ 0.54507143]
 [ 0.52319939]]
Output:
[[ True]
 [ True]
 [ True]
 [ True]]
Accuracy: 0.75
Iteration: 3
[[-0.26254599]
 [ 0.54507143]
 [ 0.52319939]]
Output:
[[ True]
 [ True]
 [ True]
 [ True]]
Accuracy: 0.75
Iteration: 4
[[-0.01254599]
 [ 0.54507143]
 [ 0.52319939]]
Output:
[[ True]
 [ True]
 [ True]
 [ True]]
Accuracy: 0.75
Iteration: 5
[[0.23745401]
 [0.54507143]
 [0.52319939]]
Output:
[[False]
 [ True]
 [ True]
 [ True]]
Accuracy: 1.0
</code></pre>
<p>and with a learning rate of 0.25, it can learn the parameters for OR gate in just 6 iterations.</p>
<h2 id="3-visualization">3. Visualization</h2>
<p>Now that we have completely studied the basic perceptron. Let's visualize some things to get the better understanding.</p>
<p>we will use the <code>plotly</code>'s <code>express</code> and <code>graph_objects</code> for plotting.</p>
<p>Let's first plot our input data</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">plotly.express</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">px</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objects</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;str&quot;</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="s2">&quot;Input 1&quot;</span><span class="p">,</span><span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="s2">&quot;Input 2&quot;</span><span class="p">,</span><span class="s2">&quot;color&quot;</span><span class="p">:</span><span class="s2">&quot;Output&quot;</span><span class="p">},</span>
                 <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Scatter of Data Points&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>Now let's see what the weights represent.</p>
<p>We know that \(w_{ij}\) is the weight from \(i^{th}\) input node to \(j^{th}\) output node.</p>
<p>Since we have only one output neuron and 2 input nodes(3 with bias node).</p>
<p>Our Weights compute, for each example:
\(w_{01}(-1) + w_{11}\cdot inp1+w_{12}\cdot inp2\) and then check if it is greater than or less than Zero.</p>
<p>For the boundary case, </p>
<div class="arithmatex">\[ w_{01}(-1) + w_{11}\cdot inp1+w_{12}\cdot inp2=0 \]</div>
<p>if we were to plot this threshold line with \(inp2\) as the y-axis and \(inp1\) on the x-axis, then:</p>
<p>$$ inp2=\frac{-w_{11}inp1+w_{01}}{w_{12}} $$
So,in the previous example, our final weights were:</p>
<div class="highlight"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>
<pre><code>array([[0.23745401],
       [0.54507143],
       [0.52319939]])
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">inp1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="n">fig</span>  <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
                            <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Input 1&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Input 2&quot;</span><span class="p">,</span>
                            <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Decision Boundary with Scatter&quot;</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">][</span><span class="n">T</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:][</span><span class="n">T</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span> <span class="s2">&quot;Output: 1&quot;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">][</span><span class="n">T</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:][</span><span class="n">T</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">name</span><span class="o">=</span> <span class="s2">&quot;Output: 1&quot;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">inp1</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">inp1</span><span class="p">)</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">name</span><span class="o">=</span> <span class="s2">&quot;Decision Boundary&quot;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>a more sophisticated  decision boundary</p>
<div class="highlight"><pre><span></span><code><span class="n">xx</span><span class="p">,</span><span class="n">yy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">500</span><span class="p">),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">500</span><span class="p">))</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">recall</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span><span class="n">weights</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Heatmap</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">y</span><span class="o">=</span><span class="n">yy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span>
        <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
        <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span>
<span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
            <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>all the points above this line will cause the fire of the current neuron, and all the below won't.</p>
<p>Let's see the updation of weights and it's impact on the decision boundary.</p>
<p>we will train the model while saving the weights to plot it. We will set the learning rate to be small so that the animation is smooth and we get a good idea of what is happening. You can change it. I have also increased the number of epochs as the learning rate is small now. Also play with different <code>random_state</code> to start from initial different weights.</p>
<div class="highlight"><pre><span></span><code><span class="n">W</span><span class="p">,</span> <span class="n">weight_array</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="n">T</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">save_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">364</span><span class="p">)</span>
</code></pre></div>
<p>after having all the weights saved, we will plot them one after the other using the <code>animation.FuncAnimation</code> function. Change the <code>interval</code> if the animation is too slow or too fast.</p>
<div class="highlight"><pre><span></span><code><span class="n">xx</span><span class="p">,</span><span class="n">yy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">200</span><span class="p">),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">200</span><span class="p">))</span>

<span class="n">Z</span> <span class="o">=</span> <span class="p">[</span><span class="n">recall</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span> <span class="k">for</span> <span class="n">weights</span> <span class="ow">in</span> <span class="n">weight_array</span><span class="p">]</span>

<span class="n">nb_frames</span> <span class="o">=</span> <span class="mi">98</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">frames</span><span class="o">=</span><span class="p">[</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Frame</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="p">[</span>
            <span class="n">go</span><span class="o">.</span><span class="n">Heatmap</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">y</span><span class="o">=</span><span class="n">yy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">z</span><span class="o">=</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
            <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
            <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">),</span>
           <span class="p">],</span>
        <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_frames</span><span class="p">)])</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>



<span class="k">def</span><span class="w"> </span><span class="nf">frame_args</span><span class="p">(</span><span class="n">duration</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;frame&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span><span class="p">},</span>
            <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="s2">&quot;immediate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;fromcurrent&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;transition&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span> <span class="s2">&quot;easing&quot;</span><span class="p">:</span> <span class="s2">&quot;linear&quot;</span><span class="p">},</span>
        <span class="p">}</span>

<span class="n">sliders</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">},</span>
                <span class="s2">&quot;len&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
                <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;steps&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="n">f</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">),</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">frames</span><span class="p">)</span>
                <span class="p">],</span>
            <span class="p">}</span>
        <span class="p">]</span>

<span class="c1"># Layout</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Change in Decision Boundary with Weight Update&#39;</span><span class="p">,</span>
         <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
         <span class="n">scene</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">zaxis</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">6.8</span><span class="p">],</span> <span class="n">autorange</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">aspectratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="p">),</span>
         <span class="n">updatemenus</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;buttons&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">50</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;&amp;#9654;&quot;</span><span class="p">,</span> <span class="c1"># play symbol</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="kc">None</span><span class="p">],</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;&amp;#9724;&quot;</span><span class="p">,</span> <span class="c1"># pause symbol</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">],</span>
                <span class="s2">&quot;direction&quot;</span><span class="p">:</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;r&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">:</span> <span class="mi">70</span><span class="p">},</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;buttons&quot;</span><span class="p">,</span>
                <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">}</span>
         <span class="p">],</span>
         <span class="n">sliders</span><span class="o">=</span><span class="n">sliders</span><span class="p">,</span>
    <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>As you can see, the decision boundary was initially in the right spot but with reversed thresholds, and with changing epochs it flipped.</p>
<h2 id="4-linear-separability">4. Linear Separability</h2>
<h3 id="41-introduction">4.1 Introduction</h3>
<p>As we saw just now, in the visualization section, a Perceptron tries to draw a line between the two classes of data. That is for 2D (or two input features). For 3D (three input features, it will draw a plane to separate out the two classes.</p>
<p>Now for multiclass output, there will be multiple output neuron and each will have a decision boundary that will separate out the different classes(see figure):</p>
<p><img alt="" src="../perceptron_multiclass.png" /></p>
<p>Figure 3: Multiclass Classification by a perceptron.</p>
<p>Now it is evident that the data should be linearly separable among each class for a perceptron to work properly.</p>
<h3 id="42-the-perceptron-convergence-theorem">4.2 The Perceptron Convergence Theorem</h3>
<p>The Perceptron Convergence theorem proved by Rosenblatt in 1962, states that:</p>
<p><strong><em>"given a linearly separable data, the perceptron will converge to a solution within \(1/ \gamma^2\) iterations, where \(\gamma\) is the distance between the separating hyperplane and the closest datapoint to it."</em></strong></p>
<p>However there are some assumptions about it:
1. The data should be linearly separable.
2. For every input vector \(x\), \( \mid  \mid x \mid  \mid \) is bound by some constant R. In our proof we will assume \( \mid  \mid x \mid  \mid  \leq 1\).
3. Also the learning rate is chosen to be 1.</p>
<p>The point being, if the data is linearly separable, irrespective of the constant \( \mid  \mid x \mid  \mid \) is bound by or the value of learning rate, the perceptron will converge to the solution in finite iterations(i.e, it will find the solution).</p>
<p>You can see the proof of this theorem <a href="/notes/perceptron-convergence-theorem">here</a></p>
<!-- Now to the proof,

We know that the data is linearly separable, which means there exists a set of weights which represent the the seperating hyperplane. Let's say these weights are \\(w^*\\).

Our learning algorithm tries to find some vector \\(w\\) that is parallel to \\(w^*\\) or as close as possible. To see if the vectors are parallel we use the inner product (also called the dot product) \\(w^* \cdot w \\).

So

$$ w^* \cdot w =  \mid  \mid w^* \mid  \mid  \   \mid  \mid w \mid  \mid cos\theta \tag{23} $$

now if two vectors are parallel the angle is \\(0 \\), and \\(\cos{0}=1 \\) and so the inner product is maximum. **If we show that after each update \\(w^* \cdot w \\) increases, we have shown that the perceptron converges.**

However we need to be a bit more careful as \\(w^* \cdot w \\) can also increase if \\(w \\) increases, we also need to check the length of \\(w \\) down't increase too much.

Keeping all that in mind, let's move on.

Suppose at the \\(i^{th} \\) iteration of the algorithm, the network sees a particular input vector \\(x \\) that has a target \\(t \\), but the output was \\(y \\). 

Now, if the output was wrong, then

 $$ (t-y)(w^{(i-1)} \cdot x) < 0 \tag{24} $$

e.g, if the target was 1 and output was 0, then,


$$t-y = 1$$ 

and


$$w^{(i-1)} \cdot x < 0$$


$$\implies (t-y)(w^{(i-1)} \cdot x) < 0$$

or if the target was 0 and output was 1, then,


$$t-y=-1$$

and


$$w^{(i-1)} \cdot x > 0$$


$$\implies (t-y)(w^{(i-1)} \cdot x) < 0$$

Now that there is error, the weights need to be updated according to Equation 4, which means:


$$ w^{(i)} = w^{(i-1)} - \eta (y-t)x \tag{25} $$

Side Note: *Please clear it that the above equations have been generalised as \\(w^{(i)} \\) is not a single weight, but a vector of weights to a neuron from the input nodes at \\(i^{th} \\) iteration and \\(x \\) is not a single input but the input vector(including the bias input), \\(y \\) and \\(t \\) are output and target of a single neuron and the symbol \\(\cdot \\) represents inner product of two vectors.*

Coming back to above equation, our proof assumes the learning rate of 1 and let's use \\(t-y \\) instead of \\(y-t \\)(which changed sign, ofcourse!).

 $$\implies w^{(i)} = w^{(i-1)} + (t-y)x \tag{26}$$

Now to show that \\(w^* \cdot w \\) increases with iterations, using Equation 26,

 $$ w^* \cdot w^{(i)} = w^* \cdot (w^{(i-1)} + (t-y)x)\\ =w^* \cdot w^{(i-1)} + w^* \cdot (t-y)x\\ =w^* \cdot w^{(i-1)} + (t-y)\big(w^* \cdot x\big)\\ \tag{27} $$

Taking a little detour to explain what \\(w \cdot x \\) is. For that, let's talk about the basic distance formula between a point and a line:

Let a point \\(P(x_0,y_0) \\) be \\(D \\) distance(perpendicular) far from a line \\(ax+by+c=0 \\), then:


$$ D = \frac{\mid ax_0+by_0+c \mid}{\sqrt{a^2+b^2}}\\ \implies \pm D\sqrt{a^2+b^2}=  ax_0 +by_0+c\\ \implies \pm D\sqrt{a^2+b^2}= C \cdot V\\ \tag{28}$$
where \\(C \\) is a vector of coefficients of line equation and \\(V \\) is a vector of points\\((x_0,y_0,1) \\)

The above equation can be generalized for higher dimensions as well.

so \\((w^* \cdot x) \\) corresponds to the distance between the example datapoint and the line(hyperplane, in general) determined by the weights vector for each neuron and the two signs in Equation 28 determines what side of the plane the datapoint is located.

and since \\(\gamma \\) is the distance between the decision plane and the datapont closest to it,


$$\mid  w^* \cdot x\mid \geq \gamma \tag{29}$$

The \\(\mid \ \mid \\) sign corresponds to the absolute value as we have seen the distance can be both positive and negative depending on the side of the plane, so to correct for that we use \\((t-y) \\) which will fix the sign as \\(t-y \\) is either 1 or -1 for incorrect outputs.

so,


$$ (t-y)w^* \cdot x \geq \gamma \tag{30}$$

Using the above equation in Equation 27:


$$ w^* \cdot w^{(i)} \geq w^* \cdot w^{(i-1)} + \gamma \tag{31} $$

where \\(\gamma \\) is the distance between the optimal hyperplane defined by \\(w^* \\) and the closest datapoint to it.

So we have proved that \\(w^* \cdot w^{(i)} \\) increases as iterations increase. Now we have to make sure that \\( \mid  \mid w^{(i)} \\) does not increase too much. 

Now according to above equation(Eq. 31), \\(w^* \cdot w^{(i)} \\) always increases by at least \\(\gamma \\) and so after \\(i \\) iterations 


$$w^* \cdot w^{(i)} \geq i\gamma\tag{32}$$

Also,

$$ w^* \cdot w^{(i)} \leq  \mid  \mid w^* \mid  \mid \  \mid  \mid w^{(i)} \mid  \mid  \tag{33} $$

Using Equations 32 and 33,


$$ i\gamma \leq w^* \cdot w^{(i)} \leq  \mid  \mid w^* \mid  \mid \  \mid  \mid w^{(i)} \mid  \mid \\ \implies i\gamma \leq  \mid  \mid w^* \mid  \mid \  \mid  \mid w^{(i)} \mid  \mid $$

Ignoring \\( \mid  \mid w^* \mid  \mid  \\) (why?):

 $$ i\gamma \leq  \mid  \mid w^{(i)} \mid  \mid  \tag{34} $$

and using Equation 26 steps is:


$$ \begin{align}  \mid  \mid w^{(i)} \mid  \mid ^2 &=  \mid  \mid w^{(i-1)} + (t-y)x \mid  \mid ^2\\ &=  \mid  \mid w^{(i-1)} \mid  \mid ^2 + (t-y)^2 \mid  \mid x \mid  \mid ^2+2(t-y)w^{(i-1)} \cdot x \tag{35} \end{align} $$


Now,


$$(t-y)^2 = 1\\   \mid  \mid x \mid  \mid  \leq 1\\  (t-y)(w^{(i-1)} \cdot x) < 0 \text{}$$

So,


$$ (t-y)^2 \mid  \mid x \mid  \mid ^2+2(t-y)w^{(i-1)} \cdot x \leq 1 $$

Using the above equation in Equation 35,


$$  \mid  \mid w^{(i)} \mid  \mid ^2 \leq  \mid  \mid w^{(i-1)} \mid  \mid ^2 + 1 \tag{36} $$

Which shows \\( \mid  \mid w^{(i)} \mid  \mid ^2 \\) does not increase by much. Actually the equality hardly holds in the above equation. It is actually always less than that(of course given, \\( \mid  \mid x \mid  \mid  \leq 1 \\)).

Now according to Equation 36, after i iterations,

$$ \mid  \mid w^{(i)} \mid  \mid ^2 \leq i \tag{37} $$

Using Equation 34 and the Equation 37,


$$ i\gamma \leq  \mid  \mid w^{(i)} \mid  \mid  \leq \sqrt{i}\\ \implies i \leq \frac{1}{\gamma^2} \tag{37}$$

So within \\(1/\gamma^2 \\) iterations, the algorithm must have converged.

We have shown that if the data is linearly separable, then the algorithm will converge, and the time it will take is a function distance between the separating hyperplane and the nearest point. This is actually called **margin**.

***Note: The perceptron stops learning as soon as it gets all the data correctly classified, and so there is no guarantee that it will find the largest margin, just that if there is a separator, it will find it.*** -->

<h3 id="43-linear-inseparability-examplexor-logic">4.3 Linear Inseparability Example(XOR Logic)</h3>
<p>Let's try to learn the XOR Logic. Let's prepare the dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<p>Let's first visualize the data points ourselves.</p>
<div class="highlight"><pre><span></span><code><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">))</span> 
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>There is no line we can draw to separate the two classes. Let's see how the perceptron behaves.</p>
<div class="highlight"><pre><span></span><code><span class="n">W</span><span class="p">,</span> <span class="n">weight_array</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="n">T</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">save_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">364</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">xx</span><span class="p">,</span><span class="n">yy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">200</span><span class="p">),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">200</span><span class="p">))</span>

<span class="n">Z</span> <span class="o">=</span> <span class="p">[</span><span class="n">recall</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span> <span class="k">for</span> <span class="n">weights</span> <span class="ow">in</span> <span class="n">weight_array</span><span class="p">]</span>

<span class="n">nb_frames</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">frames</span><span class="o">=</span><span class="p">[</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Frame</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="p">[</span>
            <span class="n">go</span><span class="o">.</span><span class="n">Heatmap</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">y</span><span class="o">=</span><span class="n">yy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">z</span><span class="o">=</span><span class="n">Z</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
            <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
            <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">),</span>
             <span class="p">],</span>
        <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> 
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_frames</span><span class="p">)])</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">))</span>



<span class="k">def</span><span class="w"> </span><span class="nf">frame_args</span><span class="p">(</span><span class="n">duration</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;frame&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span><span class="p">},</span>
            <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="s2">&quot;immediate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;fromcurrent&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;transition&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;duration&quot;</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span> <span class="s2">&quot;easing&quot;</span><span class="p">:</span> <span class="s2">&quot;linear&quot;</span><span class="p">},</span>
        <span class="p">}</span>

<span class="n">sliders</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">},</span>
                <span class="s2">&quot;len&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
                <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;steps&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="n">f</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">),</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">frames</span><span class="p">)</span>
                <span class="p">],</span>
            <span class="p">}</span>
        <span class="p">]</span>

<span class="c1"># Layout</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
         <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Change in Decision Boundary with Weight Update&#39;</span><span class="p">,</span>
         <span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
         <span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
         <span class="n">scene</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">zaxis</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">6.8</span><span class="p">],</span> <span class="n">autorange</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">aspectratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="p">),</span>
         <span class="n">updatemenus</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;buttons&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">50</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;&amp;#9654;&quot;</span><span class="p">,</span> <span class="c1"># play symbol</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="kc">None</span><span class="p">],</span> <span class="n">frame_args</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span>
                        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;&amp;#9724;&quot;</span><span class="p">,</span> <span class="c1"># pause symbol</span>
                        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;animate&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">],</span>
                <span class="s2">&quot;direction&quot;</span><span class="p">:</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span>
                <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;r&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">:</span> <span class="mi">70</span><span class="p">},</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;buttons&quot;</span><span class="p">,</span>
                <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">}</span>
         <span class="p">],</span>
         <span class="n">sliders</span><span class="o">=</span><span class="n">sliders</span><span class="p">,</span>
    <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>as you can see, the perceptron fails to find a linear boundary and dangles between the two sides. So even a simple function like XOR cannot be learned by the perceptron. This discovery halted the neural network development for at least 20 years. There is an obvious solution though(Multiple layers, but we'll get to that at its own time!).</p>
<h3 id="44-higher-dimensions-is-the-answer">4.4 Higher dimensions is the answer?</h3>
<p>Since we cannot draw a line in the XOR dataset to separate it, how about taking the data to a higher dimension(the 3rd dimension in our case)? We can find a plane to separate the two classes in 3D. We will add a dimension in such a way that it does not change the data when looked in the \((x,y) \) plane, but moves point \((0,0) \) along the third dimension.</p>
<p>The truth table can be like:</p>
<table>
<thead>
<tr>
<th>Input 1</th>
<th>Input 2</th>
<th>New dimension</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">z</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Plot Title&quot;</span><span class="p">,</span>

    <span class="n">xaxis</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="n">XAxis</span><span class="p">(</span>
        <span class="n">title</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">Title</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="s1">&#39;x Axis&#39;</span><span class="p">,</span>
            <span class="n">font</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">family</span><span class="o">=</span><span class="s1">&#39;Courier New, monospace&#39;</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#7f7f7f&#39;</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;y Axis Title&quot;</span><span class="p">,</span>
    <span class="n">font</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">family</span><span class="o">=</span><span class="s2">&quot;Courier New, monospace&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#7f7f7f&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<p>we can now easily see a plane separating the two kinds, just by lifting one point into the third dimension. Also if you rotate the figure to see the input2 and input1 as the y-axis and x-axis, you can see the exact same plot as before. </p>
<p>Now let's train a model and check the accuracy.</p>
<div class="highlight"><pre><span></span><code><span class="n">W</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">364</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<pre><code>Iteration: 0
Output:
[[ True]
[False]
[False]
[False]]
Accuracy: 0.25
Iteration: 1
Output:
[[ True]
[ True]
[ True]
[ True]]
Accuracy: 0.5
Iteration: 2
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 3
Output:
[[False]
[ True]
[ True]
[ True]]
Accuracy: 0.75
Iteration: 4
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 5
Output:
[[ True]
[ True]
[ True]
[ True]]
Accuracy: 0.5
Iteration: 6
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 7
Output:
[[False]
[ True]
[ True]
[ True]]
Accuracy: 0.75
Iteration: 8
Output:
[[False]
[ True]
[ True]
[ True]]
Accuracy: 0.75
Iteration: 9
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 10
Output:
[[False]
[ True]
[ True]
[ True]]
Accuracy: 0.75
Iteration: 11
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 12
Output:
[[ True]
[ True]
[ True]
[ True]]
Accuracy: 0.5
Iteration: 13
Output:
[[False]
[False]
[False]
[False]]
Accuracy: 0.5
Iteration: 14
Output:
[[False]
[ True]
[ True]
[ True]]
Accuracy: 0.75
Iteration: 15
Output:
[[False]
[ True]
[ True]
[False]]
Accuracy: 1.0
Iteration: 16
Output:
[[False]
[ True]
[ True]
[False]]
Accuracy: 1.0
Iteration: 17
Output:
[[False]
[ True]
[ True]
[False]]
Accuracy: 1.0
Iteration: 18
Output:
[[False]
[ True]
[ True]
[False]]
Accuracy: 1.0
Iteration: 19
Output:
[[False]
[ True]
[ True]
[False]]
Accuracy: 1.0
</code></pre>
<p>let's plot the decision boundary for this one.</p>
<div class="highlight"><pre><span></span><code><span class="n">weights</span><span class="o">=</span><span class="n">W</span>
<span class="n">xx</span><span class="p">,</span><span class="n">yy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">10</span><span class="p">),</span>
                  <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span>
<span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Surface</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">yy</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span><span class="n">showscale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">,</span><span class="n">opacity</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">z</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="n">colorscale</span><span class="o">=</span><span class="s2">&quot;Viridis&quot;</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p>as you can see, by increasing a dimension, we were able to classify what seemed to be impossible before. Infact, it is always possible to classify two classes with a linear function, provided we project the data into correct set of dimensions. It will be explored in <em>kernel classifiers</em>, which are the basis of Support Vector Machines.</p>
<p>For now, we have learned how to get around the linear barrier of the perceptrons(by getting into higher dimensions and multi-layer, which will be discussed later). </p>
<p>Some Notes for Data Preparation:
1. It is better to normalize the inputs as well as the target values(especiallly for regression).
2. Normalize both train and test inputs with the same mean and variance.
3. Perform a basic form <em>feature selection</em> by trying out the classifier by missing out different feature columns one at a time as see if it can increase the accuracy. If a missing out feature does improve the results, then leave it out completely and try missing out others as well.</p>
<p>The above method is actually a simplistic way of testing for the correlation between output and each of its features.</p>
<ol>
<li>We can also consider <em>dimensionality reduction</em>, more on it later.</li>
</ol>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Murtaza Nazir
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
      
    
  </body>
</html>