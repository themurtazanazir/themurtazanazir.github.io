<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.55.6" />

<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">

<link rel="alternate" type="application/rss&#43;xml" href="/docs/index.xml">

<link rel="shortcut icon" href="/assets/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/assets/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/assets/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/assets/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/assets/favicons/android-96x196.png" sizes="96x196">
<link rel="icon" type="image/png" href="/assets/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/assets/favicons/android-192x192.png"sizes="192x192">

<title>Search</title>
<meta property="og:title" content="Search" />
<meta property="og:description" content="Awesome Description of this site.
" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://themurtazanazir.github.io" />
<meta property="og:site_name" content="https://themurtazanazir.github.io" />

<meta itemprop="name" content="Search">
<meta itemprop="description" content="Awesome Description of this site.
">
<meta name="google-site-verification" content="s0WiwrbDw1_pBMDht88L84Om9X-4_aYhBUIlcRehLQc" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Search"/>
<meta name="twitter:description" content="Awesome Description of this site.
"/>

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/palette.css">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="stylesheet" href="/assets/css/dark-codes.css">


<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>
  
  
  <script type="text/javascript" async 
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?
config=TeX-AMS-MML_HTMLorMML"></script>

<!-- <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_CHTML">
</script> -->
<!-- for plotly graphs -->



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-167489245-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-167489245-1');
</script>





</head>

  

  <body class="td-section">
    <header>
        <nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
            <span class="navbar-logo"></span><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149v0 0zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><path style="fill:#5b7fc0" d="M198.8952 225.1043h122.6266v13.8671H198.8952z"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><path style="fill:#d95140" d="M198.8952 170.69h122.6266v13.8671H198.8952z"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><path style="fill:#56a55c" d="M199.3456 279.5436h122.6266v13.8671H199.3456z"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032-4.13-4.1299-6.4032-9.6186-6.4056-15.4628.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><path style="fill:#f1bc42" d="M198.8952 333.6497h122.6266v13.8671H198.8952z"/></g></g></svg>
<span class="text-uppercase font-weight-bold">Murtaza Nazir</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="https://github.com/themurtazanazir" target="_blank"><span>GitHub</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="/about" ><span>About</span></a>
      </li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="/notes" ><span>Notes</span></a>
      </li>
      


		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
        </div>

        

  
</nav>
</header>

<script>
$(document).ready(function() {
  var url = "https://api.github.com/search/repositories?q=themurtazanazir/themurtazanazir.github.io";
  fetch(url, { 
      headers: {"Accept":"application/vnd.github.preview"}
  }).then(function(e) {
    return e.json()
  }).then(function(r) {
     console.log(r.items[0])
     stars = r.items[0]['stargazers_count']
     forks = r.items[0]['forks_count']
     $('#stars').text(stars + " Stars")
     $('#forks').text(forks + " Forks")
  });
});
</script>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 d-none d-xl-block col-xl-2 td-toc d-print-none">
              <nav id="TableOfContents">
                Table Of Contents
                <ul>
              <li><ul id="TOC">
                <!-- Links will be appended here-->
              </ul></li>
              </ul></nav>
          </div>
          <div class="col-xl-2 td-sidebar d-print-none">
            <div id="td-sidebar-menu" class="td-sidebar__inner">  
  <form class="td-sidebar__search d-flex align-items-center">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
    <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type="button" data-toggle="collapse" data-target="#td-section-nav" aria-controls="td-docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    </button>
  </form>  
  <nav class="collapse td-sidebar-nav pt-2 pl-4" id="td-section-nav">
<ul class="td-sidebar-nav__section pr-md-3">
  <li class="td-sidebar-nav__section-title">
    <a  href="/notes" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Notes</a>
  </li><ul>
    <li class="collapse show" id="notes">
        <ul class="td-sidebar-nav__section pr-md-3">
          <li class="td-sidebar-nav__section-title">
            <a href="/notes/linear_algebra/vectors-linear-combinations" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Vectors, Linear Combinations, Eliminations</a>
          </li>
          <ul><li class="collapse show" id="">
              <a class="td-sidebar-link td-sidebar-link__page " id="m-notes-vectors-linear-combinations-eliminations-vectors" href="/notes/linear_algebra/vectors-linear-combinations#vectors">Vectors</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-vectors-linear-combinations-eliminations-linear-equations" href="/notes/linear_algebra/vectors-linear-combinations#linear-equations">Linear Equations</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-vectors-linear-combinations-eliminations-solving-linear-equations" href="/notes/linear_algebra/vectors-linear-combinations#solving-linear-equations">Solving Linear Equations</a>
              </li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/notes/neural_networks/multi-layer-perceptron" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">The Multi-Layer Perceptron</a>
          </li>
          <ul><li class="collapse show" id="">
              <a class="td-sidebar-link td-sidebar-link__page " id="m-notes-the-multi-layer-perceptron-training-the-mlp" href="/notes/neural_networks/multi-layer-perceptron#2-training-the-mlp">Training the MLP</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-the-multi-layer-perceptron-the-backpropagation-algorithm" href="/notes/neural_networks/multi-layer-perceptron#232-the-backpropagation-algorithm">The Backpropagation Algorithm</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-the-multi-layer-perceptron-speeding-up-code" href="/notes/neural_networks/multi-layer-perceptron#25-speeding-up-the-code">Speeding Up Code</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-the-multi-layer-perceptron-network-improvements" href="/notes/neural_networks/multi-layer-perceptron#3-improvements-for-the-network">Network Improvements</a>
              </li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/notes/neural_networks/perceptron" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Maths Behind Perceptron</a>
          </li>
          <ul><li class="collapse show" id="">
              <a class="td-sidebar-link td-sidebar-link__page " id="m-notes-maths-behind-perceptron-the-perceptron" href="/notes/neural_networks/perceptron#the-perceptron">The Perceptron</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-maths-behind-perceptron-implementation" href="/notes/neural_networks/perceptron#2-implementation">Implementation</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-maths-behind-perceptron-speeding-up-computations" href="/notes/neural_networks/perceptron#24-speeding-up-the-code">Speeding Up Computations</a>
              </li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/notes/neural_networks/perceptron-convergence-theorem" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Perceptron Convergence Theorem</a>
          </li>
          <ul><li class="collapse show" id="">
              <a class="td-sidebar-link td-sidebar-link__page " id="m-notes-perceptron-convergence-theorem-planes" href="/notes/neural_networks/perceptron-convergence-theorem#planes">Planes</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-perceptron-convergence-theorem-planes-with-perceptron" href="/notes/neural_networks/perceptron-convergence-theorem#planes-with-perceptron">Planes with Perceptron</a><a class="td-sidebar-link td-sidebar-link__page " id="m-notes-perceptron-convergence-theorem-the-proof" href="/notes/neural_networks/perceptron-convergence-theorem#the-proof">The Proof</a>
              </li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/notes/extras" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Extras</a>
          </li>
          <ul><li class="collapse show" id="">
              <a class="td-sidebar-link td-sidebar-link__page " id="m-notes-extras-tags-page" href="/tags">Tags Page</a>
              </li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/about" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">About</a>
          </li>
          <ul><li class="collapse show" id=""></li></ul>
    </ul>
  </nav>
</div>

            </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            <nav aria-label="breadcrumb" class="d-none d-md-block d-print-none">

              <!-- changed here to remove extra titile -->
	      <!-- <ol class="breadcrumb spb-1">
                <li class="breadcrumb-item active" aria-current="page">
	          <a href="/search/">Search</a>
                </li>
	      </ol> -->
           </nav>
           <div class="td-content">
	      <input class="form-control td-search-input" type="search" name="q" id="search-input" placeholder="&#xf002 Search this site…"  style="margin-top:5px" autofocus>
<i style="color:white; margin-right:8px; margin-left:5px" class="fa fa-search"></i>

<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>

<ul id="search-results"></ul>

<script>
	window.data = {
		
				
					
					
					"notes-linear-algebra-index": {
						"id": "notes-linear-algebra-index",
						"title": "Linear Algebra",
						"categories": "",
						"url": " /notes/linear_algebra/index",
						"content": "Introduction to Vector Spaces and Sub Spaces, Rank and Invertibility\n\nThis post provides an introduction to the vector sapces and subspaces. It goes on to define column space and null space. With that it defines rank, and inveribility.. . .  read more\n\n\n\n\nVectors, Linear Combinations, Eliminations\n\nBasics of Linear Algebra. . .  read more"
					}
					
				
		
				
					,
					
					"notes-linear-algebra-vector-spaces-and-subspaces": {
						"id": "notes-linear-algebra-vector-spaces-and-subspaces",
						"title": "Introduction to Vector Spaces and Sub Spaces, Rank and Invertibility",
						"categories": "",
						"url": " /notes/linear_algebra/vector-spaces-and-subspaces",
						"content": "Introduction to Vector Spaces and Sub Spaces, Rank and Invertibility\n\nIntroduction\n\nThis article will dive deep into Vector Spaces, Subspaces, Column Spaces, Null Space, Span, Rank, Invertibility and much more.\n\nVector Spaces\n\nA vector space is a collection of vectors where each vector can be defined as a linear combination of all other vectors. It can also be defined as “if \\(n\\) vectors are in a space, then all the linear combinations of all these vectors are also in that space”.\n\ne.g: for 2-D vectors, the \\(xy\\) plane is a space. It contains all the 2-D vectors. All of these vectors can be represented as a linear combination of all other vectors(some scalar multipliers might be zero).\n\nThe above space is denoted by \\(\\mathbb{R}^2\\) and is called the real space in two dimensions(or simply the two dimensional space). It the biggest space possible for two dimensional real vectors. If we include complex numbers as well, then that space will be \\(\\mathbb{C}^2\\).\n\nSimilarly, \\(\\mathbb{R}^1\\), \\(\\mathbb{R}^3\\), \\(\\mathbb{R}^4\\), \\(\\mathbb{R}^n\\) are the real spaces in their respective dimensions. These contain all the real respective-dimensional vectors.\n\nSo if, for example, we have two vectors\n\n\n\nthen\n\n\n\nBut any vector in \\(\\mathbb{R}^2\\) is not in the \\(\\mathbb{R}^5\\) as no linear combination of 5-dimensional vectors can form a 2-dimesional vector.\n\nBased on the that every space must have a zero vector (when all the scalar multipliers in a linear combination are zero).\n\nWe can even extend the concept of spaces from traditional “column vectors” to other “vectors”. Basically, we need a multiplication by a scalar with a “vector” keep the resulting “vector” in that same space. Also sum of two “vectors” in a space should also be in the same space.\n\n\n  Note: A space may not necessarily contain column vectors. In the definition of vector space, vector addition, \\(v_1 + v_2\\), and scalar mutiplication, \\(cv\\), should follow the following eight rules:\n  \n    \\(v_1 + v_2 = v_2 + v_1\\)\n    \\(v_1 + (v_2 + v_3) = (v_1 + v_2) + v_3\\)\n    There exists a zero vector \\(0\\) such that \\(v+0 = v\\).\n    There is a unique vector \\(-v\\), for each vector \\(v\\), such that \\(v+(-v)=0\\).\n    Multiplication of vector \\(v\\) by unity, 1 ,scalar, does not change the vector,i.e \\(1v = v\\)\n    \\((c_1c_2)v = c_1(c_2v)\\)\n    \\(c(v_1 + v_2) = cv_1 + cv_2\\)\n    \\((c_1 + c_2)v = c_1v + c_2v\\)\n  \n\n\nAny “vectors” following those eight rules can have a concept of spaces in them. For example: matrices. Matrices(of same dimensions) follow all the above rues and hence concept of spaces is possible.\n\nAll real \\(3 \\times 4\\) matrices form a space. Any two such shaped matrices can be added to give the same shaped matrix. Any such shaped matrix can be multipied(with a scalar, ofcourse!) to give the same shaped matrix again. It also incudes the zero matrix. This space can be called \\(\\mathbb{R}^{3 \\times 4}\\)\n\nWe can also consider all real functions. They will also form a space. Also has zero function. A function space is infinite-dimensional.\n\nIn both above examples the eight conditions are also easily checked.\n\nWe saw multiple dimensional spaces but there is another special dimensional space, the zero dimensional space \\(\\mathbb{Z}\\). By the simple definition if it has zero dimensions, it means it has no components and so one might think there is no vector. But it only contains exactly one vector.\n\nSo at many times we can think matrices and functions as vectors but mostly we refer to vectors when we mean column vectors and with that let’s talk about subspaces.\n\nSubspaces\n\nA subspace is a space inside another space. This subspace is a part of the whole space as well as satisfies all the criteria to be called a space itself.\n\nFor example, in three dimensional vector space, any plane passing through origin is a subspace of \\(\\mathbb{R}^3\\).\n\nEvery vector in that plane is a linear combination of other vectors in the same plane. It is also passing via origin and so has the zero vector in it. One thing to note is that a plane in three-dimensional space is not \\(\\mathbb{R}^2\\). The vectors are in \\(\\mathbb{R}^3\\) as they have three components, they just lie on a plane.\n\nAlso note that any plane that does not pass through the origin is not a subspace as it does not account for the combination when all the multipliers of a linear combination are zero.\n\nApart from all the planes passing through origin, the whole \\(\\mathbb{R}^3\\) is also a subspace of itself!. The list of all subspaces of \\(\\mathbb{R}^3\\) is:\n\n  The whole space itself.\n  Any plane passing through origin.\n  Any line passing through origin.\n  The Zero Vector.\n\n\nJust like \\(\\mathbb{R}^3\\), \\(\\mathbb{R}^2\\) also has its subspaces: any line passing through origin,for example.\n\nWe also talked about matrices forming spaces. So they can also form subspaces. For example in the vector space of all \\(4 \\times 4\\) real matrices i.e \\(\\mathbb{R}^{4 \\times 4}\\),a subspace will be all the \\(4 \\times 4\\) diagonal real matrices as all linear combinations of these matrices will also reult in a \\(4 \\times 4\\) real diagonal matrix. We can also have a subspace of traiangular matrices. Further more, diagonal matrices are the subspaces of triangular matrix space(of the same dimensions!).\n\nAlso, all these spaces also have the Zero matrix in them, which is also an important check for a space.\n\nColumn Space of \\(A\\): \\(C(A)\\)\n\nA column space is related to a matrix. A column space of a matrix \\(A\\) is, the space containing only all linear combinations of columns of a matrix. It is represented as \\(C\\left(A\\right)\\) It is explained in the context of solving the equation:\n\n\n\nFor all the possible \\(\\mathbf{x}\\), \\(A\\mathbf{x}\\) is linear combinations of columns of \\(A\\).\n\ne.g: If\n\n\n\nthen,\n\n\n\nBy our definition of matrix vector multiplication, in the previous chapter:\n\n\n\nSo for all \\(\\mathbf{x}\\), \\(A\\mathbf{x}\\) is all the linear combinations of columns of \\(A\\). So \\(A\\mathbf{x}\\) represents the whole column space, for all \\(\\mathbf{x}\\). For a specific \\(\\mathbf{x}\\), say \\(\\mathbf{x_1}\\) we have a specific vector \\(A\\mathbf{x_1}\\) which lies in the column space of \\(A\\).\n\nSo for \\(A\\mathbf{x} = \\mathbf{b}\\) to have any solution, \\(\\mathbf{b}\\) has to be in the column space of \\(A\\). Otherwise there is no solution. If \\(\\mathbf{b}\\) is in \\(C\\left(A\\right)\\), then the vector of multipliers of that combination is the solution of this equation.\n\nFor any matrix of shape \\(m\\) by \\(n\\), each column has \\(m\\) components, so the column space of that matrix is a subspace of \\(\\mathbb{R}^m\\).\n\nFor our example above the column space will form a plane in \\(\\mathbb{R}^3\\) passing via origin.\n\nusing Plotly\n\n\n# using multiple values for x\nx= [[i;j] for i=-0.7:0.01:0.7,j=-0.7:0.01:0.7]\n\n# create matrix A\nA = [2 3; 6 1; -1 8]\n# calculate the linear combination for each vector (x_1,x_2)\nlinear_combos = [A*xx for xx in x]\n\n#fetch the x, y and z cordinates from each vector\nx_s = [xx[1] for xx in linear_combos]\ny_s = [xx[2] for xx in linear_combos]\nz_s = [xx[3] for xx in linear_combos]\n\n# plot column 1\ntrace1 = scatter3d(x=[0, A[1,1]], y=[0, A[2,1]], z=[0, A[3,1]], mode=\"lines\", line=attr(width=5), name=\"vector 1\")\n#plot column 2\ntrace2 = scatter3d(x=[0, A[1,2]], y=[0, A[2,2]], z=[0,A[3,2]], mode=\"lines\", line=attr(width=5), name=\"vector 2\")\n# plot the combinations\ntrace3 = surface(x=x_s, y=y_s, z=z_s, opacity=0.8, showscale=false, name=\"Plane\")\n\np = plot([trace1,trace2,trace3], Layout(scene_camera=attr(eye=attr(x=1.5, y=1.2, z=1)), title=\"Column Space of a matrix\"))\n\n\n\n\n\nThe plane represents all the linear combinations of these two vectors lie on that plane which also passes through the origin. It is the column space of the matrix. It is a subspace of the whole \\(\\mathbb{R}^3\\) space. For all the vectors \\(\\mathbf{b}\\) lying in that plane, \\(A\\mathbf{x} = \\mathbf{b}\\) has solution. But for those \\(\\mathbf{b}\\) which do not lie in that plane (i.e are not in the column space), have no solution.\n\n\n  Span: \nNow instead of just columns we can have a set of vectors \\(V\\) and their linear combinations form a space \\(VV\\). This span is the smallest space that contains all the linear combinations of these vectors. This can also be said as The subspace \\(VV\\) is the span of set \\(V\\). So the columns “span” the column space.\n\n\nSo, as per above observations, it entirely depends on the vector \\(\\mathbf{b}\\) to have a solution to \\(A\\mathbf{x}=\\mathbf{b}\\). If the vector \\(\\mathbf{b}\\) is in the column space of \\(A\\) or not. But there is one vector for \\(\\mathbf{b}\\) we would always have solution(s) for. The only vector(of the same dimension) which lies in all subspaces. The zero vector.\n\nThat means, \\(A\\mathbf{x} = 0\\) will always have solution(s). (\\(0\\) here is a zero vector, not a scalar.)\n\nThis gives introduction to another important subspace called the Null Space.\n\nNull Space of \\(A\\): \\(N(A)\\)\n\nWe will now deal with special equations where the right hand side is always a zero vector, i.e \\(\\mathbf{b} =0 \\).\n\nLet’s look at the possible solutions of \\(A\\mathbf{x} = 0\\):\n\n\n  \\(\\mathbf{x} = 0\\) is always a solution to it.\n  If \\(\\mathbf{x_1}\\) is a solution, then so is \\(c_1\\mathbf{x_1}\\), \\(c_1\\) being a scalar.\n\n\nIf\n\n\nthen\n\n\n\n\n  If \\(\\mathbf{x_1}\\) and \\(\\mathbf{x_2}\\) are two solutions, then \\(x_1 + x_2\\) is also a solution. It can be shown as:\n\n\nIf \\(\\mathbf{x_1}\\) and \\(\\mathbf{x_2}\\) are solutions, then:\n\n\n\nand\n\n\n\nand so,\n\n\n\nso \\(\\mathbf{x_1} + \\mathbf{x_2}\\) is also a solution.\n\n\n  By the above two points we can show that all the linear combinations of the solutions are also solutions to \\(A\\mathbf{x} = 0\\).\n\n\nSo we can conclude the solutions of \\(A\\mathbf{x} = 0\\) form a subspace. This subspace is called the Null Space of matrix \\(A\\). It is denoted by \\(N(A)\\).\n\nIf the matrix \\(A\\) is \\(m\\) by \\(n\\), then the null space, \\(N(A)\\) is a subspace of \\(\\mathbb{R}^n\\) (while the column space, \\(C(A)\\), was in \\(\\mathbb{R}^m\\)).\n\nFinding the Null Space\n\nThe column space is simply the space of all linear combinations of columns of \\(A\\) and the columns are known. But for null space, we need to find the solutions.\n\nWe know that the solutions were found by elimination. We will do the same, but with some special extensions. We have used elimination on the square matrices (i.e \\(m\\) equations \\(m \\) variables, but let’s generalize it to rectangluar matrices).\n\nLet’s say we have two equations and two variables:\n\n\n\nIf we eliminate, we get:\n\n\n\nHere \\(x_2\\) is called the free variable. The above system of equations is equivalent to just one of the above eqautions(both are same!).\n\nWe can set the free variable to anything and get corresponding \\(x_1\\) for that solution. Preferably, we set \\(x_2=1\\), and so \\(x_1 = -7\\).\n\nThis solution \\((-7,1)\\) is a specific solution to the equation above. The nullspace is all the linear combinations of this solution. Since we are having linear combinations of just one vector, it will result in a line through origin. That line represents the nullspace of the equation system.\n\nSo, \\(c\\begin{bmatrix}-7 \\ 1\\end{bmatrix}\\) is the nullspace of this matrix for all scalars, \\(c\\).\n\nAnother Example\n\nLet’s say we have two equations and four variables, e.g:\n\n\n\nIt can be written in matrix form as, \\(A\\mathbf{x} = 0\\), where\n\n\n\nand\n\n\n\nSo, essentially we are trying to find the nullspace of \\(A\\). We will proceed with elimination, but note that we need not to perform the same elimination on Right Hand Side as it is a Zero vector and it won’t change.\n\nEliminate using the first pivot (bold-face in matrix above):\n\n\n\nAnd now we are done. This is the closest to “upper traingular” system we can get. The Pivots are: 3, -1. The two columns, which have pivots are called pivot columns. The rest of the columns are called free columns.\n\n\n\nThe variables corresponding to the free columns are the free variables, in this case, \\(x_3\\) and \\(x_4\\). Now to get the nullspace, we will first need the specific solutions and then the nullspace will formed by all the linear combinations of those specific solutions.\n\nFor each specific solution, we will set each free variable equal to 1 and all other free varaibles to zero. Since this has two free columns, which means two free variables, we have two specific solutions.\n\nOne will have \\(x_3=1\\),\\(x_4=0\\) and the other will have \\(x_3=0\\), \\(x_4=1\\).\n\nFor specific solution 1,\n\nUse \\(x_3=1,x_4=0\\) in the second row and we get \\(x_2=-9\\). and then backsubstituting \\(x_2,x_3,x_4\\) into row 1, we get \\(x_1 = \\frac{14}{3}\\)\n\nOur first specific solution is \n\nFor second specific solution, we will keep \\(x_3 = 0\\) and \\(x_4 = 1\\).\n\nBack substituting,\n\n\\(x_2 = 10\\) and \\(x_1 = \\frac{-17}{3}\\)\n\nSecond specific solution is \n\nThe nullspace contains all the linear combinations of \\(s_1\\) and \\(s_2\\). If we put these two specific solutions in a matrix.\n\n\n\nWe can also say the nullspace of \\(A\\) was the columnspace of \\(S\\).\n\n\n\nReduced Row Echelon Form\n\nWe most often take a step further from converting the matrix \\(A\\) to upper triangular \\(U\\) during elimination. We convert it into, what’s called, a reduced row echelon form, \\(R\\). It gives us a better view at the nullspace of \\(A\\) which is same as \\(U\\) and as we will see for \\(R\\) as well.\n\nIn this form we do not stop at the upper triangular \\(U\\) form but we remove the elements above the pivots as well. And we also divide each pivot row to make its pivot unity.\n\nIn our above example, we had reduced till upper traingular:\n\n\n\nOur pivots (in bold-face) will eliminate all the elements above them as well. The first pivot has not to change anything. But we can remove the elements above the second pivot.\n\n\n\nNow we have removed the entries, we have to make our pivots unity.\n\n\n\nHere we have reached the reduced row echelon form. The pivot columns form a sub identity matrix. But here is the good part. If we look at our two special solutions,\\(s_1\\) and \\(s_2\\), the free columns seem to have half of the solution. Well actually the negative of the free columns.\n\nIf we show our reduced matrix in the form of this identity and free columns, i.e:\n\n\n\nThen our special solution matrix is:\n\n\n\nLet’s look at one more example, in which I will try to encapsulate all cases this form can have. Let’s have a 3 by 5 matrix and find its nullspace, i.e three equations and 5 variables.\n\n\n\nNow to find it’s null space, we will find it’s special solutions for \\(A\\mathbf{x} = 0\\). For that we will use elimination to convert it into \\(U\\) form. Eliminating using the first pivot (bold-face).\n\n\n\nNow the number at second pivot has become ZERO, which calls for a row exchange, but every element below it is also zero and hence no row to exchange with. So, elimination done? No. This whole column is actually a free column and not a pivot column. The next column to it is the pivot column and \\(-1\\) (bold-face, below) is the second pivot.\n\n\n`\n\nNow going on with the elimination with this pivot, we get:\n\n\n\nNow we have finished the elimination and reached the \\(U\\) phase.\n\n\n  Note: Each column and row can have at most one pivot.\n\n\nAt this point, usually we would check if our right hand side (which was \\(\\mathbf{b}\\)) had zero at the last entry or not \\( -\\) to check for no solution. But in null space, all the RHS are zero, so we don’t need to worry.\n\nSo the pivot columns are column 1 and column 3, and free columns are column 2, column 4 and column 5, which means \\(x_2\\), \\(x_4\\) and \\(x_5\\) are free variables. That means we have three specific solutions, one when \\((x_2, x_4, x_5)=(1,0,0)\\), one when \\((x_2, x_4, x_5)=(0,1,0)\\) and another when \\((x_2,x_4,x_5)=(0,0,1)\\).\n\nBack substitute to find the solution of:\n\n\n\nBack-substituting \\(x_2=1\\), \\(x_4=0\\) and \\(x_5=0\\) to compute \\(s_1\\):\n\n\n  \n    The last equation(row) contributes nothing.\n  \n  \n    The second equation(row) gives \\(x_3 = 0\\)\n  \n  \n    And the first equation gives \\(x_1 = \\frac{-4}{3}\\)\n  \n\n\nand so our first specific solution is:\n\n\n\nBack-substituting \\(x_2=0\\), \\(x_4=1\\) and \\(x_5=0\\) to compute \\(s_2\\):\n\n\n  \n    The last equation(row) contributes nothing.\n  \n  \n    The second equation(row) gives \\(x_3 = 10\\)\n  \n  \n    And the first equation gives \\(x_1 = \\frac{-17}{3}\\)\n  \n\n\nand so our first specific solution is:\n\n\n\nBack-substituting \\(x_2=0\\), \\(x_4=0\\) and \\(x_5=1\\) to compute \\(s_3\\):\n\n\n  \n    The last equation(row) contributes nothing.\n  \n  \n    The second equation(row) gives \\(x_3 = -14\\)\n  \n  \n    And the first equation gives \\(x_1 = \\frac{20}{3}\\)\n  \n\n\nand so our first specific solution is:\n\n\n\nAnd so the null space is all the linear combinations of these three vectors. The null space will be 3-D surface inside a 4-Dimensional space. We can also group these solutions into a matrix \\(S\\), and so \\(N(A) = C(S)\\).\n\n\n\nKeeping this \\(S\\) in mind, we move on to the Row Echelon form of A. Let’s check our \\(U\\) highlighting its pivots.\n\n\n\nReduce the elements above the pivots as well and make pivots unity.\n\n\n\n\n\nAll pivots are Zero and no element above or below the pivots are non-zero. By definition, we have reached the reduced row echelon form.\n\nIf we look at the matrix \\(S\\), there are negative of elements of free columns of \\(R\\) in matrix \\)S\\).\n\nLet me tell you how it relates, if our reduced row echelon form to looks like:\n\n\n\nwhere:\n\n\\(F\\) are the free columns.\n\n are all the zero rows until the end of the matrix.\n\nthen our null solution matrix is:\n\n\n\nwhere \\(I’\\) is the identity matrix of the same size as the number of free columns in \\(R\\).\n\nBut our current example isn’t looking like the form we want, for that we can do column exchanges, but that changes the system and so we need to change the variable vector as well. Let’s first write our full equation:\n\n\n\nin our example,\n\n\n\nIf we want to exchange our 2nd and 3rd column of \\(R\\), we need to exchange our 2nd and 3rd variable as well to preserve the multiplication.\n\n\n\nNotice I have exchanged \\(x_2\\) and \\(x_3\\) as well. Now we have the form .\n\nSo our null matrix should be \n\n\n\nand since there are 3 free columns \\(I’\\) is a 3 \\(\\times\\) 3 identity matrix.\n\n\n\nAnd so our null matrix is:\n\n\n\nand we are done? No. A small change needs to be made. This null matrix corresponds to the changed variable vector, i.e in each column the first entry corresponds to \\(x_1\\), second entry to \\(x_3\\) (not \\(x_2\\)), third entry to \\(x_2\\) (not \\(x_3\\)), fourth entry to \\(x_4\\) and fifth entry to \\(x_5\\). This change was because of the column exchange we did back there.\n\nSo to get back the correct form of the null matrix we exchange the row2 and row 3 of the above matrix, and so:\n\n\n\nAnd now we have finished. These three columns are the special solutions we have to find the whole null space.\n\nHowever it is not necessary, to turn \\(R\\) into the said form and do column exchanges, the \\(R\\) form itself makes the back substitution very easy.\n\nBut if we use the , we must know that sometimes there may not be a bunch of zero rows and so our form might be  which will again have the same solution. The zero rows do not contribute to the nullspace. However if the RHS were not a zero vector, these rows would decide the possibility of no solution.\n\nIf our matrix \\(A\\) is of size \\(m \\times n\\) and,\n\n\n  \n    If \\(n &gt; m\\), i.e more variables than equations(like in our previuos example), we will atleast have \\(n-m\\) free columns (because each row and column can at most have one pivot), so there will be atleast \\(n-m\\) special solutions, which means we will have infinite “non-zero” solutions, which will form a nullspace. These will have a form of   or .\n  \n  \n    If \\(m &gt; n\\), i.e more equations than variables, we will atleast have \\(m-n\\) rows of zeros at the bottom. Since the columns are less than rows, all the columns can be pivots, so it may or may not have any \\(F\\) column. The possible scenarios are  and . In the first case there are special solutions and hence infinite solutions. In the second case, since there is no free column, there is only one vector in nullspace, the zero vector, i.e there is no non-zero null vector.\n  \n  \n    If \\(m=n\\), i.e equal number of equations and variables. It has many possibilities. It may or may not have \\(F\\) and even it may or may not have zero rows. So possibilities are ,  ,  and even . The last case also has just one null vector, the zero vector. If a matrix is able to reduce to the last case, it is said to be invertible. More on it later.\n  \n\n\nI highly recommend you to work on some problems yourself and try to get the feel for this form.\n\nThe Rank of a Matrix\n\nNow we are introducing an important concept for our matrices, the rank of the matrix.\n\nOur matrix defines a linear system. If a matrix is \\(m \\times n\\), that is supposed to be it’s size. But is it it’s true size? Well, what do I mean by true size?\n\nLet’s dig into some basic questions. What did the pivot columns  signify? Why does elimination cause some rows to be Zero? What do free columns signify?\n\nFor that let’s revisit our example of reducing a matrix to reduced row echelon form and finding the pivots.\n\nOur initial matrix was:\n\n\n\nand the reduced row echelon form of \\(A\\) was:\n\n\n\nThe size of \\(A\\) is \\(3 \\times 5\\).\n\nThe last row turned to be zero. It is because it did not add anything new to the system. It was a linear combination of the rows above it. Actually,\n\n\n\nSo the true size of this matrix from the row size is actually 2 not 3.\n\nNow let’s look at pivot columns and free columns. Why was the second column declared as a free column? Because it did not have a pivot. But what does not having a pivot mean? It means this column is a linear combination of all the pivot columns before it.\n\nEvery free column is a linear combination of the pivot columns before them. The special solutions tell us these combinations.\n\n\n\nSo these three columns also don’t provide any new information to the linear system. So the true size of this matrix from the column size is actually 2 not 5.\n\nSo, we can say the true size of this matrix is \\(2 \\times 2\\).\n\nThe number of the pivot columns is the true size of every matrix from the column size. And we can argue that non-zero rows are all the pivot rows. And the number of pivot rows is same as number of pivot columns(becasue a column and a row can have at most one pivot).\n\nSo the number of true columns and true rows is actually the same no matter the size of the matrix and that is called the rank of the matrix.\n\nThe rank of the matrix is defined as the number of pivots.\n\nSo in our example,\n\n\n\nSo if a matrix of size \\(m \\times n\\) has rank \\(r\\), it means it has \\(r\\) pivots and so \\(n-r\\) free columns which means \\(n-r\\) special solutions.\n\nThe concept of Rank is very important and it will pop up every once in a while. We will not go too deep into this concept as we will lose track of what we are doing. We will revisit it’s applications whenever needed. But for now, let’s move on to finding solutions to a linear system.\n\nSolving \\(A\\mathbf{x}=\\mathbf{b}\\)\n\nWe have already solved the form \\(A\\mathbf{x} = \\mathbf{b}\\) for a unique solution. We will revisit these briefly and also include a new method to do it along with for the infinite solutions. We will see how reduced row echelon form, \\(R\\) makes both the solutions easy and see the role of rank in it.\n\nWe know \\(A\\mathbf{x}=\\mathbf{b}\\) is solvable only if \\(\\mathbf{b}\\) is in column space of \\(A\\). We used to reduce this form to \\(U\\mathbf{x} = \\mathbf{b’}\\) and then back substituted. But now we will go ahead and reduce it further to \\(R\\mathbf{x} = \\mathbf{d}\\).\n\nNow \\(R\\) has the general form of . This matrix (\\(R\\) as well as \\(A\\)) has a rank \\(r\\).\n\nIf the matrix is \\(m \\times n\\) and the reduced form turned out to be  or  (i.e no Zero rows and \\(m \\leq n\\)), which means all the rows have a pivot and so the rank of this matrix is \\(r = m \\leq n\\). This is called the full row rank matrix. In this form there is always either 1 or infinte number of solutions to \\(A\\mathbf{x} = \\mathbf{b} (\\text{or } R\\mathbf{x} = \\mathbf{d})\\).\n\nIn case of the reduced form turned out to be  or  (i.e no free columns and \\(n \\leq m\\)), which means all the columns have a pivot and so the rank of this matrix is \\(r = n \\leq m\\). This is called full column rank matrix. This form can have zero or one solution.\n\nThe intersection of these two cases, i.e if a matrix is reduced to , it is an invertible matrix. It’s rank is \\(r=m=n\\). It has exactly one solution. \\(\\mathbf{x} = A^{-1}\\mathbf{b}\\). More on it in a moment.\n\nComing back to the general case, when . We will now augment \\(A\\) and \\(\\mathbf{b}\\) as  and perform elimination on the full matrix to turn it into .\n\n\n\nwhere:\n\n\n  \\(R = EA\\)\n  \\(\\mathbf{d} = E\\mathbf{b}\\)\n  \\(E\\) is the elimination matrix.\n\n\nLet’s talk about the no-solution case first. It is only possible if \\(R\\) has zero rows. If \\(A\\) of size \\(m \\times n\\) has rank \\(r\\), then the number of zero rows in \\(R\\) = \\(m-r\\), and so the last \\(m-r\\) elements of \\(\\mathbf{d}\\) must be zero inorder to have any solution. If they are not zero, we don’t have any solution.\n\nNow we have eliminated the possibility of no-solution, by checking all the last \\(m-r\\) elements of \\(\\mathbf{d}\\) are zero. We find all the solutions of \\(A\\mathbf{x} = \\mathbf{b}\\) by finding a particular solution, any solution, \\(\\mathbf{x_p}\\) to \\(A\\mathbf{x} = \\mathbf{b}\\). Once we have found one solution, all solutions are this particular solution plus some vector in nullspace of \\(A\\); \\(\\mathbf{x_n} \\in N(A)\\).\n\n\n\nThe particular solution can be any solution, but one easy to find is to set all the free variables as zero. Let’s see an example:\n\n\n\nLet’s use augmented matrix and perform elimination:\n\n\n\n\n\n\n\nElimination done. Two pivots, hence rank \\(r=2\\). Last row is zero for \\(R\\), but the corresponding element for \\(\\mathbf{d}\\) isn’t zero. Hence no solution.\n\nLet’s take the same matrix with a different RHS.\n\n\n\nSince the matrix is same, we will apply the same elimination to the new RHS.\n\n\n\nThe new eliminated augmented matrix is:\n\n\n\nRank, as already discussed, was 2 and now the last \\(m-r\\) rows of \\(\\mathbf{d}\\) are also zero, so we will have solution(s). Now we need the null vector of \\(A\\) and a particular solution of this.\n\nNull vector is any linear combination of the specific solutions to \\(A\\mathbf{x} = 0 \\). The specific solutions are easy to find with \\(R\\) form and in this example, we have three free columns and so three specific solutions.\n\nNull vector:\n\nwhere \\(c_1, c_2, c_3\\) are scalar multpliers.\n\nNow we need a particular solution. We can have any one by setting arbitrary values to free variables and back substituting to find the whole. One interesting is to set zero for all free values. Let’s try that.\n\nSet \\(x_2 = x_4 = x_5 = 0\\).\n\nBacksubstitute, we get \\(x_3 = 2\\), \\(x_1 = \\frac{5}{3}\\).\n\nIf you did the backsubstitution along, you would have certainly found that those values came directly from \\(\\mathbf{d}\\). Set the free variables to be zero and the pivot variables come from \\(\\mathbf{d}\\). Keep this in the back of your mind, it will come back later.\n\nSo our particular solution is:\n\n\n\nNow the whole set of solutions is:\n\n\n\nThis is the complete solution of this example. Both parts of our solution, \\(\\mathbf{x_p}\\) and \\(\\mathbf{x_n}\\), came from the same Reduced augmented matrix.\n\n\n  Does the set of all the solutions to \\(A\\mathbf{x} = \\mathbf{b}\\) for any \\(A\\) and \\(\\mathbf{x}\\) form a subspace?\n\n\nI highly recommend to practice on a few different forms of questions to get the hang of this.\n\nInvertibility\n\nA matrix \\(A\\) is said to be invertible if there exists another matrix \\(A^{-1}\\) such that:\n\n\n\nThe fact that \\(AA^{-1} = A^{-1}A\\), implies that both these matrices have to be square and of same size. So rectangular matrices cannot have inverses.\n\nAlso, each invertible matrix has a unique inverse. It has a simple proof:\n\nLet’s say \\(B\\) and \\(C\\) are two inverses of \\(A\\), then:\n\n\n\nNow we have to find an inverse of a matrix, we can formalize this problem as:\n\n\n\nWhere \\(X\\) is a matrix and not a vector, we have to find this matrix, if it exists. But we know that this \\(X\\) is unique for this \\(A\\) and \\(X\\) is a square matrix of the same size as \\(A\\).\n\nLet’s have an example for a \\(3 \\times 3\\) marix.\n\n\n\nWe need to find its inverse(if it exists!).\n\n\n\nThis above problem can be broken into three equations:\n\n\n\n\n\nand\n\n\n\nSince the matrix \\(X\\) has to be unique, each of these above equations should have just one unique solution, which means the nullspace should only have the zero vector and so the final solution should be only the particular solution.\n\n\n\nFor just a unique solution, there should be no free columns, so the rank of the matrix should be equal to it’s number of coulmns and since it is a square matrix, the rank is also equal to the number of rows, eliminating the possibility of zero rows in reduced form which can lead to no solution.\n\nSo a matrix is invertible, iff it is a square full ranked matrix.\n\nTo check if a matrix is invertible, we simply check its rank, by reducing and counting the pivots. We can also reduce it to its reduced row echelon form and if that form ends of like an identity matrix, then it is an invertible matrix.\n\nNow we know which matrix is an invertible matrix. But what is the inverse of that matrix? And how to find it?\n\nTo find the inverse we simply have to solve the above equations and find the values of elements of matrix \\(X\\).\n\nNow we know we have just one unique solution which is also our particular solution to each of the above equations. While looking for the particular solution to a linear system, we used to set the free variables to be zero and the values of pivot variables came from \\(\\mathbf{d}\\).\n\nSince in our form there are no free variables, the whole particular solution is equal to the \\(\\mathbf{d}\\), i.e:\n\n\n\nSo we just reduce our RHS and find the values.\n\nLet’s recall our equations:\n\n\n\n\n\nand\n\n\n\nSolving the first equation, we will augment the matrix and the RHS and then reduce, the resulting \\(\\mathbf{d}\\) will be the solution for the first column of the inverse matrix.\n\n\n\n\n\n\n\n\n\nAnd \n\nThis is the first column of the inverse matrix of \\(A\\). We can do the same with other two equations, but instead of augmenting these RHS’s one at a time and reducing, we can augment all of them and reduce all of the RHS at the same time.\n\nWe augment the matrix as:\n\n\n\nthen reduce to:\n\n\n\n\\(X\\) is the inverse of \\(A\\).\n\nIt can also be seen as:\n\n\n\nWhich means \\(EA = I\\) and \\(EI= X\\), So \\(E\\) is the inverse of \\(A\\) and \\(X= E\\).\n\nThis method of finding the inverse is called the Gauss-Jordan method of finding the inverse.\n\nLet’s finish our current example and then look at one more example to conclude this topic.\n\nLet’s augment:\n\n\n\n\n\n\n\n\n\nSo,\n\n\n\nA = [1 5 3; 2 9 4; 5 7 1]\ninv_A = [19/22 -8/11 7/22; -9/11 7/11 -1/11; 31/22 -9/11 1/22]\nA*inv_A\n\n\n3×3 Array{Float64,2}:\n 1.0  -4.44089e-16  -5.55112e-17\n 0.0   1.0          -5.55112e-17\n 0.0  -7.77156e-16   1.0        \n\n\ninv_A \n\n\n3×3 Array{Float64,2}:\n  0.863636  -0.727273   0.318182 \n -0.818182   0.636364  -0.0909091\n  1.40909   -0.818182   0.0454545\n\n\nWe can also find the inverse in julia using:\n\ninv(A)\n\n\n3×3 Array{Float64,2}:\n  0.863636  -0.727273   0.318182 \n -0.818182   0.636364  -0.0909091\n  1.40909   -0.818182   0.0454545\n\n\nLet’s look at one more example to clear this procedure.\n\nLet’s say our matrix,\n\n\n\nTo find the inverse, let’s augment \\(A\\) and \\(I\\),\n\n\n\nElimiating,\n\n\n\n\n\nWe got a row of zeros for the matrix, which means this matrix is not full row ranked and so not full ranked at all. And so the inverse of this matrix is not possible.\n\nI think this is a good stopping point. I would recommend practicing for everything that we have covered here. Next up we will try to explain Independence, basis and dimensions of subspaces."
					}
					
				
		
				
					,
					
					"notes-linear-algebra-vectors-linear-combinations": {
						"id": "notes-linear-algebra-vectors-linear-combinations",
						"title": "Vectors, Linear Combinations, Eliminations",
						"categories": "",
						"url": " /notes/linear_algebra/vectors-linear-combinations",
						"content": "Vectors, Linear Combinations, Eliminations\n\nIntroduction\n\nThe whole field of linear algebra, as the name suggests, is based on linear combinations of different “things”. We will get to know what these “things” are. How can we represent the different combinations and what these different combinations represent, if they represent anything. We will basically work with vectors and then with matrices. So let’s begin.\n\nVectors\n\nIntroduction\n\nA vector is, simply put, a data holding structure. It can hold entries of data. We can store values of a specific feature in a vector. We can store coordinates of any point in a n-dimensional space.\n\nThe specific function of a vector holding coordinates of a point is used the most. The same data can represent an arrow from origin to the point stored in the vector(the definition physicists usually identify vectors by).\n\nSo a vector can represent just  numbers(data), Arrow from origin, or a point in a space. The vector is said to be -dimensional.\n\nRepresentation of a Vector\n\nHow do we represent vectors? There are basically two ways to do it. A column vector and a row vector. In a column vector, we stack all the numbers in a single vertical fashion and in a row vector, we stack them in horizontal fashion. While both are fine and can be converted from one form to another, the column vector is conventionally used.\n\ne.g: a vector containing 2 and 3 is represented as:\n\n\n\nThis vector corresponds to point .\n\nA column vector(or a row vector) can also be represented by paranthesis. So the above vector can also be . It does not mean it is a row vector. It is actually a column vector(in this case), because we were using column vector. It is just easier to write it.\n\nA 3-dimensional column vector  can also be written as  and it sill is column vector. A row vector will be .\n\nFor now we will primarily represent vectors as columns, unless specified otherwise.\n\nWe can do it in a simple way in julia.\n\nvector = [1, 2, 3]\n\n\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\nIt can be also created like:\n\nvector = [1; 2; 3]\n\n\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\nvector = [1\n          2\n          3]\n\n\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\nOperations on Vectors\n\nIn linear algebra, we work with two important operations, multiplication by a scalar and addition.\n\nWhen we multiply a vector by a scalar, all the values in the vector (called the components) are multiplied by the same number.\n\ne.g:\n\n\n\nWe can add two vectors if their dimensions are same. The resultant vector is the vector of corresponding sums of components of two vectors.\n\ne.g:\n\n\n\n\n  If you are familiar with vectors from basic physics, you know the addition of two vectors is the third side of a triangle formed by placing the tail of one vector at the head of the other vector.\n\n\nIf we combine the above two operations on any number of vectors, i.e we multiply each vector by a scalar and then add all the vectors, we get a linear combination of those vectors.\n\nSo for any two vectors,  and , a linear combination is:\n\n\n\nwhere  are scalars.\n\nfor any  vectors,  a linear combination will be:\n\n\n\nWe will talk about what all these linear combinations for all  and  represent, later.\n\nExample in julia for three vectors with scalars being 2,3,-1.\n\nv1 = [1;2;3;4]\nv2 = [4;3;5;1]\nv3 = [22,45,0,1]\nc1,c2,c3 = 2,3,-1\nc1*v1 + c2*v2 + c3*v3\n\n\n4-element Array{Int64,1}:\n  -8\n -32\n  21\n  10\n\n\nBesides the two important operations in linear algebra, we can do other operations on vectors.\n\nDot Product: We can multiply two vectors to get a scalar. It is called a dot product. It can occur between two vectors of same dimensions. We just multiply the corresponding elements of the two vectors and sum up the products.\n\ne.g:\n\n\n\nWe can achive this in julia as:\n\nusing LinearAlgebra\n\n\nv1 = (1,2);\nv2 = (4,5);\n\ndot(v1,v2)\n\n\n14\n\n\nIt can be also calculated as:\n\n\n\n is also called the inner product and the  is called the outer product. The outer product produces a matrix.\n\nFor two vectors,  and , the dot product is also calculated as:\n\n\n\nwhere  is the length of vector  and  is the angle between the two vectors.\n\nBecause of the cosine, the dot prouct of perpendicular vectors is zero. Also dot product of a vector with itself gives the square of its length.\n\nSince ,\n\n\n\nIt is the Cauchy-Schwarz-Buniakowsky inequality.\n\nMatrices\n\nAs we have established, we save data in vectors. Now we work with multiple vectors (for their linear combinations of course!). We will save multiple vectors in a matrix. Let’s do some examples.\n\nLet’s say we have three vectors:\n\n\n\nTheir linear combination,  for scalars ,  and   is:\n\n\n\nNow if we use all our vectors as columns of a matrix, , that matrix multiplies the vector :\n\n\n\nNow instead of being just numbers,  are now also forming a vector. This gives a new view-point to look at it. The output vector, (or ) is a combination of the columns of .\n\nIt can also be thought as the matrix  above, acts on the vector  and transforms into vector . This specific matrix  above is a “difference matrix” because  contains differences of vector . The vector  is the input and the output is . The top difference is \n\nLinear Equations\n\nIntroduction\n\nLet’s change the view again. Upto now, the vector  was known. The right hand side  was unknown. Now we think of  as known and look for .\n\nWe were earlier asking to compute the linear combination of  to find . Now we are asking which combination of  produces a particular vector ?\n\nFrom now on we will call the unknown vector  instead of , because duh!.\n\nThis problem is the inverse problem i.e to find the input vector  that gives the desired output .\n\nEquations:\nFor our previous matrix, ,\n\n\n\n\n  \n    \n      Equations\n      Solutions\n    \n  \n  \n    \n      \n      \n    \n    \n      \n      \n    \n    \n      \n      \n    \n  \n\n\nSo the solution vector , for the above equation is:\n\n\n\nNow let’s compare the effects on this vector with .  acted on a vector and gave the “differences” of the vector elements and this new matrix gives the “sums” of the elements of the vector it acts on. The new matrix is the inverse of the original  and is shown as .\n\nSo if,\n\n\n\nThis was the solution for this problem because the matrix  was invertible(we will talk more about it later).\n\nLet’s talk about when there is more or less than one solution.\n\nLet’s say we have three equations:\n\n\n\n\n\n\n\nNow if , then\n\n is solved by all vectors \n\nwhere  is any constant.\n\nNow if,say, , then:\n\n has no solution. Left side sums upto 0 and right side to 9.\n\nBut Let’s open the problem in the form ,\n\n\n\nNow our question transforms into finding the linear combination of columns of  that is equal to .\n\nNow if we think about it geometrically, no combination of the columns will the vector . The combinations(of columns) don’t fill up the whole three-dimensional space but a plane given by \n\nA = [1 0 -1; -1 1 0; 0 -1 1]\nb=[1; 1; 1];\n\n\nusing Plotly\n\n\nxx= [j for i=-0.7:0.01:0.7,j=-0.7:0.01:0.7]\nyy = xx';\nz = -xx - yy\n\ntrace1 = scatter3d(x=[0, A[1,1]], y=[0, A[2,1]], z=[0, A[3,1]], mode=\"lines\", line=attr(width=5), name=\"vector 1\")\ntrace2 = scatter3d(x=[0, A[1,2]], y=[0, A[2,2]], z=[0,A[3,2]], mode=\"lines\", line=attr(width=5), name=\"vector 2\")\ntrace3 = scatter3d(x=[0, A[1,3]], y=[0, A[2,3]], z=[0,A[3,3]], mode=\"lines\", line=attr(width=5), name=\"vector 3\")\ntrace4 = scatter3d(x=[0, b[1]], y=[0, b[2]], z=[0,b[3]], mode=\"lines\", line=attr(width=5), name=\"vector b\")\ntrace5 = surface(x=xx, y=yy, z=z, opacity=0.8, showscale=false, name=\"Plane\")\n\n\nplot([trace1,trace2,trace3,trace4,trace5], Layout(scene_camera=attr(eye=attr(x=1, y=1.2, z=1))))\n\n\n\n\n\nHere  represents all the linear combination of columns (for all values of , of course!). Now the sum of two vectors in same direction will have all its linear combinations in that direction. Similarly two vectors in different directions will have all their linear combinations in the plane defined by these two vectors. Now for three vectors, any two vectors will form a plane and if the third vector is not in that plane, then all three vectors are said to be independent and their linear combinations will fill up the whole three dimensional space. But if the third vector is a linear combination of the first two (i.e, it is in the same plane), then the vectors are said to be dependent and the third vector does not contribute anything new and so the result will be a plane.\n\nNow in our matrix, the third column is a linear combination of the first two and hence the linear combination of these three vectors can only form a plane and we would have a solution if the vector  was in that plane. And since the vector  is not in plane determined by the columns of the matrix, this equation has no solution. See Figure above.\n\nIf all this seems a bit too fast or shallow, don’t worry we will cover it in detail later.\n\nSolving Linear Equations\n\nIntroduction\n\nLet’s just simply start with solving two equations with two variables. A two variable equation represents a line in a two dimensional space and all the points on that line satisfy that equation.\n\nNow if we have two equations and we have to find solutions(s) that satisfy both these equations. Now based on the coefficients, a system of equations may have a unique solution, an infinite number of solution, or no solution.\n\nWe have a unique solution, if both the lines intersect at one point and that point is the solution to the system. We have infinite solutions when both lines run over each other. We have no solution if the lines don’t intersect at all(like parallel lines).\n\nLet’s see an example of a unique solution case.\n\nLet’s say we have two equations:\n\n\n\nThe first equation  produces a straight line in the  plane. There are infinite points on it but a special point  also satisfies it and is on the line.\n\nThe line by second equation  is another line that also passes through  and so the solution is  and .\n\nx = [i for i=-5:1:5]\ny1 = 4*x .- 9\ny2 = (4 .- (3*x))/2\n\ntrace1 = scatter(x=x,y=y1, mode=\"lines\")\ntrace2 = scatter(x=x,y=y2, mode=\"lines\")\n\nplot([trace1, trace2], Layout(showlegend=false, annotations=[attr(x=2,\n            y=-1,\n            text=\"(2,-1)\")], title=\"Equations\", xaxis_title=\"x\", yaxis_title=\"y\"))\n\n\n\n\n\n\n\nThis was the row picture. Let’s look at the column picture.\n\nWe will recognize the same system as a vector system. Instead of using numbers, we will use vectors. It can be shown as:\n\n\n\nNow the same problem has transformed into “find the combination of those two vectors that equals the vector on the right. Choosing  and  (same as before!), we will get the right result.\n\nLet’s see how the column picture reveals the answer. Let’s draw each vector, then the vector multipied and the vector on the right.\n\nvec1 = [4;3]\nvec2 = [-1;2]\nb = [9;4]\n\ntrace1 = scatter(x=[0,vec2[1]], y=[0,vec2[2]],mode=\"lines\", name= \"vector 2\")\ntrace2 = scatter(x=[0,vec1[1]], y=[0,vec1[2]],mode=\"lines\", name= \"vector 1\")\ntrace3 = scatter(x=[0,b[1]], y=[0,b[2]],mode=\"lines\", name= \"b\", line=attr(color=\"red\"))\ntrace4 = scatter(x=[0,2*vec1[1]], y=[0,2*vec1[2]],mode=\"lines\", name= \"2 x vector 1\", line = attr(color=\"green\"), opacity=0.5)\ntrace5 = scatter(x=[0,-1*vec2[1]], y=[0,-1*vec2[2]],mode=\"lines\", name= \"-1 x vector 2\", line= attr(color=\"blue\"))\ntrace6 = scatter(x=[2*vec1[1],b[1]], y=[2*vec1[2], b[2]], mode=\"lines\", name= \"-1 x vector 2\", line = attr(color=\"blue\", dash=\"dash\"))\ntrace7 = scatter(x=[-1*vec2[1],b[1]], y=[-1*vec2[2], b[2]], mode=\"lines\",name= \"2 x vector 1\", line = attr(color=\"green\", dash=\"dash\"))\n\n\n\nplot([trace1,trace2,trace3, trace4,trace5,trace6,trace7],\n    Layout(xaxis=attr(scaleanchor=\"y\", scaleratio=1),  width=800))\n\n\n\n\n\n\nHere you can see the combination of these vectors lead to the final vector .\n\n\n\nBy the simple look of the eye the row picture looks better than the column picture. It’s all in your right to choose, but I think it is easier to see a combinaton of four vectors in four dimensional space, than to visualize four hyper-planes meeting at a point.\n\nSame problem, different pictures, same solutions. We combine the problem into a matrix problem as:\n\n\n\nThe matrix,   is called the coefficient matrix. Its rows give the row picture and its columns give you the column picture. And we can try it in julia like.\n\nA = [ 4 -1; 3 2]\nx = [2;-1]\nA*x\n\n\n2-element Array{Int64,1}:\n 9\n 4\n\n\nAnd it has given the same result as the vector .\n\nIn  three-equations-three-variables, the row picture will be that every equation will repersent a plane in the 3-D world and the solution will be all the intersecting points of these planes.\n\nThe column picture is three vectors (the vector of coefficients of  in all the equations, the vector of coefficients of  and that of ) lying in a 3-D space and their combination resulting in the vector .\n\nThe matrix form represents these both pictures.\n\nElimination\n\nUntil now, we just guessed the right answer to a system of equations and just verified the solution. But let’s now try to actually find the solution to a linear system.\n\nLet’s start with 2 variables and 2 equations and return back to the system example we used before.\n\n\n\nNow, let’s see we can get the answer .\n\nThis equation is pretty easy to solve. I’m sure you can do as well.\n\nI would like to eliminate the -part of the second equation in the system. So, I multiply the first equation by  and then subtract it from the second equation.\n\nResulting,\n\n\n\nThe new equation gives , quickly and substituting that in the first equation we get .\n\nThat was simple and you have done it tons of times. But I would like to introduce some terms here and maybe even formalize this procedure.\n\nWe used the the coefficient of  in the first equation to eliminate the first term in the second equation. This is called a pivot and the variable associated with it (here, ) is called a pivot variable.\n\nThe pivot can never be zero, as we cannot eliminate a non zero coefficient by it. No matter what we multiply it by we will always get a zero and that subtracted from other equation will not change them at all.\n\nThe resulting system was in a “upper triangular form” (if we align the variables). The pivots always lie on the diagonal of this traingular form after completed elimination.\n\nWe have a few more terminology to introduce. But let’s look at a few \nmore cases of this system. The solution we got before was simple as the solution was unique.\n\nBut if solution isn’t unique, two cases arise: No solution and infinite solutions.\n\nLet’s say the system is:\n\n\n\nLet’s do the simple elimination again. Multiply the first equation by 2 and subtract from the second one to get the triangluar form:\n\n\n\nThere is no solution . Usually we would divide -11 by second pivot, but here is no second pivot(Zeros are not pivots!) making it a no solution system. In the row form it is represented by two parallel lines. The column picture shows that the vector  and the vector  are in the same direction. And so all it’s linear combinations will be restricted on a line along that direction. And the vector  does not lie on that line and so no combination can do it. Hence no solution.\n\nFor the infinite soution let’s just change the vector  to a vector which is on that line, say .\n\nSo the equations are:\n\n\n\nEliminating…, we get:\n\n\n\nEvery  satisfies . The  is said to be a “free variable”, i.e we can choose  freely and  is then computed using the first equation. There is actually just one equation . This also has just one pivot.\n\nIn the row picture, both lines are the same. In the column picture the vector  lies on the line determined by the coefficient vectors. In fact it is one-third times the first column and it can also be defined as one-fourth times the second column and hence we can have an infinte combinations of these vectors that can end up on that vector .\n\nSometimes we may have to exchange rows. It is because we want to have that traingular form, there might occur a Zero where there should be a pivot and we can exchange that row with the nearest row below which has a non-zero number at that place. e.g, a system is:\n\n\n\nHere we have a Zero where there should be a pivot in the first row. So we cannot perform elimination. But we can exchange it with the row below to get a pivot at that place and proceed with elimination.\n\n\n\nNow this form is already in the trianglular form and can be back-substituted. So,\n from equation 2 and so  from the first.\n\nTo understand Gaussian elimination, we need to go beyond 2-equations and two variables. Let’s try a 3-equation and 3-variable system.\n\nLet’s say a system is:\n\n\n\nThe first pivot is in the bold-face. Now as we have to make it traingular, we will have to eliminate all the  terms in the second and third equation.\n\nSo subtracting  times the first equation from second and  times the first equation from third.\n\n\n\nNow the second pivot is shown in bold-face. We need to eliminate the  term in the third equation with it. So subtracting  times the second equation from the third,\n\n\n\nThe third pivot is in bold-face. We have finished the forward pass of the Elimination. The pivots are 2,-5,9. The last two pivots were hidden in original system but elimination revealed them. Now it is ready for back substitution and\n\n and so  and finally .\n\nThe row picture has three planes which meet at one point .\n\nThe column picture has three vectors in the 3d space whose specific combination  produce the vector , the output vector.\n\nSo the process of elimination can be summarized as, for any n by n problem:\n\n\n  \n    Use first equation* to create zeroes below the first pivot.\n  \n  \n    Use the second equation* to create zeroes below the second pivot.\n  \n  \n    Keep going untill you get an triangular form or all the equations below have Zero coefficients.\n  \n  \n    *Do row exhanges wherever necessary, as Zero cannot be a pivot.\n  \n  \n    If you get a complete triangular form, then back substitution will reveal the unique solution. If you get all the coefficients to be Zero then if the cooresponding output is also zero, you have infinite solution, and if the corresponding output is not zero then there is no solution.\n  \n\n\nMatrix Multiplication\n\nBefore talking about further elimination, let’s talk about matrix multiplication a bit more.\n\nLet’s say we multiply a matrix and a column vector. The result will be another column vector., e.g:\n\n\n\nThis multiplication, by the simple formula of multiplying rows and columns and sum upto get one element of the resultant matrix, gives us the result:\n\n\n\nAlthough this multiplication can also be represented as a linear combination of columns of the matrix using the elements of the vector:\n\n\n\nSimilarly if we multiply two matrices, each column of the resultant matrix will be a linear combination of columns of left matrix using the elements of the corresponding column of right matrix as multipliers. If it seems too much, let’s see an example:\n\n\n\nIt can broken into two parts:\n\n\n  \n    The left matrix multiplying the first column of the right matrix to give the first column of the resultant matrix.\n  \n  \n    The left matrix multiplying the second column of the right matrix to give the second column of the resultant matrix.\n  \n\n\nSo in the above example the first column of the resultant matrix is the first column plus twice the second column plus three times the third column of the left matrix,i.e a linear combination of columns of left matrix with the multipliers being the elements of the first column of right matrix.\n\nSimilarly we can see the second column of the resultant matrix again being the linear combination of columns of the left matrix with the numbers of the second column of the right matrix as multipliers.\n\nAgain if we multiply a row vector and a matrix,\n\n\n\nThe result will be a row vector which will be linear combination of rows of the matrix with multipliers being elements of the row vector.\n\n\n\nSimilarly, if we multiply two matrices we can show that each row is a linear combination of rows of the right matrix with elements from the corresponding row of the left matrix are the multipliers.\n\nSo a matrix multiplication can be shown as linear combination of rows(of the right matrix) as well as a linear combination of columns(of the left matrix).\n\nWe will put the above facts, particularly about the row combination to our use to perform subtraction of equations and hence elimination.\n\nElimination Using Matrices\n\nLet’s use the system again we used before for this,\n\n\n\nThis system can be conveniently changed into,\n\n\n\nand so can be also written as \n\nA = [2 4 -6;\n     4 3 -8;\n    -2 6  7]\n\nb = [-2; 0; 3];\n\n\nNow, to perform first step of elimination, we have to remove the elements below the first pivot (bold face) using row subtractions. Now whatever row changes we make in , we have to make in  as well.\n\nWe have to subtract 2 times the first row from the second and -1 times the first row from the third. To perform this operation, I will multiply both sides by a matrix .\n\nI would say the matrix  is:\n\n\n\nE1 = [1 0 0;\n     -2 1 0\n      1 0 1];\n\n\nThis matrix, when pre-multiplied, will always perform the above operation on any matrix(which is compatible for matrix multiplication, of course!). Let’s see why.\n\nLet’s think of the resultant matrix. The first row of that matrix will be a combination of the rows of the right matrix (on which the operation is being done on) with the first row of  being the multipliers.\n\nFirst row of resultant matrix:  (of original matrix) + \n\nSo the first row is not changed.\n\nSimilarly second row of resultant matrix: \n\nSo we have subtracted twice row 1 from row 2.\n\nThird row of resultant matrix: \n\nSo we have subtracted -1 times row 1 from row 3.\n\nLet’s now perform  and :\n\n\n\n\n\nE1*A\n\n\n3×3 Array{Int64,2}:\n 2   4  -6\n 0  -5   4\n 0  10   1\n\n\nE1*b\n\n\n3-element Array{Int64,1}:\n -2\n  4\n  1\n\n\nSo now our equation is:\n\n\n\nThe second pivot(bold face) has to remove the elements below it. Now we have to subtract -2 times row from row 3. We will make another Elimination matrix,  to perform this operation. But let’s now make it row by row so we understand how it works.\n\nSo in the row1 resultant matrix, we do not want any change in the matrix.\n\nhence row1 of elimination matrix =  i.e we want 1 of the first row and none of any other row, giving us the original row back.\n\nIn row2 of resultant matrix we again do not want any change,\n\nso row2 of elimination matrix =  i.e we want 1 of second row and none of any other row.\n\nNow in row3 we want to eliminate 10 using pivot -5, so we want to subtract -2 times the row 2 from row 3 which is also adding 2 times row 2 to row 3:\n\nso row3 of elimination matrix =  i.e we want twice of row2 and row 1, which will eliminate the required numbers.\n\nSo the final elimination matrix will be:\n\n\n\nE2 = [1 0 0; 0 1 0; 0 2 1];\n\n\nSo let’s now perform  and :\n\n\n\n\n\nE2*(E1*A)\n\n\n3×3 Array{Int64,2}:\n 2   4  -6\n 0  -5   4\n 0   0   9\n\n\nE2*(E1*b)\n\n\n3-element Array{Int64,1}:\n -2\n  4\n  9\n\n\nSo now the equation is:\n\n\n\nHere we have reached to the upper triangular form and hence have completed the forward pass. the backward pass is simple.\n\nSo we apply elimination matrices to change , where  is an upper traingular matrix. We apply the same matrices to change  and finally solve  using back-substitution(if there is a unique solution).\n\nOne more thing to mention about matrix multiplication is that it holds on associativity. So, if  are three matrices(compatible for matrix multiplication in the order), then:\n\n\n\nSo basically we can multiply all our elimination matrices first, and then multiply that with our  and .\n\n\n\nLet’s see how this matrix  looks like in our example.\n\n\n\nSo we multiply by this elimination matrix to our matrix  to form an Upper triangular matrix, ,\n\n\n\nand\n\n\n\nE = E2*E1\n\n\n3×3 Array{Int64,2}:\n  1  0  0\n -2  1  0\n -3  2  1\n\n\nNow the matrix  has almost all the same multipliers that we use in individual except a few(shown in bold-face of matrix ). It is because the effect of the first elimination is shown in second and so on. In our example the second row is subtracted by 2 times the first row and the third row is  added by 1 times first row. Then the new third row is added 2 times the new second row. So essentially, the original third row was subtracted 3 times the first row and 2 times the original second row.\n\nHowever to show it in a better way, we can use the inverse of ,\n\n can be shown as \n\nLet’s look at \n\n\n\nL=inv(E)\n\n\n3×3 Array{Float64,2}:\n  1.0   0.0  0.0\n  2.0   1.0  0.0\n -1.0  -2.0  1.0\n\n\nThe  has the correct values that mutiply the pivots, before subtracting them from the lower rows going from  to . SInce it is an lower traingular matrix, we represent it by .\n\n\n\nThe matrix  can be used at many places.\n\n\n  \n    It can be used to factorize .\n  \n  \n    It has the memory of pivot multipliers before subtraction.\n  \n  \n    *It can be used to compute transformed right hand side,, as .\n  \n\n\n*Although we can also concatenate  and  as  and then run it though the forward elimination but most applications tend to do them separately.\n\nRow Exchanges\n\nHere we had prepared everything but considering no row exchange will be needed. Let’s remind that row exchanges are needed when zeros occur at pivot places.\n\nWhat matrix to use when we have to exchange two rows? Let’s take an example:\nend{bmatrix}\n\n\nLet’s first eliminate the first column using the first pivot(bold-face),\n\n\n\nAs you can see the second diagonal element is zero, which cannot be a pivot. So we will exchange the second and third row. the matrix we will apply is called a permutation matrix.\n\n\n\nSo the first resultant row will be the same. The resultant second row will be zero times first and second row and 1 times third row ,i.e the third row. The resultant third row will be zero times first and third row but 1 times the second, i.e the second row. So, essentially the second and the third row have been exchanged. A permutation matrix is basically identity matrix with the same rows exchanged which need to be changed in the coefficient matrix.\n\n\n\nNow we have the new pivot and we can move with elimination.\n\n\n  Note: Row exchanges will alter the final the elimination matrix,  as well as the inverse  which will not have the values at the same place.\n\n\nNow one way to keep it in the same way is if we perform all the row exchanges first, using the product of all permutation matrices,  and then perform the elimination using .\n\nFinal equation is:\n\n\n\nThis is a good stopping point in basics. We will next see what does the infinite solutions mean, how we represent them. What are vector spaces and subspaces, rank, invertibility and more."
					}
					
				
		
				
					,
					
					"notes-neural-networks-convolutional-neural-networks-convolutions": {
						"id": "notes-neural-networks-convolutional-neural-networks-convolutions",
						"title": "Convolutions",
						"categories": "",
						"url": " /notes/neural_networks/convolutional_neural_networks/convolutions",
						"content": "Convolutions\n\n\n  Convolutions    \n      Introduction\n      Impulse as a delta function\n      Output of an Impulse\n      Dimensions\n      Example\n      Convolution is commutative\n      The formula?\n      Padding\n      Properties of Convolution        \n          1. Delta Function \n          2. Commutative Property\n          3. Associative Property\n          4. Distributive Property\n        \n      \n      Correlation\n      References\n    \n  \n\n\nIntroduction\n\nConvolution operation(denoted by ) is one of the most important, if not the most important technique in Signal Processing. It gives us the idea of how a linear invariant system converts an input signal to an output signal. From now on, we will refer to digital signal as simply signal.\n\nLet’s first introduce some terminology:\n\n\n  Input Signal: As the name suggests, it is a signal that acts as an input to a system.\n  Output System: The output that the system generates by acting over the input signal.\n  Impulse: An impulse is a signal that is zero everywhere except at a single point.\n  Delta function: It is an impulse with value unity at sample number 0 and zero at every other sample number. It is a normalized impulse, also called unit impulse.\n\n\n\n\n\n  Impulse response: The output of a system when a delta function is give as input.\n\n\nThe impulse response of a system defines the system. Different systems will have different impulse responces.\n\nNow, how to obtain an output from a system for an input signal? We use what is called a Decomposition technique.\n\nDecomposition: Break the input signal into smaller units. Pass those units through the system to get corresponding outputs. Add those outputs to get the final output signal.\n\nThere are two main decompositions in signal processing: Fourier Decomposition and Impulse Decomposition. When impulse decomposition is done, it can be described by a mathematical operation called convolutions(denoted ).\n\nWe do an impulse decomposition, i.e we decompose our input signal in multiple impulses and then pass those impulses through the system to produce corresponding outputs. The outputs are added to generate the final output signal.\n\nImpulse as a delta function\n\nAny impulse function can be represented as a shifted and scaled delta function. e.g: An impulse, say  with zeroes everywhere except at sample no. 2, has a value of -1.3. This impulse can be represented as\n\n\n\nIn the abpve figure, the LHS is an impulse  of -1.3 at sample number 2 and the RHS is a standard delta  i.e impulse of unity at sample number 0.\n\nNow, we can represent this impulse  as a scaled and shifted  as:\n\n\n\nSimilarly any impulse  which has value  and sample number , i.e\n\n\n\nthen,\n\n\n\nOutput of an Impulse\n\nNow if  is passed through a system with impulse response , what will be the output? Well  is the output when the input is . What could be output when input is ?\n\n\n\nThe output is shifted and scaled by the same amount as the delta function is to form the input impulse. These are the properties of homogeneity and shift invariance.\n\nSo if we know the impulse response of any system, we know the output of any impulse.\n\nWith the information of how outputs to impulses are produced, let’s revisit how do we prouce output to a complete signal by Impulse Decomposition, which is mathematically equivalent to convolution of input signal and impulse response.\n\nFirst we decompose the input signal into impulses which can be viewed as shifted and scaled delta functions. These shifted and scaled delta functions produced similar shifted and scaled impulse responses as outputs. These outputs are finally sunthesized(added) to produce the final output.\n\nThis whole operation is called convolution of impulse response  and input signal  and is denoted as:\n\n\n\n\n  Note:  is not multiplication, it is convolution.\n\n\nSo, to know impulse response of a system, we know output of any input signal. It is something that defines the system.\n\nThis impulse response is sometimes called a kernel. And the output as feature map.\n\nDimensions\n\nLet’s say our input signal has  number of samples and the kernel has  number of samples, then output signal(the convolution of input signal and the kernel, will be .\n\nNote: When we say a signal has  samples, it means we know these  samples. The signal actually continues from  to . We assume every signal(be that input, kernel or output) has values of zero anywhere outside of those  samples.\n\nIf an input signal has, say,  samples, and a kernel is  samples long, then we have to shift and scale the kernel for each impulse as that impulse is shifted and scaled from the delta function. Now for the first impulse of input(i.e sample 0), the kernel will be scaled but not shifted and thus will contribute to output signal from sample 0 to sample 19 (because is 20 samples long). For second impulse of input (i.e sample no. 1), the kernel will shift 1 step and will be scaled as well, and thus will contribute to output signal from sample 1 to sample 20. The intersecting output contrbutions at a given sample are added. Similarly at  impulse of input(i.e at sample no. ), the kernel will be shifted  places (and scaled as well) and thus will contribute to output signal from  sample no.  to sample no.  i.e .\n\nExample\n\nLet’s see an example to make things more clear. Let’s say we have an input of 9 samples a kernel of 4 samples. We will store these in numpy arrays.\n\nimport numpy as np\ninput_signal = np.array([1.1,0,-1.05,1.4,-1.2,-1.4,-1,0,0.7])\nkernel = np.array([1,0.5,-0.3,0.2])\n\n\nNow input is 9 samples long() and kernel is 4 samples long () so output will be  samples long.\n\n\n  Note: The size of each signal does not mean these signals are just restricted to these samples. These run to infinity(on both sides) just that the value everywhere else is 0, e.g: sample number 5 onwards and before sample number 0 of kernel are all Zero.\n\n\n\n  Let’s start with creating an output array of 12 values with each element equal to zero.\n  We will then extend our kernels to be of the same size as our outputs and then shift and scale the kernels.\n  Finallly we will add them to our output signal.\n\n\ndef simple_convolve(input_signal, kernel):\n    \"\"\"A simple way of convolving two signals.\n    input_signal: numpy array containing the input signal.\n    kernel: numpy array containing the kernel.\"\"\"\n    \n    output_signal = np.zeros(len(input_signal)+len(kernel)-1)\n    \n    for i in range(len(input_signal)):\n        \n        shifted_kernel = np.hstack((np.zeros(i), kernel, np.zeros(len(output_signal)-i-len(kernel))))\n        scaled_shifted_kernel = input_signal[i]*shifted_kernel\n        \n        #add the scaled and shifted kernel to the output\n        output_signal+=scaled_shifted_kernel\n    \n    return output_signal\n\n\noutput_signal = simple_convolve(input_signal, kernel);output_signal\n\n\narray([ 1.1  ,  0.55 , -1.38 ,  1.095, -0.185, -2.63 , -1.06 , -0.32 ,\n        0.72 ,  0.15 , -0.21 ,  0.14 ])\n\n\nimport matplotlib.pyplot as plt\ntext_color = \"orange\"\nback_color = (33/255,33/255,33/255)\nf, ax = plt.subplots(1,3, figsize=(18,4), gridspec_kw=dict(width_ratios=[3,1,3]))\n\nfor subplot, data, title in zip(ax, (input_signal, kernel, output_signal), ('Input Signal', 'Kernel', 'Output Signal')):\n    subplot.plot(data, '.', markersize=20, color=text_color)\n    subplot.set_title(title, color=text_color)\n    subplot.set_ylim(-3,3)\n    subplot.set_xticks(list(range(len(data))))\n    subplot.set_xticklabels(list(map(str,range(len(data)))), color=text_color)\n    subplot.set_yticklabels(list(map(str,np.arange(-3,4))), color=text_color)\n    subplot.set_facecolor(back_color)\n    subplot.grid(True, alpha=0.3, linestyle='--')\n    subplot.set_xlabel(\"Sample Number\", color=text_color)\n\nf.set_facecolor(back_color)\nf.set_alpha(0)\nf.tight_layout()\n\n\n\n\nThe process can be shown graphically as:\n\n\n\nThe key take away from the above graphic is this frame:\n\n\n\nThese are the contributions of each shifted and scaled kernels to the final output signal. This figure shows how each impulse from the input signal changes the kernel and then these changes are added to the final output.\n\n\n  Note: The kernel is in orange color, the cyan color is just extensions of zeros to make it the same size as that of the output signal.\n\n\nConvolution is commutative\n\nLet’s again convolve the input signal with kernel.\n\noutput1 = simple_convolve(input_signal=input_signal, kernel=kernel); output1\n\n\narray([ 1.1  ,  0.55 , -1.38 ,  1.095, -0.185, -2.63 , -1.06 , -0.32 ,\n        0.72 ,  0.15 , -0.21 ,  0.14 ])\n\n\nNow let’s now reverse the input_signal and the kernel.\n\noutput2 = simple_convolve(input_signal=kernel, kernel=input_signal); output2\n\n\narray([ 1.1  ,  0.55 , -1.38 ,  1.095, -0.185, -2.63 , -1.06 , -0.32 ,\n        0.72 ,  0.15 , -0.21 ,  0.14 ])\n\n\nAs you can see, both the outputs are same. This is an important property of convolution that is put to use, i.e:\n\n\n\nThe result of convolution is always same, no matter the order of the signals. This operation is commutative.\n\nNow, what does this mean in Signal Processing?\nIt means we can exchange the impulse response and the input signal to generate the same output, but that does not make any sense physically as the impulse response of a system is fixed and cannot be altered. It is what defines the system. So changing the impulse response means to changing the system completely.\n\nSo basically, for signal processing, it does not have any special meaning. It is simply a mathematical tool that can be leveraged to implement convolution operation.\n\nThe formula?\n\nNow we have implemented convolution, but it what if we need to know just what the, say, 8th element of the convolved output signal is? Our current implementation will calculate that by computing the whole output signal and then giving us the output. This method is slow and if the input signal is hundreds of thousands(or even millions) of points, it will take a huge amount of time to do that, only to return one element.\n\nSo what we need is a mathematical formula of what convolution is.\n\n\n\nThis is what we need to find out. For that let’s recall the important take away from the animation we saw earlier. I’ll add the x axis at each figure, we will need it.\n\n\n\nNow the output signal is the sum of all these signals. These signals are added at their corresponding samples. So the 8th element of the output signal is the sum of all 8th elements in each of these signals.\n\nNow, after observations, you can tell that the 8th elements of most of these signals is zero (in cyan). These were the extensions to make the kernel longer. And these zeros don’t contribute anything to the final sum. This is how our calculation gets fast, we only only sum values from those signals, which were not extensions.\n\nSo, for element 8, only  contributes (because only these signals are  orange  at sample number 8).\n\nSo we can say,\n\n\n\nSubstituting ,\n\n\n\nIt can be written as,\n\n\n\nThis means 4 samples of kernel are multiplied with 4 samples of input.\n\nLet’s look at output sample 6. This value comes from the sum of all the  orange  samples at sample number 6 in the above figure.\n\nso,\n\n\n\n\n\nAgain, it can be written as:\n\n\n\nGeneralizing, for a kernel of size , running from  to \n\n\n\nThis equation is called convolution sum. It let’s us calculate the output at any point independent of other output points. As  runs from  to , each sample from the kernel,  is multiplied with corresponding input samples  and then summed up to form the output at sample .\n\n\n\nAs you can see in the above figure, the kernel is flipped and multiplied with the corresponding input elements (white). These products are then summed up to form the final output(white in ouput).\n\nPadding\n\nComing back to Eq. 5, let’s see how we can generate,  and .\n\n\n\nFor  and ,\n\n\n\nFor  and ,\n\n\n\nIn both these equations, we have some inputs, which are not part of our original input signal. Our original signal has sample number 0 to 8. So what would , ,  and , ,  mean?\n\nActually the input signal (as well as output and kernel), all are present at all samples. It is just they are zero (i.e no signal). And they don’t contribute to the convolution and hence are not saved. (Besides, we cannot save infinite numbers in a computer, can we?). But, as it turns out we need some of these zero points, for our outputs. Specifically, we need  points on both sides of an input signal. So we just extend our signal with zeros for these samples. This is what we call padding. Padding is a technique where we add a bunch of zeros to a signal where the signal does not exist.\n\n\n\nThe above animation shows how the flipped kernel moves along the input signal. At each stop it multiplies the elements of the kernel and the that of the input signal which overlap with the kernel. These products are summed up to form the corresponding output sample. Look at this animation and the equation 5. Make sure you understand both. Practice a bit on paper. Remember, the kernel is flipped.\n\nThe cyan points in the input signal in above animation are the padding of that signal. The far left and far right data points of the output signal are based on incomplete information, because some of the inputs are padded. We say that the kernel is not fully immersed in the input signal while computing these points. If the kernel is  samples long, then the  samples of the ouput signal on both sides are based on less information. The farther elements of these  elements (on both sides) are based on lesser information than the closer ones to the center. So the extreme points in the output signal are usually not used. Another way to do this is to control the padding. If we intitially pad the the signal less than  points on both sides, it is equivalent of ignoring the outputs that would have formed because of these points.\n\nWith that in mind, let’s write the code for simple convolution using this method. We will control the padding as well.\n\nimport numpy as np\n\n\ndef conv(input_signal, kernel, padding=None):\n    \"\"\"Performs convolution of input and kernel with padding.\n    \n    Parameters\n    ----------\n    `input_signal`: iterable containing the input signal.\n    \n    `kernel`: iterable contatining the kernel.\n    \n    `padding`: int, the amount of zero padding to be done in each sides of the input signal.\n               Default is `len(kernel)-1`\n    \"\"\"\n    \n    if padding is None:\n        padding = len(kernel)-1 # default padding is the full padding\n    \n    padded_inp = np.pad(input_signal,padding)\n    output_signal=[]\n    \n    #traverse through the input signal until kernel overlaps with the end point\n    for i in range(len(padded_inp)-(len(kernel)-1)):\n        # perform convolution sum.\n        current_out = np.sum(padded_inp[i:i+len(kernel)]*np.array(kernel[::-1])) #kernel is flipped.\n        output_signal.append(current_out)\n        \n    return np.array(output_signal)\n        \n\n\noutput3 = conv(input_signal=input_signal, kernel=kernel); output3\n\n\narray([ 1.1  ,  0.55 , -1.38 ,  1.095, -0.185, -2.63 , -1.06 , -0.32 ,\n        0.72 ,  0.15 , -0.21 ,  0.14 ])\n\n\noutput4 = conv(input_signal=kernel, kernel=input_signal); output4\n\n\narray([ 1.1  ,  0.55 , -1.38 ,  1.095, -0.185, -2.63 , -1.06 , -0.32 ,\n        0.72 ,  0.15 , -0.21 ,  0.14 ])\n\n\nAs you can see, the commutative property still holds up.\n\nLet’s look at some examples,\n\nfrom math import floor, ceil\nimport matplotlib as mpl\nmpl.rcParams[\"mathtext.fontset\"]=\"cm\"\n\ninput_color = \"orange\"\nkernel_color = \"white\"\noutput_color = (0,1,0)\n\n\n\ndef plot_signals(input_signal, kernel, input_name=None, kernel_name=None, output_name=None, padding=None, fig_size=(10,5), axes=None, f=None, tight_layout=True):\n    \"\"\"Plots a 1 x 3 grid of input signal, kernel and output signal\n    \n    Parameters:\n    -----------\n    `input_signal`: iterable, containing the input signal.\n    \n    `kernel`: iterable, containing the impulse response of a system.\n    \n    `input_name`: [optional] str, name for the input signal. It will be displayed in parenthesis. Can include latex as well.\n    \n    `kernel_name`: [optional] str, name for kernel. Will be displayed in parenthesis. Can include latex as well.\n    \n    `padding`: [optional] int, padding to be used for convolution.\n    \n    `fig_size`: [optional] tuple(int, int), containing width and height of the figure.\n    \"\"\"\n    p_flag = False #flag is set if padding is None\n    if padding is None:\n        p_flag = True\n        padding = len(kernel)-1\n    output_signal = conv(input_signal, kernel, padding)\n\n    init_color, final_color = np.array([1,0,0]), np.array([0.1,0.9,0])\n    unusable_colors = [list(final_color - (i*(final_color-init_color)/(len(kernel)-1))) for i in range(padding)]\n\n    if axes is None:\n        f, axes = plt.subplots(1,3,figsize=fig_size, facecolor=back_color, gridspec_kw=dict(width_ratios=[len(input_signal),len(kernel),len(output_signal)]))\n    \n    input_name = rf\"Input Signal $$x[n]$$ ({input_name})\" if input_name is not None else r\"Input Signal $$x[n]$$\"\n    kernel_name = rf\"Kernel $$h[n]$$ ({kernel_name})\" if kernel_name is not None else r\"Kernel $$h[n]$$\"\n    \n    \n    if output_name is None:\n        output_name = rf\"Output Signal $$y[n] = x[n] * h[n]$$\"+f\"\\nPadding: {f'full({len(kernel)-1})' if p_flag else padding}\"\n    \n    for ax, data, name, color,label_color in zip(axes, (input_signal, kernel, output_signal), (input_name, kernel_name, output_name), \n                                                 (input_color, kernel_color, list(reversed(unusable_colors)) +\\\n                                                  [output_color]*(len(output_signal)-2*padding)+unusable_colors), (input_color, kernel_color, output_color)):\n        if ax is not None:\n            ax.scatter(list(range(len(data))),data,s=20, c=color)\n            ax.set(facecolor=back_color, alpha=0, ylim=(np.floor(min(data))-1,ceil(max(data))+1), \n                   yticks=range(floor(min(data))-1,ceil(max(data))+2,max(1,ceil((max(data)-min(data)+2)/15))), xticks=range(0,len(data)+1,10))\n            \n            ax.grid(True,linestyle='--',alpha=0.3)\n            \n            ax.set_yticklabels(list(map(str,ax.get_yticks())), color=label_color)\n            ax.set_xticklabels(list(map(str,ax.get_xticks())), color=label_color)\n            \n            ax.set_title(name, color=label_color, size=18)\n            \n            for spine in ax.spines.values():\n                spine.set_visible(False)\n    \n    if tight_layout:\n        f.tight_layout()\n    \n    return f,axes\n\n\n\nLet’s use a new input signal. A sine with a negative ramp.\n\nx = np.arange(101)/3\ninput_signal = np.sin(x)-0.3*(x)\n\n\nLet’s try to invert this signal using a known inverter kernel.\n\ninverter = np.zeros(31)\ninverter[15] = -1\n\n\nplot_signals(input_signal, inverter, fig_size=(30,4), input_name=r\"$$\\sin {\\left({}^n/_3\\right)} - 0.3 n$$\", kernel_name=\"Inverter\");\n\n\n\n\nLook at the output. The signal has been inverted but not at the end points. This is because while computing these points, the kernel was not fully immersed into input signal because of the padding. These extreme output points are not usable and hence are to be ignored. Another way is to not compute them at all, i.e reduce the padding. Our current kernel is 31 samples long, and so the padding will be 30 samples on each side. Let’s try padding of just 15 samples.\n\nplot_signals(input_signal, inverter, fig_size=(30,4), padding = 15, \n             input_name=r\"$$\\sin {\\left({}^n/_3\\right)} - 0.3 n$$\", kernel_name=\"Inverter\");\n\n\n\n\nMuch better. But remember there are still extreme points which are based on less information. It is just they are based on comparatively more information than the ones before them. If we want only those points which are based on complete information, then we have to set the padding to be zero. The redder samples are based on lesser information.\n\nplot_signals(input_signal, inverter, fig_size=(30,4), padding = 0, \n             input_name=r\"$$\\sin {\\left({}^n/_3\\right)} - 0.3 n$$\", kernel_name=\"Inverter\");\n\n\n\n\nNotice the difference in sizes of output signal for each padding. We had mentioned earlier that if an input signal is  samples long and a kernel is  sampes long then the output signal will be  signals long. This is actually true for full padding.\n\nFor padding ,\n\n\n\nFor full padding, ,\n\n\n\nThere is another padding, called same padding. It keeps the input and output size the same.\n\nFor same padding, ,\n\n\n\nLet’s try another kernel. A known high pass filter. Since out input signal consists of a sine function and a linear function, we would like to just keep the higher frequency part(i.e the sine part). The linear part should be removed.\n\nhighpass_filter = np.linspace(-0.23,0.23,31)**2-(0.23**2)\nhighpass_filter[15]=1\n\n\ndef plot_all(input_signal, kernel, paddings=[0,15,None], input_name=None, kernel_name=None, fig_size=(10,5)):\n    from matplotlib.gridspec import GridSpec    \n    \n    axes = []\n    gs = GridSpec(len(paddings), 3,wspace=0.1, width_ratios=[len(input_signal),len(kernel),len(input_signal)+len(kernel)-1])\n    \n    f = plt.figure(figsize=fig_size, facecolor=back_color)\n    input_ax = f.add_subplot(gs[(len(paddings)//2),0])\n    kernel_ax = f.add_subplot(gs[(len(paddings)//2),1])\n    \n    plot_signals(input_signal, kernel,input_name=input_name, kernel_name=kernel_name, padding=None,axes=[input_ax,kernel_ax], f=f, tight_layout=False)\n    \n    out_ax = f.add_subplot(gs[0,2])\n    plot_signals(input_signal, kernel, padding=paddings[0],axes=[None,None,out_ax], f=f, tight_layout=False)\n    for index in range(1,len(paddings)):\n        out_ax = f.add_subplot(gs[index,2], sharex=out_ax)\n        out_name = f\"Padding: {paddings[index] if paddings[index] is not None else f'full ({len(kernel)-1})'}\"\n        plot_signals(input_signal, kernel, padding=paddings[index],axes=[None,None,out_ax], f=f, output_name=out_name, tight_layout=False)\n    \n\n\n\nplot_all(input_signal, highpass_filter, input_name=r\"$$\\sin {\\left({}^n/_3\\right)} - 0.3 n$$\", paddings=[0,(len(highpass_filter)-1)//2, None], #zero, same and full\n         kernel_name=\"High Pass Filter\", fig_size=(30,12))\n\n\n\nProperties of Convolution\n\n1. Delta Function \n\n\n  It is the identity function for convolution. Just like  is for addition () or like  is for multiplication (), similarly:\n\n\n\n\n\n  If the delta function is scaled, then the output is also scaled:\n\n\n\n\nSo it can be used as an amplifier ar as an attenuator. We can even invert a signal like we did above by setting  and can do much more with this simple property.\n\n\n  If the delta function is shifted by an amount, the output function is also shifted by the same amount:\n\n\n\n\n2. Commutative Property\n\nIt does not matter which signal is convolved with which signal, (or which signal is slided over which signal, provided padding is appropriate), the result will be the same.\n\n\n\nThis property doesn’t mean anything in the signal processing physically. It is just a convenient tool for mathematics and certain implementations.\n\n3. Associative Property\n\n\n\nIt provides idea how cascaded systems work. Suppose, we have two kernels,  and , and we apply them respectively:\n\n\n\nNow by associative property,\n\n\n\nLet’s say , then:\n\n\n\nSo if we are convolving a signal with  kernels one after another, we can equivalently convolve the signal with the convolution of all these kernels with each other. It means a cascaded system can be replaced by a single system. The impulse response is the convolution of all the impulse responses of individual systems.\n\n4. Distributive Property\n\n\n\nIt provides idea of how parallel systems work. If  systems share the common input and their outputs are finally added (or subtracted), we can repalce it with a single system with impulse response being the addition (or subtraction) of individual impulse responses  of the systems.\n\nCorrelation\n\nCorrelation is another operation that is somewhat similar to convolution. Correlation uses two signals and produces an output called the cross correlation of the two input signals. If a signal is correlated with itself, the output is called autocorrelation.\n\nThe main difference between calculating the output of correlation from that of convolution is that the kernel is not flipped.\n\nIf convolution,  of  and  is:\n\n\n\nthen the correlation,  of  and  is:\n\n\n\nThe formula for correlation will be:\n\n\n\nfor a kernel that runs from sample number  to .\n\nCorrelation, unlike convolution, is not commutative. The order matters. We cannot interchange the signals and expect the same cross-correlation. The second signal, which is moved along the first signal is called a target signal, . It is called so because correlation is a technique of pattern recognition. The amplitude of the output signal at any point is a measure of how much the input signal resembles the target signal at that point.\n\nIt means a peak in the cross-correlation will mean a high resemblance, while a negative peak means the opposite.\n\nLet’s see a quick example of it.\n\npattern = np.sin(np.linspace(np.pi/2,np.pi,21))\nsignal = np.hstack((np.zeros(50),pattern,np.zeros(50), pattern, np.zeros(50), -pattern,np.zeros(50)))\nnoise = np.random.random(len(signal))*0.2*2-1\nsignal = signal + noise # add some noise\n\n\nf = plot_all(input_signal=signal, kernel=pattern[::-1], # we send in the reversed kernel because it is correlation\n            paddings=[0, (len(pattern)-1)//2, None], fig_size=(30,12))\n\n\n\n\nThe above plot shows how different paddings for correlation can have spikes at different points for the same pattern, ex: in zero padding, the peak is at the corresponding sample number when the pattern starts. In same padding, the peak occurs at the same sample number as the middle of the pattern. In full padding, the peak occurs at the sample number when the pattern ends. Notice the negative peak for an opposite pattern.\n\nAlso, the kernel(pattern) is reversed, as we sent it that way, so that the convolution function will reverse it again making it a correlation.\n\nIn correlation a target signal goes along the input signal, multiplying the corresponding elements and summing them up. Now if the target signal happens to coincide with that portion of the input signal, it will only generate positive values which will sum up to a bigger number than the surrounding points. Convolution does the same, except it flips the kernel first, so in a way, convolution is matching the reverse of the kernel in the input signal.\n\n\n  Note: Convolution and Correlation seem very similar, but they are very different operations when it comes to the Signal Processing. Convolution is related to how linear systems produce outputs while correlation is used for pattern matching in signals. It is just that their math is very similar.\n\n\nI think this is a good stopping point. Although we only covered one dimensional signals, this gave us a good idea into how and what convolution as well as correlation is and does. We will next start how we can convolve in higher dimensional spatial signal, like pictures and other data. Since ConvNets are mostly used on image data, we will introduce those concepts in the next one along with the basic idea of how convolutions work.\n\nReferences\n\n\n  Steven W. Smith. The Scientist and Engineer’s Guide to Digital Signal Processing.\n  I. Goodfellow, Y. Bengio and A. Courville. Deep Learning.\n  https://lpsa.swarthmore.edu/Convolution/Convolution.html"
					}
					
				
		
				
					,
					
					"notes-neural-networks-convolutional-neural-networks-index": {
						"id": "notes-neural-networks-convolutional-neural-networks-index",
						"title": "Convolutional Neural Networks",
						"categories": "",
						"url": " /notes/neural_networks/convolutional_neural_networks/index",
						"content": "Convolutional Neural Networks\n\nIntroduction\n\nOn September 30, 2012, Alex Krizhevsky competed in the ImageNet Large Scale Visual Recognition Challenge. His submission achieved a top-5 error rate of 15.3%. The runner up had an error rate of 26.1% giving a huge 10.8 points lead. What was so special about this model? He will go on to publish his model architechture and techniques in his paper, AlexNet. This would revolutionize the Deep Learning community that had been dormant for long. At the time of writing this(April 2020), AlexNet paper has been cited about 60,833 times. The one of the most important feature, among others, was that it was a Convolutional Neural Network.\n\nThis series will be devoted to learn about the Convolutional Neural Networks -  the mathematics, the implementations, the results. Nowadays, CNNs have become very popular in the visual learning and so it is mostly taught with image examples. I, however, would like to take other examples as well, so that the reader may not just find it highly correlating with just the visual aspect of it and lose sight of the general notion of CNNs.\n\nWe will first start with convolutions, more precisely, discrete convolutions. We will try to understand what a convolution is. Why do we do convolutions at all? What does it mean to do a convolution? and the mathematics and other parts around it.\n\n\n\n\n\nConvolutions\n\nA description of mathematics of Convolution operation in terms of signal processing. . .  read more"
					}
					
				
		
				
					,
					
					"notes-neural-networks-index": {
						"id": "notes-neural-networks-index",
						"title": "Neural Networks",
						"categories": "",
						"url": " /notes/neural_networks/index",
						"content": "Convolutional Neural Networks \n        A Series of posts on the famous convNets.\n      \n      \n        Show more \n      \n    \n        \n\n\n    \n        \n    \n      \n      \n        \n        Multi-Layer Perceptron \n        A Series of posts on the Multi-Layer Perceptron...\n      \n      \n        Show more"
					}
					
				
		
				
					,
					
					"notes-neural-networks-multiayer-perceptron-improvements-to-mlp": {
						"id": "notes-neural-networks-multiayer-perceptron-improvements-to-mlp",
						"title": "The Multi Layer Perceptron Part  II",
						"categories": "",
						"url": " /notes/neural_networks/multiayer-perceptron/improvements-to-mlp",
						"content": "3 Improvements for the network\n\n3.1 Introduction\n\nAs you can see, the network takes a lot of time to train. Sometimes the network may not converge at all even after a lot of iterations. It is because the error get’s stuck at a local minima. Since we update the weights from all the examples at the same time, the error follows the direction of the steepest gradient. But the steepest gradrient may lead to a local minima and so no number of iterations will help it overcome that minima. These are problems with the gradient descent algorithm and hence apply to every model that uses it not just the MLP. Now there are ways around it:\n\n1. Changing Learning Rate:\n\nIf the local minima has a small “width”, then a higher learning rate may just jump over it. However it makes the network unstable.\n\n2. Multiple models with random initialization:\n\nWe train the same model multiple times with different starting points and maybe from any other starting point the steepest gradient is towards global minima. This is very effective for small models. But some larger models take weeks to train, which have hundreds of millions of datapoints and we cannot afford to train multiple models.\n\n3. Mini-Batch and Stochastic Gradient Descent:\n\nThe algorithm we have implemented is called a Batch Gradient Descent. We update the weights for every example at the same time. But sometimes the dataset is too large to perform matrix operations and so we use small random batches of data from the large dataset and update weights for them. We keep on doing this until all the data is utilized and then start another iteration again. It is called Mini-Batch Gradient Descent. Now at each weight update i.e at every step of gradient descent isn’t towards the steepest gradient of error for all examples but for just this mini-batch that we used. The downside is it may not take the best steps towards the minima but will eventually reach there after taking a “longer road”. The upside is it may sometimes not get stuck at a local minima as it may not have the steepest gradient for that training batch. Since it can avoid a local minima, we often use it in a dataset where complete batch gradient descent can be used as well. The number of examples used in a batch is called batch size. If the batch size is one,i.e if we update weight after every example, it is called Stochastic Gradient Descent. Remember, bigger the batch size, better steps it will take to minima and smaller the batch size, more deviated the path and so higher chances of avoiding local minima. There is a middle ground we need to find to make the training better.\nRemember it may also cause to deviate from the global minimum and reach a local minimum.\n\n3.2 SGD and Mini-Batch Implementation\n\nLet’s do a batch implementation of MLP and let’s also include a regression version.\n\nclass MLP_batch:\n    def init_weights(self,layer_sizes,random_state):\n        #save weights in a list of matrices\n        np.random.seed(random_state)\n        self.weights = [np.random.rand(layer_sizes[l-1]+1,layer_sizes[l])*(2/np.sqrt(layer_sizes[l-1]))-(1/np.sqrt(layer_sizes[l-1])) for l in range(1,len(layer_sizes))]\n    def sigmoid(self,x):\n        return 1/(1+np.exp(-x)) # keep beta = 1\n    \n    def forward(self,A_0,is_regression,weights=None):\n        self.outputs=[]\n        A_l = A_0\n        self.outputs.append(A_0)\n        if weights is None:\n            weights = self.weights\n        for weight in weights:\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1) # add bias to input data\n            H_l = np.matmul(A_lbias,weight) # compute the summation\n            A_l = self.sigmoid(H_l) # compute the activation\n            self.outputs.append(A_l)\n        if is_regression:\n            A_l = H_l\n            self.outputs.pop()\n            self.outputs.append(A_l)\n        return A_l # return the final output\n            \n    def backward(self,T, learning_rate,is_regression,batch_size):\n        A_L = self.outputs[-1]\n        if is_regression:\n            delta_L = A_L-T\n        else:\n            delta_L = (A_L-T)*(A_L*(1-A_L)) # beta = 0\n        delta_l_next = delta_L\n        \n        for i in range(len(self.weights)-1,-1,-1):\n#             print(i)\n            A_l = self.outputs[i]\n            #compute error for previous layer\n            delta_l = A_l*(1-A_l)*(np.matmul(delta_l_next,np.transpose(self.weights[i][1:,:])))\n#             A_0 A_1 A_2\n#             W_1 W_2\n#             0   1    2\n            # add bias output to output matrix\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1)\n            #update weights using the next errors\n            self.weights[i] = self.weights[i]- (1/batch_size)*(learning_rate*(np.matmul(np.transpose(A_lbias),delta_l_next)))\n            # change the next errors for next layer\n            delta_l_next = delta_l\n            \n        \n            \n            \n    \n    def train(self,input_data,input_target, epochs,layer_sizes=(100,), \n              learning_rate=0.01,batch_size=None,is_regression=False,random_state=0,verbose=0, save_weights=False):\n        \n        \n        X = np.array(input_data)\n        Target = np.array(input_target)\n        layer_sizes=list(layer_sizes)\n        layer_sizes.insert(0,X.shape[1])\n        n_outputs = np.unique(Target).shape[0] if np.unique(Target).shape[0]  != 2 and not is_regression else 1\n        layer_sizes.append(n_outputs)\n        \n        \n        self.init_weights(layer_sizes, random_state=random_state)\n        if save_weights:\n            self.saved_weights = [self.weights.copy()]\n            \n        if batch_size is None:\n            batch_size=X.shape[0]\n        for e in range(epochs):\n            \n                \n            \n    \n            # shuffle the input so we don't train on same sequences\n            idx = np.arange(0,Target.shape[0])\n            np.random.shuffle(idx)\n            X=X[idx]\n            Target=Target[idx]\n            \n            b=0\n            while b&lt;X.shape[0]:\n                A_0=X[b:b+batch_size,:]\n                T=Target[b:b+batch_size,:]\n                A_L = self.forward(A_0,is_regression)\n                if e%((epochs//10)+1) == 0 and verbose:\n                    print(\"epoch:\",e)\n                    print(f\"Error: {np.sum((A_L-T)**2)/T.shape[0]}\")\n                    print(f\"out: {A_L}\")\n    #                 print(\"weights\",*self.weights,sep='\\n',end='\\n\\n')\n                self.backward(T,learning_rate,is_regression,batch_size)\n\n\n                if save_weights:\n                    self.saved_weights.append(self.weights.copy())\n             ---\ntitle: The Multi Layer Perceptron Part  II\ndescription: A complete description of mathematics that go in making a multi layered perceptron work.\ntags: \n - neural networks\n - momentum\nhasplot: true\ncoll: neural_network\n---\n   b=b+batch_size\n        print(f\"Error: {np.sum((A_L-T)**2)/T.shape[0]}\")\n        \n    def predict(self,input_data,weights=None):\n        output = self.forward(np.array(input_data),weights)\n        #since this output is a realnumber(between 0 &amp; 1)\n        # we will have a threshold to predict its class for now 0.5\n        output = (output&gt;0.5)*1\n        return output\n    \n    def confmat(self,input_data,targets):\n        '''returns the confusion matrix for binary classification'''\n        outputs = self.predict(np.array(input_data))\n        T = np.array(targets).reshape(outputs.shape)\n        tp = ((T==1)&amp;(outputs==1)).sum()\n        tn = ((T==0)&amp;(outputs==0)).sum()\n        fp = ((T==0)&amp;(outputs==1)).sum()\n        fn = ((T==1)&amp;(outputs==0)).sum()\n        return np.array([[tp,fp],\n                        [fn,tn]])\n\n\n\nLet’s make a simple regression dataset that has just one feature and it’s target is a simple linear function to clear things.\n\nnp.random.seed(364)\nX = np.random.random((12000,1))\nT = 25*X+7.8\n\n\nLet’s now try different forms of gradient descent on it. Also set the random state so we have the same starting points. We will also check the training time for the same number of epochs along with the error.\n\n3.2.2 Results\n\n#Batch Gradient Descent(Full Dataset)\nbatch_model=MLP_batch()\n%time batch_model.train(X,T,layer_sizes=(),epochs=80,is_regression=True,learning_rate=1,random_state=0)\n\n\nError: 0.0004875391124500146\nCPU times: user 138 ms, sys: 47 µs, total: 138 ms\nWall time: 81.9 ms\n\n\nmini_batch1024 = MLP_batch()\n%time mini_batch1024.train(X,T,layer_sizes=(),epochs=80,is_regression=True,learning_rate=1,random_state=0,batch_size=1024)\n\n\nError: 1.834208786827062e-29\nCPU times: user 197 ms, sys: 0 ns, total: 197 ms\nWall time: 100 ms\n\n\nmini_batch64 = MLP_batch()\n%time mini_batch64.train(X,T,layer_sizes=(),epochs=80,is_regression=True,learning_rate=1,random_state=0,batch_size=64)\n\n\nError: 4.0429121392576855e-30\nCPU times: user 611 ms, sys: 3.93 ms, total: 615 ms\nWall time: 614 ms\n\n\n# for SGD, we will set batch_size=1\nSGD = MLP_batch()\n%time SGD.train(X,T,layer_sizes=(),epochs=80,is_regression=True,learning_rate=1,random_state=0,batch_size=1)\n\n\nError: 0.0\nCPU times: user 30.8 s, sys: 347 ms, total: 31.2 s\nWall time: 30.7 s\n\n\nAs you can see, SGD performed the best while taking a lot of time to train. Both of these because it made much more weight updates than any of them. For equal number of weight updates, the batch version should perform best.\n\nNow let’s try keeping the weight updates to be same, the best way is to let SGD go over the dataset atleast once. So that is a 12000 weight updates.\n\n#Batch Gradient Descent(Full Dataset)\nbatch_model=MLP_batch()\n%time batch_model.train(X,T,layer_sizes=(),epochs=12000,is_regression=True,learning_rate=1e-2,random_state=0)\n\n\nError: 3.255002724680526e-06\nCPU times: user 13.6 s, sys: 90.9 ms, total: 13.7 s\nWall time: 6.87 s\n\n\nmini_batch1024 = MLP_batch()\n%time mini_batch1024.train(X,T,layer_sizes=(),epochs=1024,is_regression=True,learning_rate=1e-2,random_state=0,batch_size=1024)\n\n\nError: 3.2897801810988825e-06\nCPU times: user 2.34 s, sys: 15.8 ms, total: 2.35 s\nWall time: 1.18 s\n\n\nmini_batch64 = MLP_batch()\n%time mini_batch64.train(X,T,layer_sizes=(),epochs=64,is_regression=True,learning_rate=1e-2,random_state=0,batch_size=64)\n\n\nError: 3.473449823532693e-06\nCPU times: user 515 ms, sys: 25 µs, total: 515 ms\nWall time: 512 ms\n\n\n# for SGD, we will set batch_size=1\nSGD = MLP_batch()\n%time SGD.train(X,T,layer_sizes=(),epochs=1,is_regression=True,learning_rate=1e-2,random_state=0,batch_size=1)\n\n\nError: 6.853664577305198e-06\nCPU times: user 480 ms, sys: 40.5 ms, total: 521 ms\nWall time: 464 ms\n\n\nAs you can see the opposite has happened, the batch version has done great but in most time and SGD has done worst in least time. But the mini batch of 1024 examples has done acceptable in very small time. We could prefer this model over both the models. It is the middle ground we need to find and depends on what can we spare, time or cost? It also depends on the type of dataset we are using. That stuff is for trial and error, atleast for now.\n\n3.3 Visualization\n\nNow let’s see how the weights are updated. But before that let’s project out data error in a chart. Let’s see how the error varies as with the weight. We will plot the weights on x and y axis and error on z axis.\n\ndef compute_multiple_error(X,T,xx,yy):\n    print(\"computing error\")\n    e = (T[0]-(xx*X[0]-yy))**2\n    for i in range(1,len(X)):\n        if (i+1)%1000==0:\n            print(f\"{i+1}/{len(X)} done\")\n        e = e+(T[i]-(xx*X[i]-yy))**2\n    return (1/T.shape[0])*e\n    \n\n\nxx,yy = np.meshgrid(np.linspace(-5,35,1000),np.linspace(-30,5,1000))\nerr = compute_multiple_error(X,T,xx,yy)\n\n\ncomputing error\n1000/12000 done\n2000/12000 done\n3000/12000 done\n4000/12000 done\n5000/12000 done\n6000/12000 done\n7000/12000 done\n8000/12000 done\n9000/12000 done\n10000/12000 done\n11000/12000 done\n12000/12000 done\n\n\nfig = go.Figure()\nfig.add_trace(go.Surface(x=xx,y=yy,z=err))\nfig.update_layout(\n        scene = {\n            \"xaxis\": {\"title\": \"Weight 1\"},\n            \"zaxis\": {\"title\": \"Error\"},\n            \"yaxis\": {\"title\": \"Weight 2\"}\n        })\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs you can see, this surface has a minimum. A 3D graph looks clumsy, let’s use contours of this 3D plot. However plotly doesn’t support uneven labels, we will use the logarithm of error to make the plots have regular contours.\n\nfig = go.Figure(data=\n                [go.Contour(\n                    x=xx[0],\n                    y=yy[:,0],\n                    z=np.log1p(err),\n                    contours_coloring='lines',\n                    line_width=2,\n                    showscale=False,\n                )\n                ],\n                layout=dict(xaxis_title=\"Weight 1\",\n                           yaxis_title=\" Weight 2\",\n                           width=915, height=800,),\n                \n               )\nfig.add_trace(go.Scatter(x=[25],y=[-7.8],marker=dict(symbol=\"x\", size=10)))\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nThese are the contour lines and the cross(x) sign is the minimum of the error, we want our models to descend to that point. Let’s see how each model does it. Each line has zero gradient(i.e they lie on the same level) and the perpendicular direction at each line is the steepest gradient.\n\nbatch_model=MLP_batch()\nbatch_model.train(X,T,layer_sizes=(),epochs=150,is_regression=True,learning_rate=1,random_state=0,save_weights=True)\n\nmini_batch1024 = MLP_batch()\nmini_batch1024.train(X,T,layer_sizes=(),epochs=100,is_regression=True,learning_rate=1,random_state=0,\n                     batch_size=1024,save_weights=True)\nmini_batch64 = MLP_batch()\nmini_batch64.train(X,T,layer_sizes=(),epochs=1,is_regression=True,learning_rate=1,random_state=0,\n                     batch_size=64,save_weights=True)\n\n\nSGD = MLP_batch()\nSGD.train(X,T,layer_sizes=(),epochs=1,is_regression=True,learning_rate=1,random_state=0,batch_size=1,save_weights=True)\n\n\nError: 3.796053431101478e-08\nError: 1.8660418967252465e-29\nError: 2.1144567049716302e-10\nError: 0.0\n\n\nweights=[np.concatenate([i[0] for i in m.saved_weights],axis=1) for m in (batch_model,mini_batch1024,mini_batch64,SGD)]\n\n\nLet’s now draw every weight update\n\nfig = go.Figure()\n\nfig.add_trace(go.Contour(x=xx[0], y=yy[:,0], z=np.log1p(err), autocontour=False, \n                         line_width=2, showscale=False,contours_coloring='lines', \n                        ),\n             )\nfig.add_trace(go.Scatter(x=[25],y=[-7.8],mode=\"markers\",marker=dict(symbol=\"x\", size=10, color=\"red\"),\n                         name=\"Minimum\"),)\n\nfor p,name,color,opacity in zip(range(4),\n                        ['Full Batch','1024','64','1(SGD)'],\n                        ['Blue',\"Cyan\",\"Green\",\"Magenta\"],\n                        [1,0.8,0.8,0.8]):\n    fig.add_trace(go.Scatter(x=weights[p][1,:],y=weights[p][0,:],name=name,opacity=opacity,\n                             mode=\"lines+markers\",line=dict(color=color, width=2)),)\n\n\nfig.update_layout(legend=dict(x=0.8, y=1),height=800,width=915)\n\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs you can see, the bigger the batch size, the better the weight updates are. Also look the full batch version took steps which were perpendicular to the contour line at every point(i.e the steepest gradient). But we cannot always afford to use full dataset at one time. And besides, this random-looking update might help us to deviate from local minima. Still we can use a few more tricks to make it faster and better.\n\n3.4 The Momentum\n\nWhile using the Mini-Batch or Stochastic Gradient Descent, we use certain ways to keep the weights on track and not deviate too much. One of them is called picking up the momentum. Since in SGD or MBD, each weight update is based upon just the examples we are considering, the weights are change according to just that batch and does not consider the whole dataset and make training longer, especially when there is no local minima and traing set is very large.\n\nThe idea is to not just update the weights from the current batch’s \\(\\Delta w\\), but from the previous batch as well.\nSo, we update the weight of any layer \\(l\\), iteration \\(t\\) as:\n\n\n\nwhere,\n\n\n\nand\n\n\n  \\(w^{(l,t)}_{pq}\\) is the weight of layer \\(l\\) of iteration \\(t\\).\n  \\(\\alpha\\) is the weightage for the previous weight update. \\(0.9\\) is a good number.\n\n\nNote: iteration means a weight update and not an epoch.\n\nHowever that method is effective as it can be, but we will need to tune learning rate again and it has different impact. The current weight has a weight of \\(\\eta\\) while the previous weight updates have \\(\\alpha\\) weight. Earlier all of it had weight of \\(\\eta\\). So the proposition here is to assign a weight of \\(1-\\alpha\\) to the current update and \\(\\alpha\\) to previous ones so to make a total weight of unity and then we use the learning rate all over it.\n\nLike:\n\n\n\nIt can be easily done by:\n\ndelta_w = (1-momentum)*(1/batch_size)*(np.matmul(np.transpose(A_lbias),delta_l_next)) + momentum*delta_w\nweight = weight - learning_rate*delta_w\n\n\nLet’s try to write it up. We need just a few changes in the code.\n\nclass MLP_momentum:\n    def init_weights(self,layer_sizes,random_state):\n        #save weights in a list of matrices\n        np.random.seed(random_state)\n        self.weights = [np.random.rand(layer_sizes[l-1]+1,layer_sizes[l])*(2/np.sqrt(layer_sizes[l-1]))-(1/np.sqrt(layer_sizes[l-1])) for l in range(1,len(layer_sizes))]\n    def sigmoid(self,x):\n        return 1/(1+np.exp(-x)) # keep beta = 1\n    \n    def forward(self,A_0,is_regression,weights=None):\n        self.outputs=[]\n        A_l = A_0\n        self.outputs.append(A_0)\n        if weights is None:\n            weights = self.weights\n        for weight in weights:\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1) # add bias to input data\n            H_l = np.matmul(A_lbias,weight) # compute the summation\n            A_l = self.sigmoid(H_l) # compute the activation\n            self.outputs.append(A_l)\n        if is_regression:\n            A_l = H_l\n            self.outputs.pop()\n            self.outputs.append(A_l)\n        return A_l # return the final output\n            \n    def backward(self,T, learning_rate,is_regression,batch_size,momentum,delta_w):\n        A_L = self.outputs[-1]\n        if is_regression:\n            delta_L = A_L-T\n        else:\n            delta_L = (A_L-T)*(A_L*(1-A_L)) # beta = 0\n        delta_l_next = delta_L\n        \n        for i in range(len(self.weights)-1,-1,-1):\n#             print(i)\n            A_l = self.outputs[i]\n            #compute error for previous layer\n            delta_l = A_l*(1-A_l)*(np.matmul(delta_l_next,np.transpose(self.weights[i][1:,:])))\n#             A_0 A_1 A_2\n#             W_1 W_2\n#             0   1    2\n            # add bias output to output matrix\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1)\n        \n            # compute delta_w\n            delta_w[i] = (1-momentum)*(1/batch_size)*(np.matmul(np.transpose(A_lbias),delta_l_next)) + momentum*delta_w[i]\n            \n            \n            #update weights using the next errors\n            self.weights[i] = self.weights[i] - learning_rate*delta_w[i]\n            # change the next errors for next layer\n            delta_l_next = delta_l\n        return delta_w\n            \n        \n            \n            \n    \n    def train(self, input_data, input_target, epochs, layer_sizes=(100,), \n              learning_rate=0.01, batch_size=None, is_regression=False,\n              momentum=0.9, random_state=0,verbose=0, save_weights=False,warm_start=False):\n        \n        \n        X = np.array(input_data)\n        Target = np.array(input_target)\n        layer_sizes=list(layer_sizes)\n        layer_sizes.insert(0,X.shape[1])\n        n_outputs = Target.shape[1]\n        layer_sizes.append(n_outputs)\n        \n        if not warm_start:\n            self.init_weights(layer_sizes, random_state=random_state)\n        if save_weights:\n            self.saved_weights = [self.weights.copy()]\n            \n        if batch_size is None:\n            batch_size=X.shape[0]\n        \n        # initialize delta_w to be zero for every layer\n        delta_w = [0*i for i in self.weights].copy()\n        for e in range(epochs):\n            \n                \n            \n    \n            # shuffle the input so we don't train on same sequences\n            idx = np.arange(0,Target.shape[0])\n            np.random.shuffle(idx)\n            X=X[idx]\n            Target=Target[idx]\n            \n            b=0\n            while b&lt;X.shape[0]:\n                A_0=X[b:b+batch_size,:]\n                T=Target[b:b+batch_size,:]\n                A_L = self.forward(A_0,is_regression)\n                if e%((epochs//10)+1) == 0 and verbose:\n                    print(\"epoch:\",e)\n                    print(f\"Error: {np.sum((A_L-T)**2)/T.shape[0]}\")\n#                     print(f\"out: {A_L}\")\n    #                 print(\"weights\",*self.weights,sep='\\n',end='\\n\\n')\n                delta_w = self.backward(T,learning_rate,is_regression,batch_size,momentum,delta_w)\n                \n\n                if save_weights:\n                    self.saved_weights.append(self.weights.copy())\n                b=b+batch_size\n        return np.sum((A_L-T)**2)/T.shape[0]\n        \n    def predict(self,input_data,weights=None):\n        output = self.forward(np.array(input_data),weights)\n        #since this output is a realnumber(between 0 &amp; 1)\n        # we will have a threshold to predict its class for now 0.5\n        output = (output&gt;0.5)*1\n        return output\n    \n    def confmat(self,input_data,targets):\n        '''returns the confusion matrix for binary classification'''\n        outputs = self.predict(np.array(input_data))\n        T = np.array(targets).reshape(outputs.shape)\n        tp = ((T==1)&amp;(outputs==1)).sum()\n        tn = ((T==0)&amp;(outputs==0)).sum()\n        fp = ((T==0)&amp;(outputs==1)).sum()\n        fn = ((T==1)&amp;(outputs==0)).sum()\n        return np.array([[tp,fp],\n                        [fn,tn]])\n\n\n\nSGD = MLP_momentum()\nSGD.train(X,T,layer_sizes=(),epochs=1,is_regression=True,learning_rate=1,random_state=0,\n          batch_size=1,save_weights=True,momentum=0)\nSGD_mom = MLP_momentum()\nSGD_mom.train(X,T,layer_sizes=(),epochs=1,is_regression=True,learning_rate=\n              1,random_state=0,\n          batch_size=1,save_weights=True,momentum=0.8)\n\n\n0.0\n\n\nweights=[np.concatenate([i[0] for i in m.saved_weights],axis=1) for m in (SGD,SGD_mom)]\n\n\nLet’s now draw every weight update\n\nfig = go.Figure()\n\nfig.add_trace(go.Contour(x=xx[0], y=yy[:,0], z=np.log1p(err), autocontour=False, \n                         line_width=2, showscale=False,contours_coloring='lines', \n                        ),\n             )\nfig.add_trace(go.Scatter(x=[25],y=[-7.8],mode=\"markers\",marker=dict(symbol=\"x\", size=10, color=\"red\"),\n                         name=\"Minimum\"),)\n\nfor p,name,color in zip(range(2),\n                        ['Without Momentum(SGD)','With Momentum(SGD)'],\n                        ['Blue',\"Red\",],\n                               ):\n    fig.add_trace(go.Scatter(x=weights[p][1,:],y=weights[p][0,:],name=name,opacity=opacity,\n                             mode=\"lines+markers\",\n                             line=dict(color=color, width=2)),\n                 )\n                 \n\n\nfig.update_layout(legend=dict(x=0.8, y=1),height=800,width=915,xaxis_title=\"Weight 1\", yaxis_title=\"Weight 2\",\n                 title=\"Contour Plot of Error\")\n\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs you can see, the updates are much more smooth for SGD. This also makes it possible to use smaller learning rate and thus making it more stable. Let’s now see for a complete batch and see something different.\n\nbatch_model=MLP_momentum()\nbatch_model.train(X,T,layer_sizes=(),epochs=150,is_regression=True,learning_rate=1,\n                  random_state=0,save_weights=True,momentum=0)\n\nbatch_model_mom=MLP_momentum()\nbatch_model_mom.train(X,T,layer_sizes=(),epochs=150,is_regression=True,learning_rate=1,\n                      random_state=0,save_weights=True,momentum=0.9)\n\n\n\n3.8757600362031304e-05\n\n\nweights=[np.concatenate([i[0] for i in m.saved_weights],axis=1) for m in (batch_model,batch_model_mom)]\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Contour(x=xx[0], y=yy[:,0], z=np.log1p(err), autocontour=False, \n                         line_width=2, showscale=False,contours_coloring='lines', \n                        ),\n             )\nfig.add_trace(go.Scatter(x=[25],y=[-7.8],mode=\"markers\",marker=dict(symbol=\"x\", size=10, color=\"red\"),\n                         name=\"Minimum\"),)\n\nfor p,name,color in zip(range(2),\n                        ['Without Momentum(Batch)','With Momentum(Batch)'],\n                        ['Blue',\"Red\",],\n                               ):\n    fig.add_trace(go.Scatter(x=weights[p][1,:],y=weights[p][0,:],name=name,opacity=opacity,\n                             mode=\"lines+markers\",\n                             line=dict(color=color, width=2)),\n                 )\n                 \n\n\nfig.update_layout(legend=dict(x=0.8, y=1),height=800,width=915,xaxis_title=\"Weight 1\", yaxis_title=\"Weight 2\",\n                 title=\"Contour Plot of Error\")\n\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nHere are a few important points to note:\n\n  \n    The step size increases as we go along the right gradient but decreases and eventually stops and changes once we are not moving along the gradient as if the weights cannot stop and have a certain momentum like a block of mass.\n  \n  \n    If we use the complete dataset as the batch, then, without momentum, it will take the best steps along the steepest gradient to the minima(local or global). But with momentum, it wanders off a little. It may even reach the minimum(local ot global) and yet go past it a bit(like a ball with momentum would). If it was a local minima, it may just cross the barrier and move to global minima. If it was a global minima, then it would oscillate a little and eventually stop.\n  \n  \n    For mini batch, it will depend on the batch size. If the batch size is too small, then it will act as it does for SGD,(i.e smoothen the weight updates) and if the batch size is too big, then it will act as it does for complete batch(i.e, deviate and move past minima). The batch size will decide the degree of it.\n  \n\n\nOur XOR data has probably a local minima(or a saddle point) which does not allow all the models to converge at the global minimum. Some initializations get stuck at a local minima. Here is one. try changing the epochs and learning rates, it is still very hard to get a very low error score. So we can improve it by the momentum. With the right momentum and the correct learning rate, we can get past this minima and get a lower score in very few epochs.\n\nsimple_model = MLP()\nsimple_model.train(XOR_inp,XOR_target,30001,layer_sizes=(2,),learning_rate=5, random_state=365)\n\n\nError: 0.1250841346167755\n\n\nmom_model = MLP_momentum()\nmom_model.train(XOR_inp,XOR_target,30001,layer_sizes=(2,),learning_rate=5, random_state=365,momentum=0.9)\n\n\n3.434487809294881e-05\n\n\nAnother thing we try is called Weight Decay. The argument goes as small weights try to keep the outputs in the linear middle part of the sigmoid which change faster than at the end points(because of the gradient). It is done by multiplying all the weights by a small constant \\(\\epsilon\\) after each iteraton. It makes the network simpler and  may improve the results, but it can also sometimes make the learning significantly worse. Choosing \\(\\epsilon\\) is done experimentally.\n\nWe will discuss more optimizations in detail later on.\n\n3.5 Misc\n\n3.5.1 Amount of Training Data\n\nSince there are many parameters(weights) to look for, there actually should be sufficient data to learn that. The amont of data actually depends on the problem, but a rule of thumb is to use data 10 times the number of weights.\n\n3.5.2 Number of Hidden layers and Nodes\n\nThese are two important decisions needed to be made to get a good result. How many hidden layers to use and how many nodes in each layer? Although there is no theory for number of nodes but according to Universal Approximation Theorem, just one hidden layer will do just fine. A combination of sigmoid layers can approxiamte to any function with the sufficient number of nodes. However that one layer might need a lot of hidden nodes, so two hidden layers are usually used to be safe. The two hidden layer systemwill work for most of the problems but there are always exceptions.\n\nWe will talk more about the Universal Approximation Theorem later on.\n\n3.5.2 When to Stop Training?\n\nThis is also an important factor deciding the results. We do not want to overfit the data nor to we want to underfit it. So it is better to use a validation data to check. We will continue to train untill both the training and validation error are reducing. At the point the validation error starts increasing, we stop the training.\n\n\n\nThis technique is called early stopping.\n\n4 MLP in Practice\n\nLet’s see some examples how MLP can be used.\n\n4.1 A Regression Problem\n\nLet’s try fitting a sine wave with a small noise as well.\n\nnp.random.seed(479)\nX = np.linspace(0,1,100).reshape(-1,1)\nT = np.sin(2*np.pi*X) + np.cos(4*np.pi*X)+np.random.randn(100,1)*0.4\n\n\n# plot the data\nfig = go.Figure(go.Scatter(x=X.squeeze(),y=T.squeeze(), mode=\"markers\"),\n                layout=dict(xaxis_title=\"Input\", yaxis_title=\"Target Values\")\n               )\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nLet’s now train an MLP on this data. But before that we will normalize the data and split it into training validation and test data in the ratio 4:1:1.\n\nX =(X-X.mean(axis=0))/X.var(axis=0)\nT =(T-T.mean(axis=0))/T.var(axis=0)\n\n\nidx = np.arange(X.shape[0])\nnp.random.shuffle(idx)\nX=X[idx,:]\nT=T[idx,:]\ntrain = X[:2*(X.shape[0]//3),:]\ntest = X[2*(X.shape[0]//3):2*(X.shape[0]//3)+(X.shape[0]//6):,:]\nval = X[2*(X.shape[0]//3)+(X.shape[0]//6):,:]\ntraintarget = T[:2*(X.shape[0]//3),:]\ntesttarget = T[2*(X.shape[0]//3):2*(X.shape[0]//3)+(X.shape[0]//6):,:]\nvaltarget = T[2*(X.shape[0]//3)+(X.shape[0]//6):,:]\n\n\n# plot the data\nfig = go.Figure(data=[go.Scatter(x=train.squeeze(),y=traintarget.squeeze(),mode=\"markers\", name=\"training set\"),\n                     go.Scatter(x=val.squeeze(),y=valtarget.squeeze(),mode=\"markers\",name=\"validation set\")],\n                layout=dict(xaxis_title=\"Input\", yaxis_title=\"Target Values\")\n               )\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nTo start with, we will use one hidden layer, with 3 nodes and learning rate of 0.25 for 101 epochs and see what the output is.\n\nm = MLP_momentum()\nm.train(train,traintarget,101,layer_sizes=(3,),learning_rate=0.25,is_regression=True,momentum=0.9,verbose=True,random_state=200)\n\n\nepoch: 0\nError: 0.9954347804927682\nepoch: 11\nError: 0.695684508117699\nepoch: 22\nError: 0.6610644383959196\nepoch: 33\nError: 0.6622483713072506\nepoch: 44\nError: 0.652190286530414\nepoch: 55\nError: 0.646344230816324\nepoch: 66\nError: 0.6426767619901053\nepoch: 77\nError: 0.63862336612565\nepoch: 88\nError: 0.6343649929165276\nepoch: 99\nError: 0.6300130633180782\n\n\n\n\n\n0.6296088646689288\n\n\nAs we can see, the error is decreasing, now we have to figure out a couple of things. First figure out the early stopping. We will keep track of last two validation errors after every 10 epochs to make sure the validation error actually increases(when it does!) and do not stop the program prematurely.\n\ntrain_error=[]\nval_error=[]\nm = MLP_momentum()\nm.train(train,traintarget,100,layer_sizes=(5,),learning_rate=0.25,is_regression=True,momentum=0.9)\nold_val_error1 = np.infty\nold_val_error2 = np.infty\nnew_error = (1/val.shape[0])*np.sum((m.forward(val,is_regression=True)-valtarget)**2)\nval_error.append(new_error)\ntrain_error.append((1/train.shape[0])*np.sum((m.forward(train,is_regression=True)-traintarget)**2))\ncount = 0\nwhile (((old_val_error1-new_error)&gt;0.0005) or ((old_val_error2-old_val_error1)&gt;0.0005)):\n    count+=1\n    m.train(train,traintarget,100,layer_sizes=(5,),learning_rate=0.25,is_regression=True,momentum=0,warm_start=True)\n    old_val_error2=old_val_error1\n    old_val_error1=new_error\n    new_error = (1/val.shape[0])*np.sum((m.forward(val,is_regression=True)-valtarget)**2)\n    val_error.append(new_error)\n    train_error.append((1/train.shape[0])*np.sum((m.forward(train,is_regression=True)-traintarget)**2))\n    \nprint(\"learning_stopped at epoch:\", count*100)\nextra_train_error=[]\nextra_val_error=[]\nfor i in range(10):\n    m.train(train,traintarget,100,layer_sizes=(5,),learning_rate=0.25,is_regression=True,momentum=0.9,warm_start=True)\n    old_val_error2=old_val_error1\n    old_val_error1=new_error\n    new_error = (1/val.shape[0])*np.sum((m.forward(val,is_regression=True)-valtarget)**2)\n    extra_val_error.append(new_error)\n    extra_train_error.append((1/train.shape[0])*np.sum((m.forward(train,is_regression=True)-traintarget)**2))\n \n\n\n\nlearning_stopped at epoch: 1600\n\n\nfig = go.Figure(data=[\n    go.Scatter(y=train_error,name=\"train error before early stopping\"),\n    go.Scatter(y=val_error, name=\"validation error before early stoppping\"),\n    go.Scatter(x=list(range(len(train_error),len(train_error)+len(extra_train_error))),y=extra_train_error,\n               name= \"train error after early stopping\"),\n    go.Scatter(x=list(range(len(val_error),len(val_error)+len(extra_val_error))),y=extra_val_error,\n               name= \"validation error after early stopping\"),    \n],\n               layout=dict(xaxis_title=\"Epochs x100\", yaxis_title=\"Sum of Squares Error\"))\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs you can see there is not much change in the error after the early stopping point. We have found the for how long the network to be run but now let’s figure how many hidden nodes to be used.\n\nWe already have a early stopping function and we will run this for different sizes of hidden nodes and record the results. However we will run each model 10 times with different initialization and work on averages.\n\ndef early_stopping(train,traintarget,val,valtarget,epochs,layer_sizes,learning_rate,\n                   is_regression,momentum,random_state,diff=0.001):\n    m = MLP_momentum()\n    error=m.train(train,traintarget,epochs,layer_sizes=layer_sizes,learning_rate=learning_rate,\n            is_regression=is_regression,momentum=momentum,random_state=random_state)\n    \n    old_val_error1 = 2000000000\n    old_val_error2 = 1999999999\n    new_error = (1/val.shape[0])*np.sum((m.forward(val,is_regression=True)-valtarget)**2)\n    \n    count = 0\n    while (((old_val_error1-new_error)&gt;diff) or ((old_val_error2-old_val_error1)&gt;diff)):\n        count+=epochs\n        error = m.train(train,traintarget,epochs,layer_sizes=layer_sizes,learning_rate=learning_rate,\n            is_regression=is_regression,momentum=momentum,random_state=random_state,warm_start=True)\n        \n        old_val_error2=old_val_error1\n        old_val_error1=new_error\n        new_error = (1/val.shape[0])*np.sum((m.forward(val,is_regression=True)-valtarget)**2)\n    return m, new_error\n\n\nWe will save error for every differnt initialization and work on averages, standard deviations, minimums and maximums. We will use a pandas dataframe to form a table.\n\nimport pandas as pd\n\n\nhidden_units = [1,2,3,5,10,25]\ndf = pd.DataFrame(index=[\"Mean Error\",\"Standard Deviation\", \"Max Error\", \"Min Error\"])\nfor unit in hidden_units:\n    errors = np.array([early_stopping(train,traintarget,val,valtarget,10,(unit,),0.25,True,0,\n                                      np.random.randint(0,12000))[1] for i in range(10)])\n    df[str(unit)]=[errors.mean(),errors.std(),errors.max(),errors.min()]\n    print(f\"Units done: {unit}\")\n\n\nUnits done: 1\nUnits done: 2\nUnits done: 3\nUnits done: 5\nUnits done: 10\nUnits done: 25\n\n\ndf\n\n\n|   | 1 | 2 | 3 | 5 | 10 | 25 |\n|---|---|---|---|---|---|---|\n|Mean Error |0.423110  |0.337027  |0.221558  |0.203000  |0.168734  |1.118023  |\n|Standard Deviation  |0.000311  |0.126717  |0.117290  |0.105529  |0.085867  |1.072914  |\n|Max Error  |0.423543  |0.429690  |0.405281  |0.421871  |0.422707  |3.377288  |\n|Min Error  |0.422477  |0.141333  |0.139736  |0.145992  |0.122757  |0.244395  |\n\n\nTake a look at both the mean(or max) error and standard deviation of each model with their hidden nodes. We prefer the model with low error (mean and max) and low standard deviation. We can also change learning rate and test out the results. Also we can try more layers and optimize the nodes in each layer.\n\nFinal Code\n\nBefore starting the next part we have to add a bunch of stuff to our code, implementing the cross-entropy error. We will also include the early stopping method with it. We will also fix the confusion matrix for multiple classes.\n\nclass MLP:\n    def init_weights(self,layer_sizes,random_state):\n        #save weights in a list of matrices\n        np.random.seed(random_state)\n        self.weights = [np.random.rand(layer_sizes[l-1]+1,layer_sizes[l])*(2/np.sqrt(layer_sizes[l-1]))-(1/np.sqrt(layer_sizes[l-1])) for l in range(1,len(layer_sizes))]\n    def sigmoid(self,x):\n        return 1/(1+np.exp(-x)) # keep beta = 1\n    \n    def forward(self,A_0,is_regression,weights=None):\n        self.outputs=[]\n        A_l = A_0\n        self.outputs.append(A_0)\n        if weights is None:\n            weights = self.weights\n        for weight in weights:\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1) # add bias to input data\n            H_l = np.matmul(A_lbias,weight) # compute the summation\n            A_l = self.sigmoid(H_l) # compute the activation\n            self.outputs.append(A_l)\n        if is_regression:\n            A_l = H_l\n            self.outputs.pop()\n            self.outputs.append(A_l)\n        return A_l # return the final output\n            \n    def backward(self,T, learning_rate,is_regression,batch_size,momentum,delta_w,loss):\n        A_L = self.outputs[-1]\n        if is_regression:\n            delta_L = A_L-T\n        elif loss == 'sumofsquares':\n            delta_L = (A_L-T)*(A_L*(1-A_L)) # beta = 0\n        elif loss == 'crossentropy':\n#             delta_L = (T*(A_L-1)*A_L)\n            delta_L= A_L-T\n        delta_l_next = delta_L\n        \n        for i in range(len(self.weights)-1,-1,-1):\n            A_l = self.outputs[i]\n            #compute error for previous layer\n            delta_l = A_l*(1-A_l)*(np.matmul(delta_l_next,np.transpose(self.weights[i][1:,:])))\n\n            # add bias output to output matrix\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1)\n        \n            # compute delta_w\n            delta_w[i] = (1-momentum)*(1/batch_size)*(np.matmul(np.transpose(A_lbias),delta_l_next)) + momentum*delta_w[i]\n            \n            \n            #update weights using the next errors\n            self.weights[i] = self.weights[i] - learning_rate*delta_w[i]\n            \n            # change the next errors for next layer\n            delta_l_next = delta_l\n        return delta_w\n            \n    def compute_error(self,A_L,T,loss):\n        if loss == 'sumofsquares':\n            return np.sum((A_L-T)**2)/T.shape[0]\n        \n        if loss == 'crossentropy':\n            return -np.sum(T*(np.log(A_L))+(1-T)*(np.log(1-A_L)))/T.shape[0]\n            \n            \n            \n    \n    def train(self, input_data, input_target, epochs, layer_sizes=(100,), \n              learning_rate=0.01, batch_size=None,loss='sumofsquares', is_regression=False,\n              momentum=0.9, random_state=0,verbose=0, save_weights=False,warm_start=False):\n        \n        \n        X = np.array(input_data)\n        Target = np.array(input_target)\n        layer_sizes=list(layer_sizes)\n        layer_sizes.insert(0,X.shape[1])\n        n_outputs = Target.shape[1]\n        layer_sizes.append(n_outputs)\n        \n        if not warm_start:\n            self.init_weights(layer_sizes, random_state=random_state)\n        if save_weights:\n            self.saved_weights = [self.weights.copy()]\n            \n        if batch_size is None:\n            batch_size=X.shape[0]\n        \n        # initialize delta_w to be zero for every layer\n        delta_w = [0*i for i in self.weights].copy()\n        for e in range(epochs):\n            \n                \n            \n    \n            # shuffle the input so we don't train on same sequences\n            idx = np.arange(0,Target.shape[0])\n            np.random.shuffle(idx)\n            X=X[idx]\n            Target=Target[idx]\n            \n            b=0\n            while b&lt;X.shape[0]:\n                A_0=X[b:b+batch_size,:]\n                T=Target[b:b+batch_size,:]\n                A_L = self.forward(A_0,is_regression)\n                if e%((epochs//10)+1) == 0 and verbose:\n                    print(\"epoch:\",e)\n                    print(f\"Error: {self.compute_error(A_L,T,loss)}\")\n                delta_w = self.backward(T,learning_rate,is_regression,batch_size,momentum,delta_w,loss)\n                \n\n                if save_weights:\n                    self.saved_weights.append(self.weights.copy())\n                b=b+batch_size\n        return self.compute_error(A_L,T,loss)\n    \n    def early_stopping(self,train,traintarget,val,valtarget,epochs,layer_sizes,learning_rate,\n                       is_regression,momentum,batch_size=None, diff=0.01,random_state=0,loss='sumofsquares'):\n        error = self.train(train,traintarget,epochs,layer_sizes=layer_sizes,learning_rate=learning_rate,\n                           is_regression=is_regression,momentum=momentum,batch_size=batch_size,\n                           loss=loss,random_state=random_state)\n        old_val_error1 = 2000000000\n        old_val_error2 = 1999999999\n        new_error = self.compute_error(self.forward(val,is_regression=is_regression),valtarget,loss)\n        \n        count = 0\n        while (((old_val_error1-new_error)&gt;diff) or ((old_val_error2-old_val_error1)&gt;diff)):\n            count+=epochs\n            error = self.train(train,traintarget,epochs,layer_sizes=layer_sizes,learning_rate=learning_rate,\n                is_regression=is_regression,momentum=momentum,random_state=random_state,loss=loss,warm_start=True)\n\n            old_val_error2=old_val_error1\n            old_val_error1=new_error\n            new_error = self.compute_error(self.forward(val,is_regression=is_regression),valtarget,loss)\n        return new_error\n    \n    \n    def predict(self,input_data,weights=None):\n        output = self.forward(np.array(input_data),weights)\n        #since this output is a realnumber(between 0 &amp; 1)\n        # we will have a threshold to predict its class for now 0.5\n        output = (output&gt;0.5)*1\n        return output\n    \n    def confmat(self,input_data,targets):\n        '''returns the confusion matrix for binary classification'''\n        out = np.argmax(m.forward(input_data,is_regression=False),axis=1)\n        t = np.argmax(targets,axis=1)\n        mat = np.zeros([np.unique(t).shape[0]]*2)\n        for i in np.unique(t):\n            for j in np.unique(t):\n                mat[i,j]=np.sum((out==i) &amp; (t==j))\n        return mat,np.sum(mat*np.eye(mat.shape[0]))/np.sum(mat)\n\n\n\nLet’s save this model in our utils.py file.\n\n4.2 A Classification Problem\n\nThere are multiple ways to approach a classification problem. The inputs are the features normalized and there are a couple of choices for outputs.\n\n\n  The first is to use a single linear node and then put some threshold for different outputs. For example, for a 4 class problem we can use:\n\n\n\nBut this gets impractical when the number of classes gets large and the boundaries are artificial; say what about the output 0.5? We classify it as \\(C_3\\), but the network gives us no information that how hard this example was to classify.\n\n\n  A more suitable way is to use output is called \\(1\\text{-of-}N\\) encoding. A separate node is used to represent each posiible class and the target vector consists of zeros everywhere except for the class we are representing, e.g (0,0,1,0,0) means the third class out of 5. We are using binary output for each output node.\n\n\nWe can use one of two ways to select a class. After all the output neurons have given their sigmoidal outputs, we can now choose the neuron to be 1 which has highest value and all others are Zero. This makes the result unambigious, since it is highly unlikely that two neurons have same values and they both happen to be the maximum values. This is called Hard Max method. We can also use the Soft Max version, where we first scale the the outputs to be comparable to each other and the sum also adds up to 1. It gives us the probability of that class(more or less!). So if there is a clear winner that neuron will be close to 1, otherwise if there are other similar values they will each have a value of \\(\\frac{1}{p}\\), where \\(p\\) is the number of output neurons that have similar values.\n\nThere is another problem with the classification process. It is called class imablance. If we have, say, two class and we have 90% of training data for class 1, then the classifier will learn to always predict class 1, irrespective of the data. It will surely give it a 90% accuracy, but it is  a bad classifier. All the training examples from each classes should almost same. We may randomly throw off some data from the class which has larger data. There is another method called as novelty detection, where we train the whole model on just the over-represented data and then just predict if the data is different or similar to the training data. We will cover it in detail later.\n\nThe Iris Dataset:\nThis data is concerned with classification of iris flower into different species. This data is already available in sklearn library. This data contains features of ‘sepal length’, ‘sepal width’, ‘petal length’, ‘petal width’. There are three targets, the species, viz, ‘setosa’, ‘versicolor’, ‘virginica’. These are encoded as 0,1,2 respectively.\n\nfrom sklearn.datasets import load_iris\n\n\ndata = load_iris()['data']\ntarget = load_iris()['target']\n\n\nUpon inspection, you will find that this data has equal number of datapoints from each class, so we don’t have to discard any datapoints. Let’s first split the data into train, test and validation. Let’s keep half of the data for training, a quarter for validation and a quarter for testing, but first we will randomise the dataset. Also we need to convert the target into 1-of-N encoding.\n\nencoded_target = np.zeros((target.shape[0],3))\nencoded_target[np.arange(target.shape[0]),target]=1\n\n\nidx = np.arange(data.shape[0])\nnp.random.shuffle(idx)\ndata = data[idx,:]\nencoded_target = encoded_target[idx,:]\n\ntrain = data[::2,:]\ntraint = encoded_target[::2,:]\n\nval = data[1::4,:]\nvalt = encoded_target[1::4,:]\n\ntest = data[3::4]\ntestt = encoded_target[3::4,:]\n\n\nLet’s normalize the data. Let’s divide by the maximum instead of standard deviation. We will normalize every set with mean and max(or std) from the training data.\n\nmean = train.mean(axis=0)\nmaximum = train.max(axis=0)\nstd = train.std(axis=0)\ntrain = (train-mean)/maximum\nval = (val-mean)/maximum\ntest = (test-mean)/maximum\n\n\nm = MLP()\nm.early_stopping(train,traint,val,valt,10,(20,),15,False,0.9,loss='crossentropy',random_state=0)\n\n\n0.0798786726307614\n\n\nm.compute_error(m.forward(train,False),traint,'crossentropy')\n\n\n0.18322617355694956\n\n\nm.confmat(train,traint)\n\n\n(array([[28.,  0.,  0.],\n        [ 0., 23.,  1.],\n        [ 0.,  2., 21.]]), 0.96)\n\n\nm.confmat(val,valt)\n\n\n(array([[14.,  0.,  0.],\n        [ 0., 11.,  0.],\n        [ 0.,  0., 13.]]), 1.0)\n\n\nm.confmat(test,testt)\n\n\n(array([[ 8.,  0.,  0.],\n        [ 0., 13.,  0.],\n        [ 0.,  1., 15.]]), 0.972972972972973)\n\n\nThe confusion matrices reveal great results, on test set as well. You may even choose to change the activation of output nodes. (try softmax!)\n\n4.3 Time Series Problem\n\nTime Series data has a few problems:\n\n\n  \n    Even if there is some regularities in the data, it can appear many different scales. There are local variations, which hide the general trend.\n  \n  \n    How many datapoints of the past should we use to make a prediction? and at what intervals?\n  \n\n\nThis comes to a choice of \\(\\tau\\) and \\(k\\) deciding the interval and the number respectively.\n\nFor example, if \\(\\tau=2\\) and \\(k=3\\), then input data are elements 1,2,and 5 and 7 is the target. The next element is 2,4,6,and target is 8. Just make sure you don’t use parameters such that data is picked systematically. e.g: If some feature is only visible at odd datapoints, then it will be completely missed in even ones.\n\nAfter done it is a simple regression problem.\n\n3.6.4 The Auto-Associative Network\n\nThis is an interesting use of neural networks. In this network the input and the targets are the same. It is also called auto-encoder at times. It looks useless at first, but if we have a small hidden layer(lesser nodes than input nodes), it forms a bottleneck condition, where the outer nodes (input and output) are equal to each other and more than the hidden ones. Once the network is trained to reproduce the the own result, the hidden outputs(activations) will represent a compressed version of the data. It reduces the dimensions. We can use it to compress the data and then use the second weights to regenerate the input again.\n\nIt can also be used to denoise images. Once a model is trained, it can be used to pass noisy images to return clearer images.\n\nThe hidden acivations, if they all have linear activations, will be the Principal Components of input data. Principal Component Analysis is a useful dimensionality reduction technique and will be discussed in detail later."
					}
					
				
		
				
					,
					
					"notes-neural-networks-multiayer-perceptron-index": {
						"id": "notes-neural-networks-multiayer-perceptron-index",
						"title": "Multi-Layer Perceptron",
						"categories": "",
						"url": " /notes/neural_networks/multiayer-perceptron/index",
						"content": "The Multi Layer Perceptron Part  II\n\nA complete description of mathematics that go in making a multi layered perceptron work.. . .  read more\n\n\n\n\nThe Multi Layer Perceptron - Part I\n\nA complete description of mathematics that go in making a multi layered perceptron work.. . .  read more\n\n\n\n\nPerceptron Convergence Theorem\n\nA Mathematical proof of perceptron convergence theorem. . .  read more\n\n\n\n\nMaths Behind Perceptron\n\nA complete description of mathematics that go in making a perceptron work.. . .  read more"
					}
					
				
		
				
					,
					
					"notes-neural-networks-multiayer-perceptron-multi-layer-perceptron": {
						"id": "notes-neural-networks-multiayer-perceptron-multi-layer-perceptron",
						"title": "The Multi Layer Perceptron - Part I",
						"categories": "",
						"url": " /notes/neural_networks/multiayer-perceptron/multi-layer-perceptron",
						"content": "The Multi Layer Perceptron\n\n1. Introduction\n\nAs we have seen, in the Basic Perceptron Lecture, that a perceptron can only classify the Linearly Separable Data. We had two different approaches to get around this problem:\n\n\n  The Higher Dimensions, which was discussed briefly and will be discussed in detail later.\n  The Multiple Layers, which we will discuss now.\n\n\nSo the concept here is to add an intermediate layer of neurons between the input nodes and the output layer of neurons(as you might have noticed, we are starting to use the term layer quite a lot. You can make a drinking game out of it!). This additional layer will have input from the input nodes, and will have it’s own weights(and biases!). Then the outputs generated by this layer will be input for the next layer and so on till the final output layer. So this network can learn more complex functions than just linear ones.\n\nNow the question is how we train this network?\n\n2. Training the MLP\n\n2.1 Introduction\n\nIt is the same as with the simple perceptron. We predict the outputs on a given data. We change the weights for wrong answers, until all the outputs are correct(or until epochs run out!).\n\nThe prediction phase is quite simple. We compute the outputs of intermediate layer and use that as input for the final output layer.\n\nBut the updation of weights is what makes it a bit tricky. If an error has occured, we don’t know which weights to change(or more specifically, in which layer). The error might be in the weights of the first layer or in the final output layer. Since the updation of weights is more complex(or lengthy!) we divide the training into two parts:\n\n  Forward Process, where we compute the outputs for the data to spot errors. It is also used in the Prediction Phase.\n  Backward Process, or updation of weights. We will know why it is called “Backward”.\n\n\n2.2 Forward Process\n\nThis process is pretty straight forward, the intermediate layer has its own weights which connect the input nodes to its neurons. The intermediate layer can have any number of neurons. We will just calculate if each neuron will fire or not in that layer. That vector will be the output of that layer and the input for next layer which will finally generate the final outputs.\n\nIt is note here that it is not necessary to have just have one intermediate layer but as many layers as we want and they will work the same as passing on their outputs as inputs for next layer until the final output is generated.\n\nThe intermediate layers are called hidden layers. As we had seen in the simple Perceptron that an additional input bias node was required. So while using the outputs of a hidden layer as inputs for a next layer we again add a bias node of constant value(-1,say) to the layer but while computing the outputs of any hidden layer from it’s previous layer, we ignore the bias unit, as it is always constant.\n\n\n\nFigure 1\n\nAs you can see in the above network, a bias node is from input layer to hidden layer and another bias node from the hidden layer to output layer. There is no weight from the previous layer to the bias node of any layer as it is not computed but is constant.\n\nLet’s say we have \\(L\\) number of layers(not including the input layer but output layer is included). So \\(L-1\\) layers are hidden layers. The input layer will have nodes as many as there are features in the data and the output layer will have as many neurons as the number of classes(or 1 if there are two classes or if we are using the network for regression). The rest of the network i.e all the hidden layers can have as many neurons as we want.\n\nLet:\n\n  \\(n_i\\): the number of neurons in \\(i^{th}\\) layer.\n  \\(a^{(i)}_j\\): the output generated by \\(j^{th}\\) neuron in \\(i^{th}\\) layer.\n  \\(w^{(i)}_{jk}\\): weight connecting the \\(j^{th}\\) neuron of \\((i-1)^{th}\\) layer to \\(k^{th}\\) neuron of \\(i^{th}\\) layer.\n  \\(g_{(i)}\\) is the activation functionof \\(i^{th}\\) layer.\n\n\nNote: We can also use the term \\(0^{th}\\) layer for the input layer. So \\(n_0\\) is the number of input features. \\(a^0_j=x_j\\) is the \\(j^{th}\\) input node. \\(a^0_0=x_0\\) is the bias node of input layer.\n\nWe compute the activation of \\(j^{th}\\) neuron in \\(i^{th}\\) layer as:\n\n\n$$ a^{(i)}_j = g_{(i)}\\bigg(\\sum_{k=0}^{n_{i-1}} a^{(i-1)}_kw^{(i)}_{kj}\\bigg)  \\qquad \\forall \\ j \\in [1,n_i] \\tag{1} $$\n\nwhere \\(g_{(i)}\\) is the activation of \\(i^{th}\\) layer.\n\nNote: We did not compute for \\(j=0\\) i.e we did not compute \\(a^{(i)}_0\\) as that will be the bias node and has constant value.\n\nTo make things a bit more simpler, we introduce another term, \\(h^{(i)}_j\\), where:\n\n\n$$ h^{(i)}_j = \\sum_{k=0}^{n_{i-1}} a^{(i-1)}_kw^{(i)}_{kj} \\tag{2} $$\n\n\nSo Equation 1 can be changed to:\n\n\n$$ a^{(i)}_j = g_{(i)}\\big(h^{(i)}_j\\big) \\tag{3} $$\n\n\nTo get the final outputs,\nRepeat Equation 1 \\(\\forall i \\in [1,L]\\) sequentially.\n\nWe will see it in action later in implementation.\n\n2.3 Backward Process (Updation of weights)\n\n2.3.1 Introduction\n\nNow that we have generated outputs, it is time to check them against the ground truth targets and make changes in weights to correct the errors made. But the problem is we don’t know which weights made the error, especially in which layer was the error.\n\nNow even if we follow the basic rule of updating weights as in simple perceptron, we will compute error in each output neuron and update the weights using the learning rate and the inputs. But how to update weights of the layer before? We don’t know the ground truth values for hidden layers. How do we compute error in these layers?\n\n2.3.2 The Backpropagation Algorithm\n\n2.3.2.1 Introduction\n\nThe Backpropagation Algorithm is the core of Multi Layer Neural Networks. It works on the principle of gradient descent and minimizing error.\n\nIf you recall from the basic perceptron, we updated weights as:\n\n\n\nHere we are doing the same but for each layer, but instead of using \\((y_j-t_j)\\) we will let the calculus decide the error in that hidden layer, as we don’t know the ground truth targets for hidden layers(and that’s why they are called so!) and \\(x_i\\) was the input node for that weight, where as in layer \\(l\\), the input comes from the layer before (\\(a^{(l-1)}_j\\)).\n\nSo we can write for each layer,\\(l\\), we will update weights as:\n\n\n$$ w^{(l)}_{jk} \\leftarrow w^{(l)}_{jk} - \\eta \\delta^{(l)}_k a^{(l-1)}_j \\tag{4} $$\n\nwhere \\(\\delta^{(l)}_k\\) is the error in \\(k^{th}\\) neuron of \\(l^{th}\\) layer.\n\nPlease make sure it is the error in a neuron and not the total error in the network, which we will define now.\n\n2.3.2.2 The Network Error\n\nNow to get around the problem of updating weights in hidden layers, we decide to formalize the error in the network and try to minimize it.\n\nAs in Simple Perceptron, we had used the simple difference as our error function for each output neuron which was fine but now we would like to minimize the error of the network. There are multiple ways of doing it. We will see an example for that. But, for now let’s say the total error in the network is \\(E\\).\n\nThe error of the network has to be a function of final outputs and ground truth targets, that is how we will compute error.\n\nActually we will have a loss function for each output neuron, which will be summed. Let the loss in \\(i^{th}\\) neuron be a function \\(\\mathcal{L}(y_i,t_i)\\).\n\nThe total Error for an example will be the sum of loss functions in each final neuron.\n\nSo,\n\n\n$$ E = \\sum_{i=1}^{n_{L}} \\mathcal{L}(y_i,t_i) \\tag{5} $$\n\nwhere \\(y_i = a^{(L)}_i\\) is the output of \\(i^{th}\\) output neuron in the final layer and \\(t_i\\) is the corresponding true value.\n\nYou can even go ahead and sum this error for every training example and call that the error of the network and try to minimize that but we will define this as our network error.\n\n2.3.2.3 Computing Gradients\n\nNow to minimize this error, we will use calculus, specifically differential calculus. We can compute the gradient of the error along each weight dimension in the network and try to minimize by changing weights along the minimizing gradient.\n\nSo the gradient of the Error(\\(E\\)) w.r.t a weight \\(w^{(l)}_{jk}\\) in layer \\(l\\) is:\n\n\n\nThe negative of this gradient is the direction along which the Error is minimum along this weight dimension. Now we know what direction to change the weights in and for the amount we need to change we will use the learning rate.\n\nSo weight update can also be defined for any weight from neuron \\(p\\) of layer \\((l-1)\\) to neuron \\(q\\) of layer \\(l\\):\n\n\n$$ w^{(l)}_{pq} \\leftarrow w^{(l)}_{pq} - \\eta \\frac{∂E}{∂w^{(l)}_{pq}} \\tag{6} $$\n\n\nComparing Equation 4 and 6,\n\n\n\nNow to compute the gradient of weights, we will use the chain rule:\n\n\n$$ \\frac{∂E}{∂w^{(l)}_{pq}} = \\frac{∂E}{∂h^{(l)}_{q}}\\frac{∂h^{(l)}_{q}}{∂w^{(l)}_{pq}} \\tag{8} $$\n\n\nRecalling Equation 2:\n\n\n\nThe above equation holds by the fact that it is a partial derivative and all other weights and outputs are constant and their differentiation is zero except the weight we are differentiating with.\n\nUsing Equation 9 in 8:\n\n\n\nComparing Equation 10 and 7:\n\n\n$$ \\delta^{(l)}_q =\\frac{∂E}{∂h^{(l)}_{q}} \\tag{11} $$\n\n\nThe above equation is one of the most important equations in Backpropagation algorithm. It defines the error in \\(q^{th}\\) neuron of \\(l^{th}\\) layer.\n\n2.3.2.4 Computing Gradients (Final Layer)\n\nLet’s try to compute the weight updates for weights in final output layer.\n\nUsing Equation 4 for the final layer:\n\n\n\nNow let’s compute \\(\\delta^{(L)}_q\\)(i.e error in \\(q^{th}\\) neuron of final layer):\n\nFrom Equation 11:\n\n$$ \\delta^{(L)}_q=\\frac{∂E}{∂h^{(L)}_{q}} \\tag{13} $$\n\n\nAs we know the error is the sum of loss functions on each output neuron:\n\n\n\nwhere \\(y_i = a^{(L)}_i\\), the output of \\(i^{th}\\) neuron in the final layer.\n\nUsing Equation 3:\n\n\nwhere \\(g_{(L)}\\) is the activation of final layer.\n\nComing back to Equation 13:\n\n\n\nSince it is a partial derivative, all other functions except for those of \\(h^{(L)}_q\\) are considered constant and hence differentiation is zero. i.e:\n\n\n\n\n$$ \\begin{align} \\implies \\delta^{(L)}_q&amp;=g_{(L)}'\\big(h^{(L)}_q\\big)\\ \\mathcal{L}'\\big(g_{(L)}(h^{(L)}_q),t_q\\big) \\\\ &amp;=g_{(L)}'\\big(h^{(L)}_q\\big)\\ \\mathcal{L}'\\big(y_q,t_q\\big) \\tag{18} \\end{align} $$\n\n\nEquation 18 above calculates the error in neuron number \\(q\\) in layer \\(L\\)(the final layer).\n\nUsing the above equation in Equation 13,\n\n\n\nThis looks very confusing at first, but have a look at the indices and you’ll get the hang of it. Besides we will have an example for a specific loss function later.\n\nAlso you might have noticed that we perform differentiation of the activation function, so our current activation function (the threshold function) is no good here as that is non-differentiable at 0. We will use some new activation functions later.\n\n2.3.2.5 Computing Gradients (Final Hidden Layer)\n\nNow, that we have computed error in the final layer and updated weights, let’s try updating weights in the final hidden layer (i.e 2nd last layer, \\(L-1\\)). We will proceed the same as we did with the final output layer before.\n\nAgain Using Equation 4 for the final hidden layer:\n\n\n$$ w^{(L-1)}_{pq} \\leftarrow w^{(L-1)}_{pq} - \\eta \\delta^{(L-1)}_qa^{(L-2)}_p \\tag{20}$$\n\n\nNow let’s compute \\(\\delta^{(L-1)}_q\\)(i.e error in \\(q^{th}\\) neuron of final hidden layer):\n\nFrom Equation 11:\n\n\nNow this is where the chain rule comes to propagate the error,\n\n\n\n\n\nUsing Equation 13,\n\n\n$$ \\delta^{(L-1)}_q=\\sum_{i=1}^{n_L}\\delta^{(L)}_i\\frac{∂(h^{(L)}_{i})}{∂h^{(L-1)}_{q}} \\tag{24} $$\n\n\nNow let’s compute \\(\\frac{∂(h^{(L)}{i})}{∂h^{(L-1)}{q}}\\), using Equation 2:\n\n\n\nUsing Equation 3,\n\n\n\nAgain it is a partial derivative, so just the functions of \\(h^{(L-1)}_q\\) are considered as variables, all others are constant and differentiate to Zero.\n\n\n\n\n\nSince the Equations 25 - 28 could have worked for any layer \\(l\\) and not just layer \\(L-1\\), we can also generalize the above result, for any layer \\(l\\), as:\n\n\n$$ \\frac{∂(h^{(l)}_{i})}{∂h^{(l-1)}_{q}} = w^{(l)}_{qi} \\  g_{(l-1)}'\\big(h^{(l-1)}_q\\big)  \\tag{29} $$\n\n\nThe above equation is also important as we will see, in a moment.\n\nUsing equation 29 in Equation 24, we get:\n\n\nNow, coming back to Equation 20:\n\n\n\nWe can now update the weights of the final hidden layer as the error from the final layer has propagated to the final hidden layer.\n\n2.3.2.6 Summarizing the important points.\n\nLet’s list all the important results that we derived uptill this point to avoid confusion.\n\n\n  We update the weights of any layer \\(l\\) as Equation 4:\n\nwhere:\n    \n      \\(\\eta\\) is the learning rate.\n      \\(a^{(l-1)}_j\\) is the output generated by \\(j^{th}\\) neuron in the previous layer\n      \\( \\delta^{(l)}_k\\) is the error generated in the \\(k^{th}\\) neuron of \\(l^{th}\\) layer explained below.\n    \n  \n  The output of \\(j^{th}\\) neuron in the \\(i^{th}\\) layer is given by Equation 3:\n\nwhere:\n    \n      \\(g_{(i)}\\) is the activation function of layer \\(i\\).\n      \\(h^{(i)}_j\\) is the summation output of the \\(j^{th}\\) neuron of \\(i^{th}\\) layer explained below.\n    \n  \n  The summation output has been assigned a new term as it makes calculations easier and leads to definition of the error in a neuron. The summation output in \\(j^{th}\\) neuron of \\(i^{th}\\) layer is as Equation 2:\n\nwhere:\n    \n      \\(a^{(i-1)}_k\\) is the output from the \\(k^{th}\\) neuron of the previous layer \\((i-1)^{th}\\) layer.\n      \\(w^{(i)}_{kj}\\) is the weight joining the \\(k^{th}\\) neuron of previous (\\((i-1)^{th}\\)) layer to the \\(j^{th}\\) neuron of current (\\(i^{th}\\)) layer.\n    \n  \n  The error in \\(q^{th}\\) neuron in \\(l^{th}\\) layer is defined by Equation 11:\n\nwhere:\n    \n      \\(E\\) is the total error of the network.\n      \\(h^{(l)}_q\\) is the summation output of \\(q^{th}\\) neuron in \\(l^{th}\\) layer.\n    \n  \n  The derivative of summation output of \\(i^{th}\\) neuron in the next (\\(l^{th}\\)) layer w.r.t \\(q^{th}\\) neuron in current (\\((l-1)^{th}\\)) layer given in Equation 29:\n\nwhere:\n    \n      \\(g_{(l-1)}’\\big(h^{(l-1)}_q\\big)\\) is the derivative of the activation function of layer \\((l-1)\\) at \\(h^{(l-1)}_q\\), the summation output.\n    \n  \n\n\n2.3.2.7 Computing Gradients (Any hidden Layer)\n\nNow, let’s try to develop a generalized equation for the error in layer \\(l\\).\n\nWe update the weights of any layer \\(l\\) as Equation 4:\n\n\nwhere:\n\n  \\(\\eta\\) is the learning rate.\n  \\(a^{(l-1)}_j\\) is the output generated by \\(j^{th}\\) neuron in the previous layer\n  \\( \\delta^{(l)}_k\\) is the error generated in the \\(k^{th}\\) neuron of \\(l^{th}\\) layer explained below.\n\n\nNow we just need to compute the error \\(\\delta^{(l)}_k\\):\n\nBy Equation 11:\n\n\nwhere:\n\n  \\(E\\) is the total error of the network.\n  \\(h^{(l)}_q\\) is the summation output of \\(q^{th}\\) neuron in \\(l^{th}\\) layer.\n\n\n\n\ndoing it for all \\(i\\):\n\n\n\nUsing Equation 11,\n\n\n\nNow according to Equation 29:\n\n\n\nUsing above equation in Equation 34:\n\n$$ \\begin{align}\\implies \\delta^{(l)}_k &amp;= \\sum_{i=1}^{n_{l+1}}\\Big[ \\delta^{(l+1)}_i \\cdot w^{(l+1)}_{ki} \\cdot g_{(l)}'\\big(h^{(l)}_k\\big)\\Big]\\\\ &amp;= g_{(l)}'\\big(h^{(l)}_k\\big) \\sum_{i=1}^{n_{l+1}}\\Big[ \\delta^{(l+1)}_i w^{(l+1)}_{ki} \\Big] \\tag{36} \\end{align} $$\n\n\nEquation 36 above is the general way of how we backpropagate the error layer to layer. This is at the core of Backpropagation Algorithm which works at the heart of neural networks, not just MLP.\n\nNote: It is advised to compute the error in each neuron of previous layer first and then update the weights of current layer as they are used to calculate the error of previous layer.\n\n2.3.2.8 The Activations\n\nAs you can see in the Equation 36, that the activations we use should be differentiable at all points and the threshold activation was not differentiable at 0 and had derivative of 0 at all other points, making the error in every neuron to be zero, which isn’t what we want. So we introduce a couple more activation functions. We will visualize each function and how they vary.\n\nfrom plotly import graph_objects as go\nimport numpy as np\n\ndef plot_activation(func):\n    x = np.linspace(-100,100,400)\n    #compute the activation\n    y = func(x)\n    fig = go.Figure(data=[go.Scatter(x=x,y=y,mode=\"lines\")],\n                    layout=dict(height=500,width=500,title=f\"{func.__name__} activation\".title()))\n    fig.show()\n    \n\n\nOur original threshold function was:\n\n\n\nIt can be coded as:\n\ndef threshold(x):\n    return (x&gt;0)*1\n\n\n# plot the threshold \nplot_activation(threshold)\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\n1. The Sigmoidal Activation:\nIt is an S shaped activation. This activation is given by:\n\n \nwhere \\(\\beta\\) is a positive parameter, preferably 1.\n\nIt’s derivative is:\n\n\n$$ g'(x) = g(x)\\beta(1-g(x)) = \\beta a(1-a) \\tag{39} $$\n\n\ndef sigmoid(x,beta=1):\n    return 1/(1+np.exp(-beta*x))\n\n\nplot_activation(sigmoid)\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nLet’s compare the threshold and sigmoid together\n\nfrom plotly.subplots import make_subplots\nfig = make_subplots(rows=1,cols=2, shared_yaxes=True, subplot_titles=[\"Threshold Activation\", \"Sigmoid Activation\"])\nx = np.linspace(-10,10,400)\ny1 = threshold(x)\nfig.add_trace(go.Scatter(x=x,y=y1),row=1,col=1)\ny2 = sigmoid(x)\nfig.add_trace(go.Scatter(x=x,y=y2),row=1,col=2)\nfig.update_layout(showlegend=False)\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs we can see both the functions are almost the same, just that the sigmoid is more smooth at edges, making it differentiable. It can be used as a replacement for threshold. Although it will output values other than 0 and 1 for values close to zero.\n\n2. The tanh activation:\nIt is the similar to sigmoid but it outputs range between -1 and 1, instead of 0 and 1. It is not used much in the MLP. It is given by:\n\n\n\nIt’s derivative is rather simple:\n\n\n\nIt is already defined in numpy as np.tanh function.\n\nplot_activation(np.tanh)\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nLet’s compare all the functions in one go.\n\nx = np.linspace(-10,10,100)\nfig=go.Figure(data=[\n                    go.Scatter(x=x,y=threshold(x),name=\"Threshold\"),\n                    go.Scatter(x=x,y=sigmoid(x),name=\"Sigmoid\"),\n                    go.Scatter(x=x,y=np.tanh(x),name=\"Tanh\"),\n                   ],\n             layout=dict(width=600,height=600))\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\n3. The Softmax Activation:\nThis activation is given by:\n\n\n\nAs all the outputs in output nodes are independent of each other. The sigmoid layer may make more than one output neuron to fire. But sometimes we just want to classify a datapoint in just one class. That is where softmax is good. It sums up all the outputs to 1 and the maximum one is set to 1 and others to 0.\n\nBefore computing its derivative, we have two cases\n\n  Derivative w.r.t the summation of the node, i.e:\n\n  Derivative w.r.t the summation of some other node, i.e:\n\n\n\n\nand\n\n\n\n3. The Linear Activation\nThis activation is given by:\n\n\nThis activation is used for regression purposes.\n\n2.3.3 The Equations in MLP\n\nWe saw the equations in the light of general cases. Let’s now see them in an example to clear out the doubts if any. The activations will depend on the type of problem we are solving. For Regression problems we won’t use any activation in the final layer as we need real values, but we will use sigmoid activation in hidden layers at all times for the concept of firing and non firing of neurons. For Classification we will use sigmoid for final layer as well. We can also use softmax for the final layer, if we just need to predict one class. Let’s say we are currently using sigmoid in all cases.\n\nWe haven’t defined any Loss function for the final output neurons to compute the network error.\nWe can use the simple difference between the outputs and ground truth as the Loss function, but for the network error we sum all the losses(errors) in the final output neurons,\n\nFrom Equation 5,\n\n\n\nSo if we use just the difference, it will be positive for some neurons and negative for some which may sum to zero or a very small number, meaning small network error which isn’t the case. So we need to change the sign of all errors to the same before summing up. We can use absolute values but that has differentiation problems. Instead we can use the squares of difference as our loss function.\n\nSo for neuron \\(i\\) in the final output layer, the loss is\n\n\nWe have added the half at the front to make further calculations easier.\n\nIt’s derivative is:\n\n\nNow using  above equations, equation 5 becomes:\n\n\nNow let’s compute the error in final layer.\n\nRecalling Equations 18, \n\n\nSince our activation is sigmoid and it’s derivative is given in Equation 39.\n\n\nSince, \\( a^{(L)}_i = y_i\\)\n\n$$\\implies  \\delta^{(L)}_q=\\beta^{(L)} (y_q-t_q)y_q(1-y_q) \\tag{50}$$\n\n\nThat is how we compute the error in the final layer.\n\nNow let’s compute in any hidden layer.\n\nWe know from Equation 36,\n\n\n\nNow since we are using sigmoid activation,\n\n\n$$\\implies \\delta^{(l)}_k = \\beta^{(l)} a^{(l)}_k(1-a^{(l)}_k) \\sum_{i=1}^{n_{l+1}}\\Big[ \\delta^{(l+1)}_i w^{(l+1)}_{ki} \\Big] \\tag{51} $$\n\n\nThe equations will change with change in loss function as well as the activation function of each layer.\n\nSide Note: Another great Loss function for Classification is:\n\n\n2.4 The Multi-Layer Perceptron Algorithm\n\n2.4.1 The Algorithm\n\nWith the knowledge of Backpropagation Algorithm, we can now update weights.\n\nWe will consider the sum of squares of as our network error and sigmoid as the activation in every layer.\n\n\n  \n    Initialization:\n\n    Initialize the weights for every neuron of every layer to small(positive and negative) random values.\n  \n  \n    Training:\n\n    \n      ============repeat===========:\n        \n          for each input vector:\n            \n              forward phase:\n                \n                  \n                    for each layer \\(l\\) in the network:\n\n                    \n                      compute the activation of each neuron \\(j\\) using:\n  \n  where \\(a^{0}_i = x_i\\), i.e the input node\n  and \\(a^{(l)}_0 = -1\\), the bias node for every layer.\n                    \n                  \n                \n              \n              backward phase:\n                \n                  compute the error at the output node \\(j\\) using:\n \n                  for each layer \\(l\\) in the network starting from the final hidden layer:\n                    \n                      compute the error in the layer \\(l\\) using\n                    \n\n                    \n\n                    \n                      update the every weight in the layer \\((l+1)\\) using:\n \n                    \n                  \n                  finally update every weight of first hidden layer using:\n\nwhere \\(a^{(0)}_i = x_i\\), the input node.\n                \n              \n            \n          \n        \n      \n      ====until learning stops or epochs run out============\n    \n  \n\n\nNote: In batch implementation, we should randomise the input so that we don’t train on the same sequences for every iteration.\n\n\n  \n    Recall\n\n    \n      Use the forward phase in training section above.\n    \n  \n\n\n2.4.2 Initialization of weights\n\nThe weights should be initialized to be small random numbers. It is because the sigmoid activation flattens at the large(positive and negative) values and the slope becomes closer zero and so it takes longer to train the network. The sigmoid starts flattening at input of 1, so that will be the max input and similarly -1 will be the minimum input.\n\nSo for a neuron,\n\n\nNow since we have to figure out all the weights, we will keep all the weights to be same and equal to \\(w^{(l)}\\).\n\n\nNote: \\(w^{(l)}\\) is the general representation of every weight of layer \\(l\\) and not the weight matrix of layer \\(l\\).\n\nWe assume that all the inputs come from a stadard normal distribution zero mean and unit variance, i.e:\n\n\nwhere \\(\\mu^{(l)}\\) and \\(\\sigma^2\\) is the mean and variance of all output values in layer \\(l\\).\n\nSince mean is ZERO and variance is unity,\n\n\n\nUsing the above equation in Equation 54, we get:\n\n\n\nSo we know how to initialize weights. However still weights from different initialization can have different effects on the outputs. You should try to train the network on different random seeds and figure out the best one.\n\nAlso note that the above equation came from an assumption as well as approximation.\n\nAlso, as we know that it is better to have small inputs to a sigmoid to give better results, so \\(\\beta\\) should also be small(\\(\\beta \\leq 3.0\\)).\n\n2.5 Speeding up the code\n\n2.5.1 Speeding Up the  forward process\n\nWe can compute the activations of multiple examples at once using matrix operations.\n\nLet’s say we have \\(k\\) number of training examples and each example has \\(m\\) features with \\(n\\) types of outputs.\n\nNow we can store our inputs in a matrix where each row represents a training example and a column represents a feature.\n\nSo our training example is like:\n\n\nThe matrix shape is \\(k \\times m\\).\n\nWe will use numpy library to store inputs.\n\nimport numpy as np\n\n\nLet’s say we want to train the Logical-XOR function. So our input should look like:\n\nSo our input should look like:\n\n\nWe can make it make it using np.array method:\n\nX = np.array([[0,0],\n             [0,1],\n             [1,0],\n             [1,1]])\nX\n\n\narray([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n\n\nNow our input is ready, let’s figure out how to store the target values. Each input has target values to denote which neuron to fire and which not to(1s and 0s). This type of output is for classification process.\n\nSo with \\(k\\) examples and \\(n\\) output neurons, the target matrix should be \\([t_{ij}]\\) which is the target for \\(i^{th}\\) example and \\(j^{th}\\) neuron.\n\nSo,\n\n$$ T=\\begin{bmatrix} t_{11} &amp; t_{12} &amp; t_{13} &amp; \\cdots &amp; t_{1n}\\\\ t_{21} &amp; t_{22} &amp; t_{23} &amp; \\cdots &amp; t_{2n}\\\\ t_{31} &amp; t_{32} &amp; t_{33} &amp; \\cdots &amp; t_{3n}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ t_{k1} &amp; t_{k2} &amp; t_{k3} &amp; \\cdots &amp; t_{kn}\\\\ \\end{bmatrix}\\\\ \\text{where \\\\(t_{ij} \\in \\{0,1\\}\\\\)}\\tag{59} $$\n\n\nFor binary outputs, like in our example, we can just use one output neuron, which will fire for one output and not fire for other which means \\(n=1\\).\n\nIt is same for regression problems just instead of output being 1 or 0, it is real valued.\n\nSo, \n\n\nand in our example,\n\n\n\nWe can do it in numpy in the same way:\n\nT = np.array([[0],[1],[1],[0]]);T\n\n\narray([[0],\n       [1],\n       [1],\n       [0]])\n\n\nNow since we have multiple layers and each have their own output(of zeroes and ones), we will have an activation matrix for each layer, where \\([a^{(l)}_{ij}]\\) is the ouput for \\(i^{th}\\) example from \\(j^{th}\\) neuron in \\(l^{th}\\) layer.\n\nNow since there will be many matrices, we will save them in a python list. It will be a list of numpy arrays.\n\n\n\nThis matrix will be \\(k \\times n_l\\).\n\nOr\n\n\n\nwhere\n\n\n  \\(g_{(l)}\\) is the activation of layer \\(l\\).\n  \\(h^{(l)}{pq} = \\sum{c=0}^{n_{l-1}}a^{(l-1)}{pc}w^{(l)}{cq}\\)\n\n\n\n\n\n\nThe above matrix is a matrix multiplication of two matrices.\n\n\n\nThe left matrix looks like an activation matrix for the previous layer with extra bias column at the front.\n\nWe can generate a column of -1 using the np.ones method and then concatenate it with our matrix using np.concatenate to form this matrix. We can define an activation matrix with bias as of layert \\(l\\) as:\n\n\n\nand the right matrix of Equatio 66 is the weight matrix of layer \\(l\\), where \\(w^{(l)}_{ij}\\) is the weight from \\(i^{th}\\) node of layer \\((l-1)\\) to \\(j^{th}\\) node of layer \\(l\\).\n\n\n\nthis is a \\(\\big((n_{l-1}+1) \\times n_{l}\\big)\\) matrix\n\nso we can say,\n\n\n\nand \n\nwhere:\n\n  \\(\\times\\) is the matrix multiplication\n  \\(\\begin{bmatrix}\nM &amp; N\n\\end{bmatrix}\\) is the horizontal concatenation of matrix \\(M\\) and \\(N\\).\n  \\(g_{(l)}\\) is the activation of layer \\(l\\).\n\n\nWe will use the np.matmul function to perform a matrix multiplication and we will use the numpy broadcasting to compute activations.\n\n2.5.2 Speeding Up the backward process\n\nNow that we have completed the forward process, let’s remind of the backward equations.\n\nWe update weights of any layer \\(l\\) using:\n\n\nFor \\(k\\) examples, we can\n\n\n\nWe can turn it into a matrix operation as:\n\n\n\n\n\nwhere \\(\\Delta w^{(l)}{pq} = \\sum{i=1}^{k}\\delta^{(l)}{iq}a^{(l-1)}{ip}\\)\n\n\n\nThe matrix above looks like a matrix multiplication, let’s open it\n\n\nwhere \\(\\times\\) is the matrix multiplication.\n\nUsing Equation 67,\n\n\n\n\n\nwhere,\n\n\n\nIt is called the error matrix of layer \\(l\\)\nwhere \\(\\delta^{(l)}_{ij}\\) is the error in \\(j^{th}\\) neuron of layer \\(l\\) for \\(i^{th}\\) training example.\n\nThe matrix is \\(\\big(k \\times n_l\\big)\\).\n\nFor the final output layer,\n\n\nThe matrix is \\(\\big(k \\times n_L)\\).\n\nWe know from Equations 18, \n\n\nfor a training example, \\(i\\),\n\n\n\nand for our chosen loss function,\n\n\n\nLet’s first compute the \\(\\Delta^{(L)}\\),\n\nUsing Equation 81,\n\n\n\nOpening up,\n\n\n\nsince \\(y_i = a^{(L)}_i\\),\n\n\n\n\n\nwhere \\(*\\) is the elementwise multiplication and not matrix multiplication.\n\nNow let’s compute \\(\\Delta^{(l)}\\),\n\nRecalling Equation 51,\n\n\nfor training example \\(j\\),\n\n\n\nUsing Equation 86,\n\n\n\nUsing Equation 67,\n\n\nwhere \\(I_1\\) is the matrix full of 1 of the same shape as \\(A^{(l)}\\) and \\(*\\) represents elementwise multiplication.\n\nthe matrix on the right looks like a matrix multiplication of two matrices. Let’s open it up.\n\n\n\nUsing Equation 68 and 79,\n\n\nwhere\n\n  \\(*\\) is the elementwise multiplication\n  \\(\\times\\) is the matrix multiplication.\n  \\(W^{(l)}_{biasless}\\) is the weight matrix for \\(l^{th}\\) layer without the weights from the bias nodes of previous layer.\n\n\nSide Note: We can produce a biasless weight matrix from a complete matrix by simple slicing.\n\n2.6 Code\n\nclass MLP:\n    def init_weights(self,layer_sizes,random_state):\n        #save weights in a list of matrices\n        np.random.seed(random_state)\n        self.weights = [np.random.rand(layer_sizes[l-1]+1,layer_sizes[l])*(2/np.sqrt(layer_sizes[l-1]))-(1/np.sqrt(layer_sizes[l-1])) for l in range(1,len(layer_sizes))]\n    def sigmoid(self,x):\n        return 1/(1+np.exp(-x)) # keep beta = 1\n    \n    def forward(self,A_0,weights=None):\n        self.outputs=[]\n        A_l = A_0\n        self.outputs.append(A_0)\n        if not weights:\n            weights = self.weights\n        for weight in weights:\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1) # add bias to input data\n            H_l = np.matmul(A_lbias,weight) # compute the summation\n            A_l = self.sigmoid(H_l) # compute the activation\n            self.outputs.append(A_l)\n        return A_l # return the final output\n            \n    def backward(self,T, learning_rate):\n        A_L = self.outputs[-1]\n        delta_L = (A_L-T)*(A_L*(1-A_L)) # beta = 0\n        delta_l_next = delta_L\n        \n        for i in range(len(self.weights)-1,-1,-1):\n#             print(i)\n            A_l = self.outputs[i]\n            #compute error for previous layer\n            delta_l = A_l*(1-A_l)*(np.matmul(delta_l_next,np.transpose(self.weights[i][1:,:])))\n#             A_0 A_1 A_2\n#             W_1 W_2\n#             0   1    2\n            # add bias output to output matrix\n            A_lbias = np.concatenate(((-np.ones((A_l.shape[0],1)),A_l)),axis=1)\n            #update weights using the next errors\n            \n            \n            self.weights[i] = self.weights[i]- (1/T.shape[0])*(learning_rate*(np.matmul(np.transpose(A_lbias),delta_l_next)))\n            # change the next errors for next layer\n            delta_l_next = delta_l\n            \n        \n            \n            \n    \n    def train(self,input_data,input_target, epochs,layer_sizes=(100,), \n              learning_rate=0.01,random_state=0,verbose=0, save_weights=False):\n        A_0 = np.array(input_data)\n        T = np.array(input_target)\n        layer_sizes=list(layer_sizes)\n        layer_sizes.insert(0,A_0.shape[1])\n        n_outputs = np.unique(T).shape[0] if np.unique(T).shape[0] != 2 else 1\n        layer_sizes.append(n_outputs)\n        \n        \n        self.init_weights(layer_sizes, random_state=random_state)\n        if save_weights:\n            self.saved_weights = [self.weights.copy()]\n        for e in range(epochs):\n            \n                \n#             print(\"epoch\",e)\n            \n    \n            # shuffle the input so we don't train on same sequences\n            idx = np.arange(0,T.shape[0])\n            np.random.shuffle(idx)\n            A_0=A_0[idx]\n            T=T[idx]\n            \n            A_L = self.forward(A_0)\n#             print(e)\n            if e%(epochs//10) == 0 and verbose:\n                print(\"epoch:\",e)\n                print(f\"Error: {np.sum((A_L-T)**2)/T.shape[0]}\")\n                print(f\"out: {A_L}\")\n#                 print(\"weights\",*self.weights,sep='\\n',end='\\n\\n')\n            self.backward(T,learning_rate)\n            if save_weights:\n                self.saved_weights.append(self.weights.copy())\n        print(f\"Error: {np.sum((A_L-T)**2)/T.shape[0]}\")\n        \n    def predict(self,input_data,weights=None):\n        output = self.forward(np.array(input_data),weights)\n        #since this output is a realnumber(between 0 &amp; 1)\n        # we will have a threshold to predict its class for now 0.5\n        output = (output&gt;0.5)*1\n        return output\n    \n    def confmat(self,input_data,targets):\n        '''returns the confusion matrix for binary classification'''\n        outputs = self.predict(np.array(input_data))\n        T = np.array(targets).reshape(outputs.shape)\n        tp = ((T==1)&amp;(outputs==1)).sum()\n        tn = ((T==0)&amp;(outputs==0)).sum()\n        fp = ((T==0)&amp;(outputs==1)).sum()\n        fn = ((T==1)&amp;(outputs==0)).sum()\n        return np.array([[tp,fp],\n                        [fn,tn]])\n\n\nLet’s try to train the model for XOR data.\n\nXOR_inp = np.array([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n\nXOR_target = np.array([[0],\n       [1],\n       [1],\n       [0]])\n\n\nm = MLP()\nm.train(XOR_inp,XOR_target,5001,layer_sizes=(2,),learning_rate=1, random_state=0)\n\n\nError: 0.008145708816099705\n\n\nLet’s check the confusion matrix for this model\n\nm.confmat(XOR_inp,XOR_target)\n\n\narray([[2, 0],\n       [0, 2]])\n\n\nAs we can see all examples have been correctly classified. But it took almost 5000 iterations to do so.\n\nLet’s see for AND data.\n\nAND_inp = np.array([[0,0],\n                   [0,1],\n                   [1,0],\n                   [1,1]])\nAND_target = np.array([[0],\n                      [0],\n                      [0],\n                      [1]])\n\nm2 = MLP()\nm2.train(AND_inp,AND_target,layer_sizes=(2,),learning_rate=1,epochs=5001,random_state=27)\nm2.confmat(AND_inp,AND_target)\n\n\nError: 0.0004818608199957538\n\n\n\n\n\narray([[1, 0],\n       [0, 3]])\n\n\nWe were able to classify this as well, but it took a lot of iterations to do so. So we can classify complex data with multilayer perceptrons, but they come with a computing cost and take a lot of iterations to classify even the linearly separable data.\n\nLet’s check the decision boundary.\n\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/500),\n                      np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/500))\nZ = m.predict(np.c_[xx.ravel(),yy.ravel()])\nZ = Z.reshape(xx.shape)*1\n\n\nfig = go.Figure(layout=dict(width=600,height=600,title=\"Decision Boundary for XOR Data\",\n                            xaxis_title=\"Input 1\", yaxis_title=\"Input 2\"))\n\nfig.add_trace(\n    go.Heatmap(\n        x=xx[0],\n        y=yy[:,1],\n        z=Z,\n        colorscale=\"Viridis\",\n        showscale=False\n))\nfig.add_trace(\n    go.Scatter(\n        x=X[:,0],y=X[:,1],mode=\"markers\",\n        marker=dict(\n            size=20,\n            color=T[:,0],\n            colorscale=\"Viridis\",\n            line=dict(color=\"black\",width=2))\n    )\n)\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nm = MLP()\nm.train(XOR_inp,XOR_target,5001,layer_sizes=(2,),learning_rate=1, random_state=0,save_weights = True)\n\n\nError: 0.008145708816099705\n\n\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/200),\n                      np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/200))\n\nZ = [m.predict(np.c_[xx.ravel(),yy.ravel()],weights).reshape(xx.shape)*1 for weights in m.saved_weights[::50]]\n\nnb_frames = 5001//50\n\nfig = go.Figure(frames=[go.Frame(data=[go.Heatmap(x=xx[0],y=yy[:,1],z=Z[k],\n            colorscale=\"Viridis\",showscale=False),],name=str(k))\n                        for k in range(nb_frames)])\n\nfig.add_trace(go.Scatter(x=X[:,0],y=X[:,1],mode=\"markers\",marker=dict(size=20,\n                color=T[:,0],colorscale=\"Viridis\",line=dict(color=\"black\",width=2))))\n\nfig.add_trace(go.Scatter(x=X[:,0],y=X[:,1],mode=\"markers\",marker=dict(\n                size=20,color=T[:,0],colorscale=\"Viridis\",line=dict(color=\"black\",width=2))))\n\nfig.add_trace(go.Scatter(x=X[:,0],y=X[:,1],mode=\"markers\",marker=dict(\n                size=20,color=T[:,0],colorscale=\"Viridis\",line=dict(color=\"black\",width=2))))\n\n\n\ndef frame_args(duration):\n    return {\n            \"frame\": {\"duration\": duration},\n            \"mode\": \"immediate\",\n            \"fromcurrent\": True,\n            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n        }\n\nsliders = [\n            {\n                \"pad\": {\"b\": 10, \"t\": 60},\n                \"len\": 0.9,\n                \"x\": 0.1,\n                \"y\": 0,\n                \"steps\": [\n                    {\n                        \"args\": [[f.name], frame_args(0)],\n                        \"label\": str(50*k),\n                        \"method\": \"animate\",\n                    }\n                    for k, f in enumerate(fig.frames)\n                ],\n            }\n        ]\n\n# Layout\nfig.update_layout(title='Change in Decision Boundary with Weight Update',width=600, height=600,\n                  xaxis_title=\"Input 1\", yaxis_title=\"Input 2\",\n                  scene=dict( zaxis=dict(range=[-0.1, 6.8], autorange=False), aspectratio=dict(x=1, y=1, z=1),),\n         updatemenus = [\n            {\n                \"buttons\": [\n                    {\n                        \"args\": [None, frame_args(50)],\n                        \"label\": \"&amp;#9654;\", # play symbol\n                        \"method\": \"animate\",\n                    },\n                    {\n                        \"args\": [[None], frame_args(0)],\n                        \"label\": \"&amp;#9724;\", # pause symbol\n                        \"method\": \"animate\",\n                    },\n                ],\n                \"direction\": \"left\",\n                \"pad\": {\"r\": 10, \"t\": 70},\n                \"type\": \"buttons\",\n                \"x\": 0.1,\n                \"y\": 0,\n            }\n         ],\n         sliders=sliders,\n    showlegend=False\n)\n\nfig.show()"
					}
					
				
		
				
					,
					
					"notes-neural-networks-multiayer-perceptron-perceptron-convergence-theorem": {
						"id": "notes-neural-networks-multiayer-perceptron-perceptron-convergence-theorem",
						"title": "Perceptron Convergence Theorem",
						"categories": "",
						"url": " /notes/neural_networks/multiayer-perceptron/perceptron-convergence-theorem",
						"content": "Perceptron Convergence Theorem\n\nIntroduction\nThe Perceptron Convergence Theorem is an important result as it proves the ability of a perceptron to achieve its result. This proof will be purely mathematical. There are some geometrical intuitions that need to be cleared first. This proof requires some prerequisites - concept of vectors, dot product of two vectors.\nWe will use the train function that we developed in the Mathematics Behind Perceptron  post. It will be included in a utils.py file which you can download  here. Also, ignore the visualization code, if that seems too complex.\n\nPlanes\n\nSince, we know that a Perceptron classifies only linearly separable data with a linear hyper-plane, let’s get some things clear about planes.\n\nThe equation of an n-dimensional hyper plane is:\n\n\n\nwhere \\(x_1,x_2,\\dots,x_n\\) are orthogonal axes.\n\nAnother way of describing a plane is in the form of a vector \\(\\mathbf{n} = (a_1,a_2, \\dots , a_n)\\) (which is normal to that plane) and a point(position vector) \\(\\mathbf{x_0}\\) which resides on that plane.\n\nNow any vector between point, \\(\\mathbf{x_0}\\), and any other general point \\(\\mathbf{x} = (x_1,x_2,\\dots,x_n)\\) on the plane is perpendicular to that plane, i.e:\n\n\n\nAccording to Eq. 1 and 2, using the dot product rule,\n\n\n\nThe shortest distance(with sign) of the plane from the origin, \\(p\\) is given by:\n\n\n\nIf we divide Eq.1 by \\(\\lVert \\mathbf{n} \\rVert\\), then,\n\n\n\nUsing \\(\\frac{\\mathbf{n}}{\\lVert \\mathbf{n} \\rVert}=\\hat{\\mathbf{n}}\\) and Eq. 4, we have\n\n\n\nThe above equation is called the Hessian Normal Form of a plane.\n\nIn this form, we need a unit vector perpendicular to plane and the distance of the plane from the origin to define the plane.\n\nPlanes with Perceptron\n\nThe Perceptron prediction rule is as follows:\n\n\n\nand,\n\n\n\nwhere \\(w_0\\) is the threshold of the neuron and \\(x_0\\) can be any constant, except Zero (we use -1).\n\nThe decison boundary is formed, when \\(h=0\\), so the equation of the decision hyper plane is:\n\n\n\nComapring the above equation with the general equation of a plane (Eq. 1), the normal vector, which we will represent by \\(\\mathbf{w}\\), is:\n\n\n\nwhich means the constant term in the general equtaion, \\(d\\), will be:\n\n\n\nwhich means the perpendicular distance of the plane from origin is,\\(p\\), (from Equation 4):\n\n\n\nNow we have the perpendicular vector as well as the perpendicular distance.\n\nLet’s see an example of the OR dataset\n\nimport numpy as np\nfrom utils import train\nnp.set_printoptions(precision=2)\n# the dataset\nX = np.array([[0,0],\n             [0,1],\n             [1,0],\n             [1,1]])\nT=np.array([[0],[1],[1],[1]])\n\n\n# fit the data\nweights = train(X,T,0.25,15,random_state=42)\n\n\nAccuracy: 1.0\n\n\n#plot decision boundaries, weight vector\n\ninp1 = np.linspace(0,0.5,10000)\n\nfig  = go.Figure(layout=dict(height=800,width=800,\n                            xaxis_title=\"Input 1\", yaxis_title=\"Input 2\",\n                            title=\"Decision Boundary with Scatter\",\n                            autosize=False,\n                            legend=dict(x=0.5,y=1),\n                            annotations=[dict(x=weights[1,0],y=weights[2,0],ax=0,ay=0,arrowhead=1,\n                                             startarrowsize=4,axref=\"x\",ayref=\"y\"),\n                                        dict(x=weights[1,0],y=weights[2,0],showarrow=False,text=f\"Weight Vector {weights[1:,0]}\",\n                                             yanchor=\"bottom\"),\n                                        dict(x=0.07,y=0.14,showarrow=False,text=\"Distance, p\",\n                                             yanchor=\"middle\", xanchor=\"center\", textangle=-40),\n                                        \n                                        ],\n                             shapes=[go.layout.Shape(type=\"path\",path=\"M 0,0 L 0,0.04 L 0.18673,0.21764 L 0.22673,0.21764\",\n                                                     line_color=\"MediumPurple\",),\n        \n                                     \n    ]\n                            )\n                )\nfig.add_trace(go.Scatter(x=X[:,0:1][T==1],y=X[:,1:][T==1],name= \"Output: 1\",mode=\"markers\",marker=dict(size=20)))\nfig.add_trace(go.Scatter(x=X[:,0:1][T==0],y=X[:,1:][T==0],name= \"Output: 1\",mode=\"markers\",marker=dict(size=20)))\nfig.add_trace(go.Scatter(x=inp1,y=(-(weights[1,0]*inp1) + weights[0,0])/weights[2,0],name= \"Decision Boundary\",mode=\"lines\",marker=dict(size=20)))\n\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nSo we can represent the decision boundary with the weight vector and the bias term.\n\nThe next step is to develop a comparison technique between two decision boundaries. The idea is to show that the decision boundary that our model is creating is close to the actual decision boundary. We will talk more about it in a moment.\n\nWe can just compare the unit vectors of the two weight vectors and the constant bias terms to find if the decision boundaries are similar or even same.\n\nBut this solution needs multiple comparisons, a vector comparison and a bias weight comparison. A better way is to consider this is to consider the bias weight as part of the weight vector.\n\nSo, in our OR example, the data will be considered 3-dimensional, with the 3rd dimension being constant(we have chosen -1).\n\nFor 3-dimensions, the decision boundary will be a plane, whose general equation is:\n\n\n\nand expanding Equation 8 for our OR data set, equation of our decision boundary is:\n\n\n\nAs we we can see, our bias input \\(x_0\\) is the 3rd dimension in this equation, which is constant (-1) in our dataset. The constant term \\(d\\) is Zero.\n\nSince \\(d=0\\), for our decision boundary, it means the distance between the hyper-plane and the origin, \\(p=\\frac{d}{\\lVert \\mathbf{w} \\rVert} = 0\\). Which implies the plane always passes through the origin of that higher coordinate system.\n\nThe above result can be generalized for any linearly separable n-dimensional data, that if we consider the bias inputs as part of the data, the resulting n+1 dimensional data will have its decision boundary passing through origin of the new coordinate system.\n\nThe above fact stands because in the higher dimension, the constant term is Zero, and so the origin satisfies the new decision boundary.\n\nLet’s try to verify this on our linearly separable OR-dataset. Our bias input is constant(-1). Let’s plot the data along with the decision boundary represented by our weights (now including the threshold/bias weight as well).\n\nxx,yy=np.meshgrid(np.arange(-2,1.25,0.1),\n                  np.arange(-2,1.25,0.1))\nZ = (-xx.ravel()*weights[1,0] - yy.ravel()*weights[1,0])/weights[0,0]\nZ = Z.reshape(xx.shape)\n\nfig = go.Figure()\n\n\n#scatter points\nfig.add_trace(\n    go.Scatter3d(x=X[:,0], # First input\n                y=X[:,1], # second input\n                z=[-1]*X.shape[0], # bias additional input\n                 mode=\"markers\",\n                marker=dict(size=10,color=T.squeeze(),colorscale=\"Viridis\"),name=\"Data Point\"\n                )\n                \n)\n\n\n#decision boundary\nfig.add_trace(\n    go.Surface(x=xx[0],y=yy[:,0],z=Z,showscale=False,colorscale=\"Viridis\",opacity=0.8\n              ,name=\"Decision Boundary\")\n)\n\n\n# weight vector\nfig.add_trace(\n    go.Cone(x=weights[1], y=weights[2], z=weights[0], u=weights[1], v=weights[2], w=weights[0], sizemode=\"scaled\",\n        sizeref=0.15, anchor=\"tip\", showscale=False, name=\"Weight Vector\", cmax=0, cmin=0, colorscale=[[0,'rgb(0,0,0)'],[1,'rgb(0,0,0)'],]\n    )\n)\nfig.add_trace(\n    go.Scatter3d(x=[0,weights[1,0]], y=[0,weights[2,0]], z=[0,weights[0,0]], mode=\"lines\", line=dict(width=4,color=\"black\"), name=\"Weight Vector\"\n    )\n\n)\n\n\n#origin\nfig.add_trace(\n    go.Scatter3d(\n        x=[0],y=[0],z=[0],name=\"origin\", mode=\"markers\", marker=dict(symbol=\"diamond\", size=5,color=\"green\")\n    )\n)\n\n\nfig.update_layout(\n    scene=go.layout.Scene(\n        camera=dict(\n            eye=dict(\n                x=0,\n                y=0,\n                z=2.2\n            ),\n            up=dict(\n                x=1,\n                y=0,\n                z=0\n            )\n        ),\n        dragmode=\"turntable\",\n        xaxis=dict(\n            title_text=\"Input 1\",\n            range=[-0.3,1.5],\n        ),\n        yaxis=dict(\n            title_text=\"Input 2\",\n            range=[-0.3,1.5],\n\n        ),\n        zaxis=dict(\n            title_text=\"Bias Input\",\n            range=[-1.3,0.5],\n        ),\n    ),\n    showlegend=False,\n    height=700,\n    width=700\n)\n\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nIf you look through the top of the bias axis, you can see the data points are same as they were in the 2D figure, and the weight vector looks the same as well. And the moment you rotate the above figure you can see this new higher dimensional decision boundary also classifies the data and infact passes through the previous decision boundary(the lower dimensional). Further more, you can also see that this plane has also passed through the origin of the coordinate axis.\n\nWith this intuition in mind, we can conclude that a higher dimensional decision boundary achieves the same goal, and to represent this higher dimensional hyper-plane, we just need the weight vector(which includes the bias weight as well!), since we already know it’s distance from the origin will be Zero.\n\nNow that we have established, that only the complete weight vector(it’s unit vector) defines the decision hyper-plane, two same vectors(or vectors in the same direction), will define the same hyper plane.\n\nThe Proof\n\nThe Perceptron Convergence theorem proved by Rosenblatt in 1962, states that:\n\n“given a linearly separable data, the perceptron will converge to a solution within \\(R/ \\gamma^2\\) iterations, where \\(\\gamma\\) is the distance between the separating hyperplane and the closest datapoint to it.”\n\nHowever there are some assumptions about it:\n\n  The data should be linearly separable.\n  For every input vector \\(x\\), \\(\\lVert \\mathbf{x} \\rVert\\) is bound by some constant R. In our proof we will assume \\(\\lVert \\mathbf{x} \\rVert \\leq R\\).\n  Also the learning rate is chosen to be 1.\n\n\nNow to the proof,\n\nWe know that the data is linearly separable, which means there exists a set of weights which represent the the seperating hyperplane. Let’s say these weights are \\(\\mathbf{w^*}\\).\n\nOur learning algorithm tries to find some vector \\( \\mathbf{w} \\) that is parallel to \\( \\mathbf{w^*} \\). To see if the vectors are parallel we use the inner product (also called the dot product) \\( \\mathbf{w^*} \\cdot \\mathbf{w} \\).\n\nSo,\n\n\n\nnow if two vectors are parallel the angle is \\(0\\), and \\(\\cos{0}=1\\) and so the inner product is maximum. If we show that after each update \\(\\mathbf{w^*} \\cdot \\mathbf{w}\\) increases, we have shown that the perceptron converges. However we need to be a bit more careful as \\(\\mathbf{w^*} \\cdot \\mathbf{w}\\) can also increase if \\(\\lVert \\mathbf{w} \\rVert\\) increases, we also need to check the length of \\(\\mathbf{w}\\) doesn’t increase too much.\n\nKeeping all that in mind, let’s move on.\n\nSuppose at the \\(i^{th}\\) iteration of the algorithm, the network sees a particular input vector \\(\\mathbf{x}\\) that has a target(ground truth) \\(t\\), and the output(prediction) was \\(y\\).\n\nNow, if the output was wrong, then\n\n\n\nTo see this result clearly, look at a few examples:\n\ne.g, if the target was 1 and output was 0, then,\n\n\n\nand\n\n\n\nor if the target was 0 and output was 1, then,\n\n\n\nand\n\n\n\nNow that there is error, the weights need to be updated according to the perceptron updation rule,\n\n\n\nNote: Please clear it that the above equations have been generalised as \\(\\mathbf{w^{(i)}}\\) is not a single weight, but a vector of weights to a neuron from the input nodes at \\(i^{th}\\) iteration and \\(\\mathbf{x}\\) is not a single input but the input vector(including the bias input), \\(y\\) and \\(t\\) are output and target of a single neuron and the symbol \\(\\cdot\\) represents inner product of two vectors.\n\nComing back to above equation, our proof assumes the learning rate of 1 and let’s use \\(t-y\\) instead of \\(y-t\\)(which changed sign, ofcourse!).\n\n\n\nNow to show that \\(w^* \\cdot w\\) increases with iterations, using Equation 15,\n\n\n\nThis is where we take a break  and think what \\(\\mathbf{w^*} \\cdot \\mathbf{x}\\) represents.\n\nIf you have any idea about the signed distance of a point \\(\\mathbf{x}\\) from a hyper-plane(which passes through origin) with coefficient vector \\(\\mathbf{a}\\) is:\n\n\n\nSimilarly \\(\\mathbf{w^*} \\cdot \\mathbf{x}\\) represents \\(\\lVert \\mathbf{w^*} \\rVert\\) times the signed distance between the point \\(\\mathbf{x}\\) and the plane represented by our vector \\(\\mathbf{w^*}\\) (which is the correct decision boundary)\n\nBy signed distance, I mean the sign regarding to what side of the plane the data point lies. Now if we have made an error and misclassified the point, then \\((t-y)\\) will be the opposite the sign of the sign of the distance given by the correct boundary. Give it a little thought, work out on different cases, you’ll get it.\n\nSo \\((t-y)(\\mathbf{w^*} \\cdot \\mathbf{x})\\) represents \\(\\lVert \\mathbf{w^*} \\rVert\\) times the magnitude of distance between the point \\(\\mathbf{x}\\) and the plane represented by our vector \\(\\mathbf{w^*}\\) (which is the correct decision boundary). And the smallest distance between the correct decision boundary and any datapoint is \\(\\gamma\\).\n\nSo,\n\n\n\nUsing the above equation in Equation 16,\n\n\n\nwhere \\(\\gamma\\) is the minimum distance between the optimal hyperplane defined by \\(\\mathbf{w^*}\\) and the closest datapoint to it.\n\nNow according to above equation, \\(\\mathbf{w^*} \\cdot \\mathbf{w^{(i)}}\\) always increases by at least \\(\\gamma\\) and we initialize the weights to be small random numbers(positive and negative), so after \\(i\\) iterations\n\n\n\nSo we have proved that \\(\\mathbf{w^*} \\cdot \\mathbf{w^{(i)}}\\) increases as iterations increase.\n\nSince the R.H.S of the above equation is positive,\n\n\n\nAlso we use Cauchy–Schwarz inequality,\n\n\n\nUsing Equations 21 and 22,\n\n\n\n\\(\\lVert \\mathbf{w^*} \\rVert\\) is positive and can be cancelled without affecting the inequality.\n\n\n\nHere we have put a lower limit to \\(\\lVert \\mathbf{w^{(i)}}\\rVert\\). Now we have to make sure that \\(\\lVert \\mathbf{w^{(i)}} \\rVert\\) does not increase too much.\n\nFor that we will use the Equation 15 and square the norm on both sides and use the Vector addition rules:\n\n\nNow using Perceptron rule, assumption 2(i.e, \\( \\lVert \\mathbf{x} \\rVert \\) is bound by some constant \\( R \\)) and Equation 13 repectively, we have\n\n\n\nRemember, the last equation here is when the output is incorrect.\n\nSo using the above equations (25):\n\n\n\nUsing the above equation in Equation 24,\n\n\n\nWhich shows \\(\\lVert \\mathbf{w^{(i)}}\\rVert ^2\\) does not increase more than what the input data is bound by. If we normalize the input before training, then the data will be bound by 1.\n\nNow according to Equation 26, after i iterations,\n\n\n\nHere we have put an upper limit on \\(\\lVert \\mathbf{w^{(i)}}\\rVert\\).\n\nWe have shown that \\(\\mathbf{w^*} \\cdot \\mathbf{w^{(i)}}\\) increases by atleast \\(i\\gamma \\lVert \\mathbf{w^*}\\rVert\\) and \\(\\lVert \\mathbf{w^{(i)}}\\rVert\\) does not increase more than \\(iR\\). Which means the angle between the vectors is decreasing and so the predicting decision boundary is getting close to the actual decision boundary, and after certain weight updates, the algorithm will converge to the actual boundary.\n\nUsing Equation 23 and 27,\n\n\n\nSo within \\(R/\\gamma^2\\) iterations, the algorithm must have converged.\n\nWe have shown that if the data is linearly separable, then the algorithm will converge, and the time it will take is a function distance between the separating hyperplane and the nearest point. This is actually called margin.\n\nNote: The perceptron stops learning as soon as it gets all the data correctly classified, and so there is no guarantee that it will find the largest margin, just that if there is a separator, it will find it.\n\nNote: By weight update we mean just update weight when the algorithm makes an error and so only those weight updates count to the iterations. We do not count the examples which the algorithm classifies correctly."
					}
					
				
		
				
					,
					
					"notes-neural-networks-multiayer-perceptron-perceptron": {
						"id": "notes-neural-networks-multiayer-perceptron-perceptron",
						"title": "Maths Behind Perceptron",
						"categories": "",
						"url": " /notes/neural_networks/multiayer-perceptron/perceptron",
						"content": "Mathematics Behind Perceptron\nIntroduction\nThis is actually a notebook made by me during the internet shutdown in Kashmir (since 5th Aug 2019). This notebook, and others, are heavily inspired by  Machine Learning: An Algorithmic Perspective  . This notebook is essentially the notes of chapter 3 of this book. I highly recommend this book for the basic understanding of Machine Learning Algorithms. This post covers mathematics, implementation of the basic perceptron algorithm. I would suggest to practice on the code for perceptron. Although stay away from the visualization code, if that seems too complex.\n\nHebb’s Rule\n\nIt states that “the changes in the strength of synaptic connections are proportional to the correlation in the firing of two connecting neurons”\n\nMcCulloch and Pitts Neurons\n\n1. Introduction\n\nThis was a mathematical model of a neuron. It extracts the basic essentials to accurately represent the entity being studied(the neurons that make our nervous system!), removing all the extraneous details.\n\nIt is modelled as:\n\n  a set of weighted inputs, \\(w_i\\), that correspond to synapses.\n  an adder, that sums the input signals.\n  an activation function(usually a threshold function), that decides whether the neuron fires(spikes!) for the current inputs.\n\n\nSo,\n\n\n\nwhere \\(w_i\\) is the weight at the synapse for \\(i^{th}\\) input and \\(x_i\\) is the input from \\(i^{th}\\) neuron into synapse.\n\nNow to decide if the neuron fires or not, we need a threshold (\\(\\theta\\)). If the weighted sum of the inputs(\\(h\\)) is greater than the threshold, the neuron fires(i.e output is 1).\n\nSo the activation function is:\n\n\n2. Limitations\n\n\n  The inputs to a real neuron aren’t necessarily summed linearly: there may be non-linear summations.\n  The real neurons do not output a single response, instead a train of spikes like a sequence of pulses is produced which encodes information.\n  The neurons do not update themselves sequentially according to a computer clock but do it asynchronously.\n  The weights in our model can be positive and negative, implying the presence of excitation or inhibitance property, which is also possesed by the real neurons but unlike real neurons our model change change from exciting to inhibitory after weight updates while real neurons stay the way they are(exciting or inhibitory).\n\n\nThe Perceptron\n\n1. Introduction\n\nThe perceptron is nothing more than a collection of McCulloch and Pitts neurons together with a set of inputs and some weights to fasten the inputs to the neurons. The neurons in the Perceptron are completely independent of each other.\n\n\nFigure 1: The Perceptron Network(the orange nodes are inputs, not neurons)\n\nEach neuron has its own weights which it multiplies with its input and adds them to decide whether to fire or not depending on its own threshold. The inputs are the number of features(usually columns) our data has. The number of neurons can be varied and is usually the total unique classifying target values.\n\nWe represent a particular weight as \\(w_{ij}\\) where \\(i\\) is the input it is coming from and \\(j\\) is the neuron it is going into. So \\(w_{32}\\) is the weight that connects the input node 3 to neuron 2. In the implementation, we will save the weights in a two dimensional array.\n\nThe input will be stored as a vector and so the output.\n\n2. Implementation\n\n2.1 Introduction\n\nIn supervised learning, we already have a ground truth target.\n\n\n  For an input vector, we apply Equation 1 for each neuron to decide if each neuron will fire or not, generating its the output vector.\n  For an output vector(a vector of 0s and 1s which determine if the corresponding neurons have fired or not!), we compare it to the target vector(the actual value for that input) to identify which neurons got the answer right and which did not.\n  Those neurons with correct outputs are fine but those with wrong outputs(i.e they fire when they didn’t have to or didn’t when they had to), their weights need to be changed so that they fire correctly.\n\n\n2.2 Learning the Weights\n\n2.2.1 Introduction\n\nWe’ll talk more about it later, but for now let’s deploy a simple learning system.\n\n\\(m:\\) no. of input features.\n\n\\(n:\\) no. of output neurons.\n\n\\(x_i, \\ i \\in [0,m]:\\) the input vector of m features.\n\n\\(y_i, \\  i \\in [0,n]:\\) the output vector of n neurons.\n\n\\(t_i, \\ i \\in [0,n]:\\) the actual target vector.\n\nSuppose \\(k^{th}\\) neuron gets the wrong answer, it has \\(m\\) weights connected to it(one for each input node). The weights we need to change is \\(w_{ik}\\) where \\(i\\) runs from \\(1\\) to \\(m\\).\n\nNow we know which weights to change, but by how much to change them by?\n\nBefore answering that, let’s figure out if a weight is too high or low(i.e do we need to increase it or decrease it?).\n\nAt the first glance, we can say that bigger weights tend a neuron to fire(as they help it get over the threshold) and smaller weights tend to not fire. So if a neuron fires when it wasn’t supposed to, there are some weights which are bigger than they should be, or if doesn’t fire when it should(some weights are too small!).\n\nFor that neuron we can calculate:\n\ni.e the difference between the output of the nepuron and the actual truth.\n\nIf the above equation is Zero, then neuron has the correct output. However if it is positive(specifically \\(1\\)), then the neuron has fired when it shouldn’t have, i.e weights are big and if it is negative(specifically \\(-1\\)), then the neuron hasn’t fired when it should have, i.e weights are small. The above equation can act as a possible error function.\n\nSo until now we know:\n\nthe weights \\(w_{ij}\\) will be changed by \\( \\Delta w_{ij}\\)\n\nwhere,\n\n\n\nwhere \\(k\\) is the constant which gives the amount by which each weight needs to be changed.\n\nWhile this all seems right, we have missed something. What if the inputs are negative?\n\nIf the inputs are negative, then switch values, we’ll need to reduce the weights to fire and increase to not fire.\n\nTo get around that we make a change:\n\n\n\nif \\(x_i\\) is negative it will automatically change the direction of weight change and \\(k\\) decides how much the weight changes by. The parameter \\(k\\) is called the learning rate and is often represented by \\(\\eta\\) instead of k.\n\nso\n\n\n\nFinally we update the weights,\n\n\n\nWe can update these for an optimum learning rate for some predefined \\(T\\) iterations. However we will later see other stopping methods.\n\n2.2.2 Learning Rate\n\nThe learning rate is an important parameter which needs to be tuned to get better accuracies. Too high value of it might change the weights more than they were needed to and a too low will take too long to train. It is often used in the range of \\( 10^{-4} &lt; \\eta &lt; 10 \\). But feel free to check out of these bounds. Also for perceptron this parameter is way less important and can be set to anything. However for other models it is the most crucial parameter.\n\n2.2.3 Bias node\n\nNow that we have figured out the weights, but we haven’t discussed another important parameter, the threshold. What threshold to choose for what problem? That is where a Bias node comes into play.\n\nWe can show Equation 1 for a certain neuron as:\n\n\n\nwhere \\(x_k\\) is \\(k^{th}\\) input feature and \\(w_{kj}\\) is the weight from \\(k^{th}\\) input node to \\(j^{th}\\) neuron.\n\nNow, if the threshold is \\(\\theta\\), Equation 2 shows that:\n\n\n\nso \\(\\theta\\) can be learned as another weight, if we consider an extra input feature which is always \\(-1\\) and our new threshold is \\(0\\).(However \\(\\theta_j\\) is the actual threshold which instead of defining, we let the neuron to learn like any other weight.)\n\nThe Bias Node also helps us overcome the all-zero input problem. If all the inputs in an example are Zero then no matter how the weights change, it won’t change the output, but the bias node will change and make changes necessary for correct output.\n\nSo to make it work we will also need an extra but constant input node reserved for -1.\n\nNote : Actually, it is not necessary to use -1 as the bias input. Any constant will do. People mostly use +1 but we will use -1 to make it stand out.\n\nThe Bias Node is considered the \\(x_0\\) which is constant(-1) and the weight to it is \\(w_{0j}\\)(which is actually \\(\\theta_j\\)).\n\nSo the new Structure is like:\n\n\nFigure 2: Perceptron with Bias Node\n\n2.3 Putting Everything Together\n\nNow that we have all the things cleared out, it is time to put everything together.\n\nThe algorithm is separated into two parts: a training phase and a recall phase. The recall is essentially used after training is finished to actually use the model.\n\nThe Algorithm is as:\n\n1. Initialization:\n\n\n  set all the weights \\(w_{ij}\\) to small random numbers(both positive and negative).\n\n\n2. Training:\n\n  for \\(T\\) iterations or untill all outputs are correct:\n    \n      for each input vector:\n        \n          compute the activation of each neuron \\(j\\) using:\n        \n\n        \n\n        where \\(x_0\\) is -1 (the bias node) and \\(m\\) is the number of features our data has.\n\n        \n          update each of the weights individually using:\n \n        \n      \n    \n  \n\n\n3. Recall:\n\n  \n    compute the activation of each neuron \\(j\\) using:\n\n    \n  \n\n\n2.4 Speeding Up the code\n\n2.4.1 Speeding Up the computation of activations\n\nThe code for it has multiple loops for training. Loops for multiplying the weights with inputs and loops while updating weights. The simple loops can take a lot of time, but many languages, like python, have libraries(numpy, tensorflow, pytorch) to perform matrix perations much quicker than simple loops. We will put these to our use to speed up the training as well as the recall process as well.\n\nLet’s say we have \\(k\\) number of training examples and each example has \\(m\\) features with \\(n\\) types of outputs.\n\nNow instead of taking one example at a time and updating weights and doing the same for \\(T\\) iterations, we can store all our training examples in a matrix where each example is a row and each column is a feature.\n\nSo the 4th feature of 6th training example will look like \\(x_{64}\\).\n\nSo our input matrix \\(X\\) should look like:\n\n\n\nThis matrix will be \\(k \\times m\\).\n\nIn python we would do this using a library called numpy\n\nimport numpy as np\n\n\nlet’s say we want to train to learn the Logical-OR function.\nSo our input should look like:\n\n\n\nwe can make it make it using np.array method:\n\nX = np.array([[0,0],\n             [0,1],\n             [1,0],\n             [1,1]])\nX\n\n\narray([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n\n\nnow our input is ready, let’s figure out how to store the target values. Each input has target values for which neuron to fire and which not to(1s and 0s).\n\nSo with \\(k\\) examples and \\(n\\) output neurons, the target matrix should be \\([t_{ij}]\\) which is the target for \\(i^{th}\\) example and \\(j^{th}\\) neuron.\n\nSo,\n\nwhere \\(t_{ij} \\in {0,1}\\)\n\nFor binary outputs, like in our example, we can just use one output neuron, which will fire for one output and not fire for other which means \\(n=1\\).\n\nSo,\n\n\n\nand in our example,\n\n\n\nwe can do it in numpy in the same way:\n\nT = np.array([[0],[1],[1],[1]]);T\n\n\narray([[0],\n       [1],\n       [1],\n       [1]])\n\n\nMoving on to the outputs generated by our neurons. For \\(n\\) neurons and \\(k\\) examples, we can store that in a matrix \\([y_{ij}]\\) for \\(i^{th}\\) example and \\(j^{th}\\) neuron like:\n\n\nwhere \\(y_{ij} \\in {0,1}\\)\n\nSo,\n\n\nif we replace all of it in the matrix,\n\n\nwhere \\(h_{ij} =(-1)w_{0j}+\\sum_{a=1}^{m}x_{ia}w_{aj}\\)\n\nor if we keep\n\n\n\n\nThe above matrix looks like a multiplication of two matrices. Let’s open it up:\n\n\n\nif we look at the Left Matrix it is the input matrix (\\(X\\)) with extra column on far left and we know the far left column is always -1, so we can actually redefine the input matrix to include this extra column.\n\n\n\nThis matrix is now \\(k \\times (m+1)\\).\n\nwe can generate a column of -1 using the np.ones method and then concatenate it with our input matrix using np.concatenate to form the new input matrix, like:\n\nX = np.concatenate((-np.ones((X.shape[0],1)),X),axis=1)\nX\n\n\narray([[-1.,  0.,  0.],\n       [-1.,  0.,  1.],\n       [-1.,  1.,  0.],\n       [-1.,  1.,  1.]])\n\n\nNow that we have fixed the input matrix, let’s move to the second matrix in Equation 12, the weight matrix.\n\n\nwhere \\(w_{ij}\\) is the weight from \\(i^{th}\\) input node to \\(j^{th}\\) output neuron\n\nThis matrix is \\( (m+1) \\times n\\).\n\nwith Equation 13 can be rewriten as:\n\n\nwhere:\n\n  \\(X\\) is the input matrix(Equation 13 with bias nodes.\n  \\(W\\) is the weight matrix (Equation 14).\n  \\(\\times\\) represents matrix multiplication.\n  and the function \\(g\\)(Equation 8) is applied elementwise to the resultant matrix to generate outputs for every neuron for every training example.\n\n\nWe will use the np.matmul function to perform a matrix multiplication and we will use the numpy boolean mask broadcasting to compute activations. Since we have to repeat this step, we will make a function for this named compute_activations. so Y=compute_activations(X,W) whenever needed.\n\ndef compute_activations(X,W):\n    activation = np.matmul(X,W) &gt; 0\n    return activation\n\n\nThis completes the first part of the Training Algorithm (i.e compute activation of each neuron for each input example). Now let’s move to the Second Part of the Training, Updating Weights.\n\n2.4.2 Speeding up the the updation of weights\n\nThe updation of weights is given by Equation 4, which is:\n\n\nwhere \\(w_{ij}\\) is the weight from \\(i^{th}\\) input node to \\(j^{th}\\) output neuron.\n\nWe can vectorize this operation, instead of updating every weight using a loop, we update the whole weight matrix at once.\n\n\nwhere \\(W\\) is the weight matrix and \\( \\Delta W \\) is the matrix having the corresponding \\((y_j - t_j) \\cdot x_i\\) for each weight.\n\nNow before we move on figure out how \\(\\Delta W\\) should be computed, let’s put a detour to see how the weight changes for different examples.\n\nLet’s say we had three examples. Each weight will be updated three times with their corresponding \\(x_i\\).\n\nLet’s denote \\(x_{ij}\\) as the \\(j^{th}\\) input feature of \\(i^{th}\\) example and \\(t_{ia}\\) as the target for \\(i^{th}\\) example and \\(a^{th}\\) output neuron. So, \\(1\\leq i \\leq 3\\).\n\nNow after each example, weights will change, like:\n\n\n\n\n\n\n\neach of the above change will occur to each weight one after the another. so these can be summed as:\n\n\n\nIt can be generalized as, for \\(k\\) examples:\n\n\n\nSo \\(\\Delta W\\) is just a matrix of the \\(\\sum_{i=1}^k(y_{ia} - t_{ia}) x_{ij}\\) for every neuron and for every example.\n\nSo, for \\(k\\) examples with \\(m+1\\) input features (the first being \\(x_{i0} = -1\\)) and \\(n\\) output neurons\n\n\n\nThis matrix is \\((m+1) \\times n\\) same as the weights matrix.\n\nTake some time to write it down and look at every entry to make it clear for yourself.\n\nLet’s unpack this bad boy! So it also looks like a matrix multiplication of two matrices.\n\n\n\nThe right matrix is basically the subtraction of target matrix \\(T\\) ([Equation 6]) subtracted from the output matrix \\(Y\\) ([Equation 7]).\n\n\n\nThe left matrix is the transpose of the input matrix with bias values \\(X\\) (Equation 13).\n\n\n\nFinally,\n\n\n\nUsing the above equation, Equation 16 becomes:\n\n\n\nwhere:\n\n  \\(X^T\\): is the transpose of input matrix.\n  \\(Y\\): is the output matrix.\n  \\(T\\):  is the target matrix.\n  \\( \\eta \\):  is the learning rate.\n  \\(\\times\\):  represents matrix multiplication.\n\n\nnow to compute the transpose of a matrix, we use np.transpose function. we can use the simple minus operator to perform subtraction in matrices. Also to multiply each element by \\(\\eta\\), we use the broadcasting property. Since this step is also going to be used multiple times, we will turn it into a function, like:\n\ndef update_weights(weights, input_matrix, output_matrix, target_matrix, learning_rate):\n    delta_w = np.matmul(np.transpose(input_matrix),(output_matrix-target_matrix))\n    weights = weights - (learning_rate*delta_w) # elementwise multiplication using broadcasting\n    return weights\n\n\nbut before updating the weight matrix, we need to initialize a weight matrix with small random numbers. we can use the np.random.rand to generate random numbers between 0 and 1, then multiply by 0.1 (to make them small) and subtract 0.05 to get some negative weights.\n\ndef initialize_weights(n_input,n_out):\n    # the input shape should be including the bias inputs\n    weights = np.random.rand(n_input, n_out)*0.1 - 0.05\n    return weights\n\n\n2.5 Final Code\n\nnow that we have finished all the functions for training as well as initialization, for recall, we can again use the compute_activations function.\n\nLet’s put the code together and run for an example. while training, we can print weights and output after each iteration.\n\ndef compute_activations(X,W):\n    activation = (np.matmul(X,W) &gt; 0)\n    return activation\n\ndef initialize_weights(n_input,n_out, random_state):\n    np.random.seed(random_state)\n    # the input shape should be including the bias inputs\n    weights = np.random.rand(n_input, n_out)*0.1 - 0.05\n    return weights\n\ndef update_weights(weights, input_matrix, output_matrix, target_matrix, learning_rate):\n    delta_w = np.matmul(np.transpose(input_matrix),(output_matrix-target_matrix))\n    weights = weights - (learning_rate*delta_w) # elementwise multiplication using broadcasting\n    return weights\n\ndef train(input_data, target, learning_rate, epochs,random_state=0,init_weights=None, save_weights=False, verbose=False):\n    # add the bias values to input_matrix\n    X = np.concatenate((-np.ones((input_data.shape[0],1)),input_data),axis=1)\n    #set the shapes\n    n_input = X.shape[1]\n    n_out = target.shape[1]\n    \n    #initialize the weights\n    if init_weights is None:\n        W = initialize_weights(n_input,n_out, random_state)\n    else:\n        W = init_weights\n        \n    if save_weights:\n        weight_array=[W]\n        \n    for it in range(epochs):\n        # compute outputs\n        Y = compute_activations(X,W)\n        \n        if verbose:\n            #print the output\n            print(f\"Iteration: {it}\\n{W}\\nOutput:\\n{Y[:10,:10]}\\nAccuracy: {(Y==target).sum()/X.shape[0]}\")\n        \n        # update weights\n        W = update_weights(W, X, Y, target, learning_rate)\n        \n        if save_weights:\n            weight_array.append(W)\n    if save_weights:\n        return W, weight_array\n    else:\n        return W\n        \ndef recall(input_data, weights):\n    # add the bias values to input_matrix\n    X = np.concatenate((-np.ones((input_data.shape[0],1)),input_data),axis=1)\n    # compute activations\n    Y = compute_activations(X,weights)\n    return Y\n    \n\n\nThis is all we need for a perceptron code. After a good time, you can feel the simplicity and elegancy of it.\n\nLet’s try it for an OR data. Let’s see if it can learn the parameters.\n\n prepare the data\nX = np.array([[0,0],\n             [0,1],\n             [1,0],\n             [1,1]])\n\nT = np.array([[0],[1],[1],[1]])\n\ntrain the data\nweights = train(input_data=X,target=T,learning_rate=0.25,epochs=6, random_state=42,verbose=True)\n\n\nIteration: 0\n[[-0.01254599]\n [ 0.04507143]\n [ 0.02319939]]\nOutput:\n[[ True]\n [ True]\n [ True]\n [ True]]\nAccuracy: 0.75\nIteration: 1\n[[0.23745401]\n [0.04507143]\n [0.02319939]]\nOutput:\n[[False]\n [False]\n [False]\n [False]]\nAccuracy: 0.25\nIteration: 2\n[[-0.51254599]\n [ 0.54507143]\n [ 0.52319939]]\nOutput:\n[[ True]\n [ True]\n [ True]\n [ True]]\nAccuracy: 0.75\nIteration: 3\n[[-0.26254599]\n [ 0.54507143]\n [ 0.52319939]]\nOutput:\n[[ True]\n [ True]\n [ True]\n [ True]]\nAccuracy: 0.75\nIteration: 4\n[[-0.01254599]\n [ 0.54507143]\n [ 0.52319939]]\nOutput:\n[[ True]\n [ True]\n [ True]\n [ True]]\nAccuracy: 0.75\nIteration: 5\n[[0.23745401]\n [0.54507143]\n [0.52319939]]\nOutput:\n[[False]\n [ True]\n [ True]\n [ True]]\nAccuracy: 1.0\n\n\nand with a learning rate of 0.25, it can learn the parameters for OR gate in just 6 iterations.\n\n3. Visualization\n\nNow that we have completely studied the basic perceptron. Let’s visualize some things to get the better understanding.\n\nwe will use the plotly’s express and graph_objects for plotting.\n\nLet’s first plot our input data\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n\nfig = px.scatter(x=X[:,0], y=X[:,1], color=T.astype(\"str\"), size=[8]*X.shape[0],\n                 labels={\"x\":\"Input 1\",\"y\":\"Input 2\",\"color\":\"Output\"},\n                 title=\"Scatter of Data Points\", height=600, width=600, opacity=1)\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nNow let’s see what the weights represent.\n\nWe know that \\(w_{ij}\\) is the weight from \\(i^{th}\\) input node to \\(j^{th}\\) output node.\n\nSince we have only one output neuron and 2 input nodes(3 with bias node).\n\nOur Weights compute, for each example:\n\\(w_{01}(-1) + w_{11}\\cdot inp1+w_{12}\\cdot inp2\\) and then check if it is greater than or less than Zero.\n\nFor the boundary case,\n\n\n\nif we were to plot this threshold line with \\(inp2\\) as the y-axis and \\(inp1\\) on the x-axis, then:\n\n\nSo,in the previous example, our final weights were:\n\nweights\n\n\narray([[0.23745401],\n       [0.54507143],\n       [0.52319939]])\n\n\ninp1 = np.linspace(0,0.5,100)\n\nfig  = go.Figure(layout=dict(height=600,width=600,\n                            xaxis_title=\"Input 1\", yaxis_title=\"Input 2\",\n                            title=\"Decision Boundary with Scatter\"))\nfig.add_trace(go.Scatter(x=X[:,0:1][T==1],y=X[:,1:][T==1],name= \"Output: 1\",mode=\"markers\",marker=dict(size=20)))\nfig.add_trace(go.Scatter(x=X[:,0:1][T==0],y=X[:,1:][T==0],name= \"Output: 1\",mode=\"markers\",marker=dict(size=20)))\nfig.add_trace(go.Scatter(x=inp1,y=(-(weights[1,0]*inp1) + weights[0,0])/weights[2,0],name= \"Decision Boundary\",mode=\"lines\",marker=dict(size=20)))\n\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\na more sophisticated  decision boundary\n\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/500),\n                      np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/500))\nZ = recall(np.c_[xx.ravel(),yy.ravel()],weights)\nZ = Z.reshape(xx.shape)*1\n\n\nfig = go.Figure(layout=dict(width=600,height=600))\n\nfig.add_trace(\n    go.Heatmap(\n        x=xx[0],\n        y=yy[:,1],\n        z=Z,\n        colorscale=\"Viridis\",\n        showscale=False\n))\nfig.add_trace(\n    go.Scatter(\n        x=X[:,0],y=X[:,1],mode=\"markers\",\n        marker=dict(\n            size=20,\n            color=T[:,0],\n            colorscale=\"Viridis\",\n            line=dict(color=\"black\",width=2))\n    )\n)\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nall the points above this line will cause the fire of the current neuron, and all the below won’t.\n\nLet’s see the updation of weights and it’s impact on the decision boundary.\n\nwe will train the model while saving the weights to plot it. We will set the learning rate to be small so that the animation is smooth and we get a good idea of what is happening. You can change it. I have also increased the number of epochs as the learning rate is small now. Also play with different random_state to start from initial different weights.\n\nW, weight_array = train(input_data=X,target=T,learning_rate=0.001,epochs=100,save_weights=True,random_state=364)\n\n\nafter having all the weights saved, we will plot them one after the other using the animation.FuncAnimation function. Change the interval if the animation is too slow or too fast.\n\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/200),\n                      np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/200))\n\nZ = [recall(np.c_[xx.ravel(),yy.ravel()],weights).reshape(xx.shape)*1 for weights in weight_array]\n\nnb_frames = 98\n\nfig = go.Figure(frames=[\n    go.Frame(\n        data=[\n            go.Heatmap(\n            x=xx[0],\n            y=yy[:,1],\n            z=Z[k],\n            colorscale=\"Viridis\",\n            showscale=False\n        ),\n           ],\n        name=str(k)\n        )\n    for k in range(nb_frames)])\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\n\n\ndef frame_args(duration):\n    return {\n            \"frame\": {\"duration\": duration},\n            \"mode\": \"immediate\",\n            \"fromcurrent\": True,\n            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n        }\n\nsliders = [\n            {\n                \"pad\": {\"b\": 10, \"t\": 60},\n                \"len\": 0.9,\n                \"x\": 0.1,\n                \"y\": 0,\n                \"steps\": [\n                    {\n                        \"args\": [[f.name], frame_args(0)],\n                        \"label\": str(k),\n                        \"method\": \"animate\",\n                    }\n                    for k, f in enumerate(fig.frames)\n                ],\n            }\n        ]\n\n# Layout\nfig.update_layout(\n         title='Change in Decision Boundary with Weight Update',\n         width=600,\n         height=600,\n         scene=dict(\n                    zaxis=dict(range=[-0.1, 6.8], autorange=False),\n                    aspectratio=dict(x=1, y=1, z=1),\n                    ),\n         updatemenus = [\n            {\n                \"buttons\": [\n                    {\n                        \"args\": [None, frame_args(50)],\n                        \"label\": \"&amp;#9654;\", # play symbol\n                        \"method\": \"animate\",\n                    },\n                    {\n                        \"args\": [[None], frame_args(0)],\n                        \"label\": \"&amp;#9724;\", # pause symbol\n                        \"method\": \"animate\",\n                    },\n                ],\n                \"direction\": \"left\",\n                \"pad\": {\"r\": 10, \"t\": 70},\n                \"type\": \"buttons\",\n                \"x\": 0.1,\n                \"y\": 0,\n            }\n         ],\n         sliders=sliders,\n    showlegend=False\n)\n\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nAs you can see, the decision boundary was initially in the right spot but with reversed thresholds, and with changing epochs it flipped.\n\n4. Linear Separability\n\n4.1 Introduction\n\nAs we saw just now, in the visualization section, a Perceptron tries to draw a line between the two classes of data. That is for 2D (or two input features). For 3D (three input features, it will draw a plane to separate out the two classes.\n\nNow for multiclass output, there will be multiple output neuron and each will have a decision boundary that will separate out the different classes(see figure):\n\n\n\nFigure 3: Multiclass Classification by a perceptron.\n\nNow it is evident that the data should be linearly separable among each class for a perceptron to work properly.\n\n4.2 The Perceptron Convergence Theorem\n\nThe Perceptron Convergence theorem proved by Rosenblatt in 1962, states that:\n\n“given a linearly separable data, the perceptron will converge to a solution within \\(1/ \\gamma^2\\) iterations, where \\(\\gamma\\) is the distance between the separating hyperplane and the closest datapoint to it.”\n\nHowever there are some assumptions about it:\n\n  The data should be linearly separable.\n  For every input vector \\(x\\), \\( \\mid  \\mid x \\mid  \\mid \\) is bound by some constant R. In our proof we will assume \\( \\mid  \\mid x \\mid  \\mid  \\leq 1\\).\n  Also the learning rate is chosen to be 1.\n\n\nThe point being, if the data is linearly separable, irrespective of the constant \\( \\mid  \\mid x \\mid  \\mid \\) is bound by or the value of learning rate, the perceptron will converge to the solution in finite iterations(i.e, it will find the solution).\n\nYou can see the proof of this theorem here\n\n\n\n4.3 Linear Inseparability Example(XOR Logic)\n\nLet’s try to learn the XOR Logic. Let’s prepare the dataset.\n\nX = np.array([[0,0],\n             [0,1],\n             [1,0],\n             [1,1]])\n\nT = np.array([[0],[1],[1],[0]])\n\n\nLet’s first visualize the data points ourselves.\n\nfig = go.Figure(layout=dict(width=600,height=600)) \nfig.add_trace(go.Scatter(x=X[:,0],y=X[:,1], mode=\"markers\", marker=dict(size=20,color=T.squeeze())))\nfig.show()\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nThere is no line we can draw to separate the two classes. Let’s see how the perceptron behaves.\n\nW, weight_array = train(input_data=X,target=T,learning_rate=0.001,epochs=50,save_weights=True,random_state=364)\n\n\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/200),\n                      np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/200))\n\nZ = [recall(np.c_[xx.ravel(),yy.ravel()],weights).reshape(xx.shape)*1 for weights in weight_array]\n\nnb_frames = 60\n\nfig = go.Figure(frames=[\n    go.Frame(\n        data=[\n            go.Heatmap(\n            x=xx[0],\n            y=yy[:,1],\n            z=Z[k],\n            colorscale=\"Viridis\",\n            showscale=False\n        ),\n             ],\n        name=str(k) \n        )\n    for k in range(nb_frames)])\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\nfig.add_trace(go.Scatter(\n            x=X[:,0],y=X[:,1],mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=T[:,0],\n                colorscale=\"Viridis\",\n                line=dict(color=\"black\",width=2))\n        ))\n\n\n\ndef frame_args(duration):\n    return {\n            \"frame\": {\"duration\": duration},\n            \"mode\": \"immediate\",\n            \"fromcurrent\": True,\n            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n        }\n\nsliders = [\n            {\n                \"pad\": {\"b\": 10, \"t\": 60},\n                \"len\": 0.9,\n                \"x\": 0.1,\n                \"y\": 0,\n                \"steps\": [\n                    {\n                        \"args\": [[f.name], frame_args(0)],\n                        \"label\": str(k),\n                        \"method\": \"animate\",\n                    }\n                    for k, f in enumerate(fig.frames)\n                ],\n            }\n        ]\n\n# Layout\nfig.update_layout(\n         title='Change in Decision Boundary with Weight Update',\n         width=600,\n         height=600,\n         scene=dict(\n                    zaxis=dict(range=[-0.1, 6.8], autorange=False),\n                    aspectratio=dict(x=1, y=1, z=1),\n                    ),\n         updatemenus = [\n            {\n                \"buttons\": [\n                    {\n                        \"args\": [None, frame_args(50)],\n                        \"label\": \"&amp;#9654;\", # play symbol\n                        \"method\": \"animate\",\n                    },\n                    {\n                        \"args\": [[None], frame_args(0)],\n                        \"label\": \"&amp;#9724;\", # pause symbol\n                        \"method\": \"animate\",\n                    },\n                ],\n                \"direction\": \"left\",\n                \"pad\": {\"r\": 10, \"t\": 70},\n                \"type\": \"buttons\",\n                \"x\": 0.1,\n                \"y\": 0,\n            }\n         ],\n         sliders=sliders,\n    showlegend=False\n)\n\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nas you can see, the perceptron fails to find a linear boundary and dangles between the two sides. So even a simple function like XOR cannot be learned by the perceptron. This discovery halted the neural network development for at least 20 years. There is an obvious solution though(Multiple layers, but we’ll get to that at its own time!).\n\n4.4 Higher dimensions is the answer?\n\nSince we cannot draw a line in the XOR dataset to separate it, how about taking the data to a higher dimension(the 3rd dimension in our case)? We can find a plane to separate the two classes in 3D. We will add a dimension in such a way that it does not change the data when looked in the \\((x,y) \\) plane, but moves point \\((0,0) \\) along the third dimension.\n\nThe truth table can be like:\n\n\n  \n    \n      Input 1\n      Input 2\n      New dimension\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      0\n      1\n      0\n    \n    \n      1\n      0\n      0\n    \n    \n      1\n      1\n      0\n    \n  \n\n\nX = np.array([[0,0,1],\n             [0,1,0],\n             [1,0,0],\n             [1,1,0]])\nT = np.array([[0],[1],[1],[0]])\n\n\nfig = go.Figure()\nfig.add_trace(\n    go.Scatter3d(x=X[:,0],y=X[:,1],z=X[:,2],mode=\"markers\",marker=dict(size=10,color=T.squeeze(),colorscale=\"Viridis\"))\n)\n\nfig.update_layout(\n    title=\"Plot Title\",\n    \n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            text='x Axis',\n            font=dict(\n                family='Courier New, monospace',\n                size=18,\n                color='#7f7f7f'\n            )\n        )\n    ),\n    yaxis_title=\"y Axis Title\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=10,\n        color=\"#7f7f7f\"\n    )\n)\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nwe can now easily see a plane separating the two kinds, just by lifting one point into the third dimension. Also if you rotate the figure to see the input2 and input1 as the y-axis and x-axis, you can see the exact same plot as before.\n\nNow let’s train a model and check the accuracy.\n\nW = train(X,T,learning_rate=0.5,epochs=20,random_state=364,verbose=True)\n\n\nIteration: 0\nOutput:\n[[ True]\n[False]\n[False]\n[False]]\nAccuracy: 0.25\nIteration: 1\nOutput:\n[[ True]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.5\nIteration: 2\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 3\nOutput:\n[[False]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.75\nIteration: 4\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 5\nOutput:\n[[ True]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.5\nIteration: 6\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 7\nOutput:\n[[False]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.75\nIteration: 8\nOutput:\n[[False]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.75\nIteration: 9\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 10\nOutput:\n[[False]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.75\nIteration: 11\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 12\nOutput:\n[[ True]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.5\nIteration: 13\nOutput:\n[[False]\n[False]\n[False]\n[False]]\nAccuracy: 0.5\nIteration: 14\nOutput:\n[[False]\n[ True]\n[ True]\n[ True]]\nAccuracy: 0.75\nIteration: 15\nOutput:\n[[False]\n[ True]\n[ True]\n[False]]\nAccuracy: 1.0\nIteration: 16\nOutput:\n[[False]\n[ True]\n[ True]\n[False]]\nAccuracy: 1.0\nIteration: 17\nOutput:\n[[False]\n[ True]\n[ True]\n[False]]\nAccuracy: 1.0\nIteration: 18\nOutput:\n[[False]\n[ True]\n[ True]\n[False]]\nAccuracy: 1.0\nIteration: 19\nOutput:\n[[False]\n[ True]\n[ True]\n[False]]\nAccuracy: 1.0\n\n\nlet’s plot the decision boundary for this one.\n\nweights=W\nxx,yy=np.meshgrid(np.arange(X[:,0].min()-0.1,X[:,0].max()+0.1,(X[:,0].max()-X[:,0].min())/10),\n                  np.arange(X[:,1].min()-0.1,X[:,1].max()+0.1,(X[:,1].max()-X[:,1].min())/10))\nZ = (1*weights[0,0] - xx.ravel()*weights[1,0] - yy.ravel()*weights[2,0])/weights[3,0]\nZ = Z.reshape(xx.shape)\n\nfig = go.Figure()\nfig.add_trace(\n    go.Surface(x=xx[0],y=yy[:,0],z=Z,showscale=False,colorscale=\"Viridis\",opacity=0.9))\n\nfig.add_trace(\n    go.Scatter3d(x=X[:,0],y=X[:,1],z=X[:,2],mode=\"markers\",marker=dict(size=6,color=T.squeeze(),colorscale=\"Viridis\"))\n)\nfig.show()\n\n\n\n\n\n\n    \n        \n                \n            \n            \n            \n        \n\n\n\nas you can see, by increasing a dimension, we were able to classify what seemed to be impossible before. Infact, it is always possible to classify two classes with a linear function, provided we project the data into correct set of dimensions. It will be explored in kernel classifiers, which are the basis of Support Vector Machines.\n\nFor now, we have learned how to get around the linear barrier of the perceptrons(by getting into higher dimensions and multi-layer, which will be discussed later).\n\nSome Notes for Data Preparation:\n\n  It is better to normalize the inputs as well as the target values(especiallly for regression).\n  Normalize both train and test inputs with the same mean and variance.\n  Perform a basic form feature selection by trying out the classifier by missing out different feature columns one at a time as see if it can increase the accuracy. If a missing out feature does improve the results, then leave it out completely and try missing out others as well.\n\n\nThe above method is actually a simplistic way of testing for the correlation between output and each of its features.\n\n\n  We can also consider dimensionality reduction, more on it later."
					}
					
				
		
		// 
		// 		
		// 			,
		// 			
		// 			"about": {
		// 				"id": "about",
		// 				"title": "About",
		// 				"categories": "",
		// 				"url": " /about/",
		// 				"content": "About Me\n\n\n    \n        \n             \n          \n      \n        \n          Murtaza Nazir\n          I am a student based in the conflicted zone of Kashmir currently pursuing Bachelors in Computer Science at National Institute of Technology, Srinagar.\n        \n        \n      \n      \n        \n            \n                themurtazanazir\n                themurtazanazir\n                 murtazanazir\n                 themurtazanazir@gmail.com"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"archive": {
		// 				"id": "archive",
		// 				"title": "Articles",
		// 				"categories": "",
		// 				"url": " /archive/",
		// 				"content": "News Archive"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"feed-xml": {
		// 				"id": "feed-xml",
		// 				"title": "",
		// 				"categories": "",
		// 				"url": " /feed.xml",
		// 				"content": "Murtaza Nazir\n    Awesome Description of this site.\n\n    https://themurtazanazir.github.io/\n    \n    Sat, 23 May 2020 17:06:17 +0530\n    Sat, 23 May 2020 17:06:17 +0530\n    Jekyll v3.8.5"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"": {
		// 				"id": "",
		// 				"title": "Murtaza Nazir",
		// 				"categories": "",
		// 				"url": " /",
		// 				"content": "Welcome\n\n\n  \n    \n        \n    \n      \n      \n        \n        Linear Algebra \n        The Linear Algebra Part\n      \n      \n        Show more \n      \n    \n        \n\n\n    \n        \n    \n      \n      \n        \n        Neural Networks \n        The neural network part\n      \n      \n        Show more"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"assets-js-main-js": {
		// 				"id": "assets-js-main-js",
		// 				"title": "",
		// 				"categories": "",
		// 				"url": " /assets/js/main.js",
		// 				"content": "(function($) {\n    'use strict';\n    $(function() {\n        $('[data-toggle=\"tooltip\"]').tooltip();\n        $('[data-toggle=\"popover\"]').popover();\n        $('.popover-dismiss').popover({\n            trigger: 'focus'\n        })\n    });\n\n    function bottomPos(element) {\n        return element.offset().top + element.outerHeight();\n    }\n    $(function() {\n        var promo = $(\".js-td-cover\");\n        if (!promo.length) {\n            return\n        }\n        var promoOffset = bottomPos(promo);\n        var navbarOffset = $('.js-navbar-scroll').offset().top;\n        var threshold = Math.ceil($('.js-navbar-scroll').outerHeight());\n        if ((promoOffset - navbarOffset) < threshold) {\n            $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n        }\n        $(window).on('scroll', function() {\n            var navtop = $('.js-navbar-scroll').offset().top - $(window).scrollTop();\n            var promoOffset = bottomPos($('.js-td-cover'));\n            var navbarOffset = $('.js-navbar-scroll').offset().top;\n            if ((promoOffset - navbarOffset) < threshold) {\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n            } else {\n                $('.js-navbar-scroll').removeClass('navbar-bg-onscroll');\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll--fade');\n            }\n        });\n    });\n}(jQuery));\n(function($) {\n    'use strict';\n    var Search = {\n        init: function() {\n            $(document).ready(function() {\n                $(document).on('keypress', '.td-search-input', function(e) {\n                    if (e.keyCode !== 13) {\n                        return\n                    }\n                    var query = $(this).val();\n                    var searchPage = \"https://themurtazanazir.github.io/search/?q=\" + query;\n                    document.location = searchPage;\n                    return false;\n                });\n            });\n        },\n    };\n    Search.init();\n}(jQuery));"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"notes": {
		// 				"id": "notes",
		// 				"title": "Notes",
		// 				"categories": "",
		// 				"url": " /notes/",
		// 				"content": "Notes\n\nWelcome to the Murtaza Nazir Notes pages! Here you can quickly jump to a \nparticular page.\n\n\n    \n    \n            \n    \n    Linear Algebra\n    The Linear Algebra Part\n            \n    \n    Neural Networks\n    The neural network part"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"sitemap-xml": {
		// 				"id": "sitemap-xml",
		// 				"title": "",
		// 				"categories": "",
		// 				"url": " /sitemap.xml",
		// 				"content": "/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% for section in site.data.toc %}\n     {{ site.baseurl }}{{ section.url }}/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% endfor %}"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"tags": {
		// 				"id": "tags",
		// 				"title": "Tags Index",
		// 				"categories": "",
		// 				"url": " /tags/",
		// 				"content": "Tags Index\n{% capture site_tags %}{% for tag in site.tags %}{% if tag %}{{ tag | first }}{% unless forloop.last %},{% endunless %}{% endif %}{% endfor %}{% endcapture %}{% assign docs_tags = \"\" %}{% for doc in site.notes %}{% assign ttags = doc.tags | join:',' | append:',' %}{% assign docs_tags = docs_tags | append:ttags %}{% endfor %}\n{% assign all_tags = site_tags | append:docs_tags %}{% assign tags_list = all_tags | split:',' | uniq | sort %}\n\n{% for tag in tags_list %}{% if tag %}{{ tag }}\n\n    {% for post in site.tags[tag] %}\n    {{- post.title -}}\n     {{- post.date | date: \"%B %d, %Y\" -}}\n{%- endfor -%}\n{% for doc in site.notes %}{% if doc.tags contains tag %}\n\n    {{ doc.title }}\n         {{- doc.date | date: \"%B %d, %Y\" -}}\n    {% endif %}{% endfor %}\n{% endif %}{%- endfor -%}"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"assets-css-style-css": {
		// 				"id": "assets-css-style-css",
		// 				"title": "",
		// 				"categories": "",
		// 				"url": " /assets/css/style.css",
		// 				"content": "@import \"jekyll-theme-primer\";"
		// 			}
		// 			
		// 		
		// 
		// 		
		// 			,
		// 			
		// 			"pages-news": {
		// 				"id": "pages-news",
		// 				"title": "",
		// 				"categories": "",
		// 				"url": " /pages/news/",
		// 				"content": "# News\n\nSubscribe with RSS to keep up with the latest news.\nFor site changes, see the changelog kept with the code base.\n\n\n\n{% for post in site.posts limit:10 %}\n   \n   {{ post.title }}\n   {{ post.date | date: \"%B %d, %Y\" }}\n   {% if post.badges %}{% for badge in post.badges %}{{ badge.tag }}{% endfor %}{% endif %}\n   {{ post.content | split:'' | first }}\n   {% if post.content contains '' %}\n      read more\n   {% endif %}\n   \n   \n{% endfor %}\n\nWant to see more? See the News Archive."
		// 			}
		// 			
		// 		
		// 
	};
</script>
<script src="/assets/js/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>

<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>

<script>
$(document).ready(function() {

    var toc = $('#TOC');

    // Select each header
    sections = $('.td-content h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¶')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil("h1");
            $.each(contenders, function(idx, contender){
               if($(contender).is('h2') || $(contender).is('h3')) {
                   var contender_id = $(contender).attr('id');
                   var contender_text = $(contender).text().split('¶')[0];
                   var content = '<li class="md-nav__item"><a class="md-nav__link" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                   children.append(content);
                }
             })
             $("#link_" + div_id).append(children);
        });
    });
</script>

<script>
var headers = ["h1", "h2", "h3", "h4"]
var colors = ["red", "orange", "green", "blue"]

$.each(headers, function(i, header){
    var color = colors[i];
    $(header).each(function () {
        var href=$(this).attr("id");
        $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¶</a>')
    });
})
</script>



	
              
              <br/>


           </div>
          </main>
        </div>
      </div>
      <footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
<ul class="list-inline mb-0">  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="Twitter" data-original-title="Twitter">
    <a class="text-white" target="_blank" href="https://twitter.com/murtazanazir">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
</ul>
</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="GitHub" data-original-title="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/themurtazanazir">
      <i class="fab fa-github"></i>
    </a>
  </li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
  <small class="text-white">© 2019 Murtaza Nazir All Rights Reserved</small>
  
      </div>
    </div>
  </div>




</footer>

    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="/assets/js/main.js"></script>

  </body>
</html>
